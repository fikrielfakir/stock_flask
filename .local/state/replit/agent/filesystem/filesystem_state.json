{"file_contents":{"APPLICATION_PROMPT.md":{"content":"# StockCéramique - Comprehensive Inventory Management System\n\n## Application Overview\n\nStockCéramique is a modern, full-stack web application designed for comprehensive inventory management of ceramic spare parts in industrial environments. Built with React, TypeScript, and PostgreSQL, it provides real-time inventory tracking, advanced analytics, and streamlined workflow management with a Windows 11 Fluent Design-inspired interface.\n\n## Core Technologies\n\n- **Frontend**: React 18 with TypeScript, Vite build system\n- **Backend**: Node.js with Express.js RESTful API\n- **Database**: PostgreSQL with Neon serverless hosting\n- **ORM**: Drizzle ORM with type-safe operations\n- **UI Framework**: Tailwind CSS with Shadcn/ui components\n- **State Management**: TanStack Query (React Query)\n- **Routing**: Wouter lightweight client-side routing\n- **Forms**: React Hook Form with Zod validation\n- **Charts**: Recharts for data visualization\n- **PWA**: Progressive Web App capabilities with offline support\n\n## Complete Feature Set\n\n### 1. Dashboard & Analytics\n- **Real-time Statistics**: Live inventory counts, low stock alerts, pending requests\n- **Interactive Charts**: Stock evolution trends, purchase status distribution, category breakdowns\n- **Recent Activity**: Latest stock movements and system activities\n- **Predictive Analytics**: AI-powered demand forecasting and reorder recommendations\n- **Performance Monitoring**: System health metrics and optimization suggestions\n- **Responsive Design**: Mobile-first approach with PWA installation support\n\n### 2. Article Management\n- **Comprehensive Article Database**: Code, designation, description, unit, category, brand\n- **Advanced Search & Filtering**: Fuzzy search, multi-criteria filtering, price ranges\n- **Stock Tracking**: Real-time stock levels, minimum thresholds, automatic alerts\n- **Supplier Integration**: Direct supplier assignment and pricing management\n- **Barcode Support**: QR code generation for each article\n- **Bulk Operations**: Import/export functionality with CSV and Excel support\n- **Enhanced Autocomplete**: Intelligent search starting after 3 characters\n\n### 3. Purchase Request System\n- **Multi-Article Requests**: Create requests with multiple items in single transaction\n- **Enhanced Form Interface**: Intelligent autocomplete for articles and suppliers\n- **Approval Workflow**: Status management (Pending, Approved, Ordered, Refused)\n- **Cost Estimation**: Price tracking and budget management\n- **Document Generation**: PDF export for purchase orders\n- **Request Conversion**: Automatic conversion to receptions upon delivery\n\n### 4. Reception Management\n- **Delivery Processing**: Record incoming stock with quantity and pricing verification\n- **Purchase Request Integration**: Convert approved requests to receptions\n- **Stock Updates**: Automatic inventory level adjustments\n- **Quality Control**: Delivery notes and observation tracking\n- **Supplier Performance**: Track delivery times and accuracy\n- **Document Management**: Receipt generation and archival\n\n### 5. Outbound Operations\n- **Stock Consumption Tracking**: Record all stock movements out of inventory\n- **Real-time Stock Validation**: Prevent overselling with live stock checks\n- **Movement Reasons**: Categorize outbound types (production, maintenance, waste)\n- **Cost Tracking**: Track consumption costs and department allocation\n- **Stock Optimization**: Intelligent suggestions for stock level management\n\n### 6. Supplier Management\n- **Comprehensive Vendor Database**: Contact details, payment terms, delivery schedules\n- **Performance Metrics**: Track reliability, pricing, and delivery performance\n- **Contract Management**: Payment conditions and lead time tracking\n- **Communication Tools**: Direct contact integration\n- **Bulk Import/Export**: Supplier data management tools\n\n### 7. Requestor Management\n- **Employee Database**: Department assignments and authorization levels\n- **Department Structure**: Hierarchical organization management\n- **Role-based Access**: Position-based permissions and workflows\n- **Request History**: Track individual and department request patterns\n- **Approval Chains**: Configurable approval workflows by department\n\n### 8. Advanced Reporting & Analytics\n- **Interactive Dashboards**: Customizable analytics with drill-down capabilities\n- **Stock Reports**: Detailed inventory analysis and forecasting\n- **Cost Analysis**: Spending patterns and budget tracking\n- **Performance Metrics**: KPIs for inventory turnover and efficiency\n- **Trend Analysis**: Historical data visualization and pattern recognition\n- **Export Capabilities**: PDF, Excel, and CSV report generation\n\n### 9. Stock Status & Monitoring\n- **Real-time Inventory Levels**: Live stock status across all articles\n- **Low Stock Alerts**: Automated notifications for reorder points\n- **Stock Movement History**: Complete audit trail of all transactions\n- **Valuation Reports**: Current stock value and cost analysis\n- **Optimization Recommendations**: AI-driven suggestions for stock management\n\n### 10. Unified Settings & Administration\n- **System Configuration**: Company details, currency, date formats, language settings\n- **Category Management**: Article categories, brands, departments, positions\n- **User Management**: Role-based access control and permissions\n- **Security Settings**: Password policies, session management, two-factor authentication\n- **Backup Management**: Automated backups with configurable schedules\n- **Audit Logging**: Complete system activity tracking\n- **Performance Optimization**: System monitoring and maintenance tools\n- **Integration Settings**: Barcode scanning, API management\n\n## Key Technical Features\n\n### Enhanced User Experience\n- **Intelligent Autocomplete**: 3-character trigger for efficient article search\n- **Dark/Light Mode**: Automatic theme switching with user preferences\n- **Responsive Design**: Optimized for desktop, tablet, and mobile devices\n- **PWA Support**: Installable web app with offline capabilities\n- **Real-time Updates**: Live data synchronization across all modules\n\n### Data Management\n- **Type Safety**: Full TypeScript implementation with compile-time validation\n- **Data Validation**: Zod schemas for robust input validation\n- **Error Handling**: Comprehensive error management with user-friendly messages\n- **Performance Optimization**: Lazy loading, caching, and query optimization\n- **Data Integrity**: ACID compliance with PostgreSQL transactions\n\n### Security & Compliance\n- **Authentication**: Secure session management\n- **Authorization**: Role-based access control\n- **Data Protection**: Encrypted database connections\n- **Audit Trail**: Complete activity logging\n- **Backup Strategy**: Automated data protection\n\n## Workflow Examples\n\n### Purchase Request Workflow\n1. User searches for articles using enhanced autocomplete\n2. Creates multi-article purchase request with estimated costs\n3. Request enters approval workflow based on user role\n4. Approved requests can be converted to receptions\n5. Stock levels automatically update upon reception\n6. Complete audit trail maintained throughout process\n\n### Stock Management Workflow\n1. Low stock alerts trigger automatically\n2. Purchase requests created with recommended quantities\n3. Supplier performance metrics inform procurement decisions\n4. Incoming stock processed through reception module\n5. Outbound movements tracked with departmental allocation\n6. Real-time analytics provide optimization insights\n\n## Deployment Architecture\n\n- **Frontend Hosting**: Vite-optimized static assets\n- **Backend API**: Express.js server with RESTful endpoints\n- **Database**: PostgreSQL with Neon serverless hosting\n- **CDN**: Static asset delivery optimization\n- **Monitoring**: Performance tracking and error reporting\n- **Scalability**: Horizontal scaling capabilities\n\n## Integration Capabilities\n\n- **Import/Export**: CSV, Excel, PDF format support\n- **Barcode Integration**: QR code generation and scanning\n- **API Endpoints**: RESTful API for third-party integrations\n- **Webhook Support**: Real-time notifications and updates\n- **Backup Systems**: Automated data backup and recovery\n\n## Mobile & PWA Features\n\n- **Progressive Web App**: Full offline functionality\n- **Mobile Optimization**: Touch-friendly interface design\n- **Push Notifications**: Real-time alerts and updates\n- **Offline Mode**: Continue working without internet connection\n- **App Installation**: Native app-like experience on mobile devices\n\nThis comprehensive inventory management system provides everything needed for modern industrial inventory control, from basic stock tracking to advanced analytics and predictive insights, all wrapped in a user-friendly, mobile-ready interface.","size_bytes":8746},"DESKTOP-SETUP.md":{"content":"# StockCéramique Desktop Setup Guide\n\n## For End Users (Simple Installation)\n\n### 1. Download and Install\n1. Download the `StockCeramique Setup.exe` file\n2. Double-click to run the installer\n3. Follow the installation wizard\n4. The app will be installed and a desktop shortcut created\n\n### 2. First Run\n- The app will create a local database automatically\n- All your data stays on your computer\n- No internet connection required\n\n## For Developers (Building from Source)\n\n### Prerequisites\n- Windows 10/11\n- Node.js 18+ installed from https://nodejs.org/\n- Git (optional, for cloning)\n\n### Quick Start\n1. Download or clone the project files\n2. Open Command Prompt or PowerShell in the project folder\n3. Run: `desktop-dev.bat` (for development)\n4. Or run: `desktop-build.bat` (to build installer)\n\n### Available Commands\n\n**Development Mode** (for testing):\n```cmd\ndesktop-dev.bat\n```\nThis starts the development server and opens the app for testing.\n\n**Build Installer** (for distribution):\n```cmd\ndesktop-build.bat\n```\nThis creates the Windows installer (.exe file) in the `dist-electron` folder.\n\n**Run Built App** (after building):\n```cmd\nrun-desktop.bat\n```\nThis runs the production version without rebuilding.\n\n### Manual Commands (if batch files don't work)\n\n**Start Development Server:**\n```cmd\nset DESKTOP_PORT=3001\ntsx server/index-desktop.ts\n```\n\n**Start Electron (in another terminal):**\n```cmd\nelectron electron/main.js\n```\n\n**Build Everything:**\n```cmd\nnpm run build\nnpx esbuild server/index-desktop.ts --platform=node --packages=external --bundle --format=esm --outdir=dist-desktop\nnpx electron-builder --config electron-builder.json --win\n```\n\n## Database Location\n- **Development**: `./data/stockceramique.db`\n- **Installed App**: `%APPDATA%/StockCeramique/stockceramique.db`\n\n## Troubleshooting\n\n### \"tsx is not recognized\"\nInstall TypeScript executor globally:\n```cmd\nnpm install -g tsx\n```\n\n### \"electron is not recognized\"\nInstall Electron globally:\n```cmd\nnpm install -g electron\n```\n\n### Port Already in Use\nChange the port in the batch files:\n```cmd\nset DESKTOP_PORT=3002\n```\n\n### Database Issues\nDelete the database file to reset:\n- Development: Delete `./data/stockceramique.db`\n- Production: Delete `%APPDATA%/StockCeramique/stockceramique.db`\n\n## Features\n- Complete offline operation\n- Local SQLite database\n- Same interface as web version\n- Windows-native application\n- Automatic database backup\n- Fast startup and performance\n\n## Distribution\nThe built installer (`StockCeramique Setup.exe`) can be distributed to any Windows computer without requiring Node.js or any other dependencies.","size_bytes":2618},"PROJECT_PROMPT.md":{"content":"# StockCéramique - Next-Generation Smart Inventory Management System\n\n## System Overview\nStockCéramique is an enterprise-grade, AI-powered inventory management system specifically designed for ceramic spare parts and industrial components. This cutting-edge application combines traditional inventory control with advanced predictive analytics, mobile-first design, and Industry 4.0 integration capabilities. The system provides complete stock control, intelligent supplier management, automated purchase workflows, and comprehensive business intelligence reporting.\n\n## Key Features & Modules\n\n### 1. **Dashboard & Analytics**\n- Real-time inventory overview with key performance indicators\n- Low stock alerts and inventory health monitoring\n- Visual charts and statistics for quick decision making\n- Recent activity tracking and notifications\n\n### 2. **Inventory Management (Articles)**\n- Complete spare parts catalog with detailed specifications\n- Stock level tracking with minimum quantity alerts\n- Barcode generation and scanning capabilities\n- Price history and cost analysis\n- Category and classification management\n\n### 3. **Supplier Management**\n- Comprehensive supplier database with contact information\n- Payment terms and delivery conditions tracking\n- Supplier performance metrics and rating system\n- Purchase history and relationship management\n\n### 4. **Purchase Request Workflow**\n- Multi-stage approval process (En Attente, Approuvé, Commandé, Refusé)\n- Request tracking from initiation to completion\n- Budget approval and authorization controls\n- Purchase order generation and management\n\n### 5. **Reception Management**\n- Incoming inventory processing and validation\n- Quality control checkpoints and inspection records\n- Delivery confirmation and discrepancy handling\n- Automatic stock level updates upon reception\n\n### 6. **Outbound Operations**\n- Stock consumption tracking with detailed reasons\n- Work order and maintenance request integration\n- Return processing and inventory adjustments\n- Movement history and audit trails\n\n### 7. **Reporting & Analytics**\n- Comprehensive inventory reports and stock analysis\n- Purchase performance and supplier evaluation reports\n- Movement tracking and usage pattern analysis\n- Export capabilities (PDF, Excel) for compliance and auditing\n\n### 8. **Data Management & Business Intelligence**\n- Bulk import/export functionality for large datasets\n- Backup and restore capabilities\n- Data validation and integrity checks\n- Integration-ready API for external systems\n- **Interactive Charts & Graphs**: Real-time visual analytics with drill-down capabilities\n- **Custom Dashboard Builder**: Drag-and-drop dashboard creation with 20+ chart types\n- **Executive Summary Reports**: High-level KPIs with visual scorecards and gauges\n- **Trend Analysis**: Time-series charts with predictive projections and forecasting\n- **Heat Maps**: Visual representation of warehouse activity and supplier performance\n\n### 9. **Advanced Features & Strategic Enhancements**\n\n#### **AI-Powered Intelligence**\n- **Smart Demand Forecasting**: Historical data analysis to predict future needs\n- **AI-Powered Reorder Points**: Dynamic minimum quantities based on usage patterns\n- **Anomaly Detection**: Alerts for unusual consumption patterns\n- **Price Optimization**: ML algorithms for optimal pricing opportunities\n- **Supplier Recommendation Engine**: Pattern-based supplier suggestions\n\n#### **Mobile & Modern Experience**\n- **Progressive Web App (PWA)**: Offline capability for warehouse operations\n- **Barcode Scanner Integration**: Native mobile camera scanning\n- **Voice Commands**: Hands-free inventory operations\n- **Push Notifications**: Real-time alerts for critical stock levels\n- **Field Technician App**: Simplified interface for maintenance teams\n\n#### **Advanced Warehouse Management**\n- **Interactive Warehouse Maps**: Visual storage locations with GPS coordinates\n- **Bin Location Optimization**: AI-suggested optimal placement\n- **Pick Path Optimization**: Route planning for efficient inventory picking\n- **Cycle Counting Workflows**: Automated inventory audit scheduling\n- **Multi-Location Management**: Support for multiple warehouses\n\n#### **Quality Control & Compliance**\n- **Certificate Management**: Track quality certificates and expiration dates\n- **Batch/Lot Tracking**: Complete traceability from supplier to installation\n- **Quality Inspection Workflows**: Customizable inspection checklists\n- **Supplier Quality Scorecards**: Track defect rates and quality metrics\n- **Compliance Dashboard**: Monitor regulatory requirements\n\n#### **Financial Integration**\n- **Budget Management**: Department-wise budget allocation and tracking\n- **Cost Center Attribution**: Link costs to specific projects\n- **Price Alert System**: Supplier price change notifications\n- **Carrying Cost Calculator**: Total cost of ownership analysis\n- **ROI Analytics**: Return on investment tracking\n\n#### **Supplier Portal & Collaboration**\n- **Supplier Self-Service Portal**: Catalog and pricing updates\n- **RFQ Management**: Streamlined quote comparison\n- **Contract Management**: Track agreements and renewal dates\n- **Supplier Risk Assessment**: Monitor financial health\n- **Vendor Collaboration Tools**: Shared workspaces\n\n#### **Integration & Automation**\n- **ERP Integration**: Connect with SAP, Oracle, or other enterprise systems\n- **CMMS Integration**: Link with maintenance management systems\n- **E-Procurement Platforms**: Integrate with Ariba, Coupa\n- **API Marketplace**: Pre-built connectors for industrial software\n- **Automated Purchase Orders**: Generate POs at reorder points\n\n#### **Environmental & Sustainability**\n- **Carbon Footprint Tracking**: Monitor environmental impact\n- **Recycling Management**: Track ceramic waste and opportunities\n- **Sustainability Scorecards**: Evaluate suppliers on environmental practices\n- **Green Supplier Discovery**: Identify eco-friendly alternatives\n- **Circular Economy Features**: Track refurbishment and reuse\n\n#### **Industry 4.0 Integration**\n- **IoT Sensor Integration**: Connect with smart shelves and storage sensors\n- **AR/VR Support**: Augmented reality for warehouse navigation\n- **Digital Twin**: Virtual representation of inventory operations\n- **Blockchain Integration**: Immutable supply chain tracking\n\n## Technical Architecture\n\n### Frontend\n- **Framework**: React 18 with TypeScript\n- **UI Components**: Shadcn/ui with Radix UI primitives\n- **Styling**: Tailwind CSS with Microsoft-inspired design system\n- **State Management**: TanStack Query for server state\n- **Routing**: Wouter for client-side navigation\n- **Forms**: React Hook Form with Zod validation\n\n### Backend\n- **Runtime**: Node.js with Express.js\n- **Database**: PostgreSQL with Drizzle ORM\n- **Validation**: Shared Zod schemas between client/server\n- **API**: RESTful endpoints with comprehensive error handling\n\n### Key Technical Features\n- **Real-time Updates**: Live inventory tracking and notifications\n- **Type Safety**: End-to-end TypeScript for reliability\n- **Responsive Design**: Works seamlessly on desktop and mobile devices\n- **Performance Optimized**: Fast loading with efficient data caching\n- **Security**: Input validation and secure database operations\n- **Accessibility**: WCAG compliant UI components\n\n## Business Value & ROI\n\n### For Operations Teams\n- **80% reduction** in stockout incidents through AI-powered predictions\n- **60% decrease** in manual data entry with advanced automation\n- **50% faster** purchase request processing with streamlined workflows\n- **25% improvement** in inventory turnover rates\n- Real-time mobile access with offline capabilities for uninterrupted operations\n\n### For Management\n- **15% reduction** in carrying costs through optimized inventory levels\n- **10% supplier cost savings** through enhanced negotiation intelligence\n- **70% decrease** in emergency purchases via predictive analytics\n- **95% budget adherence** with advanced financial tracking\n- Executive dashboards with real-time KPIs and trend analysis\n\n### For Maintenance Teams\n- Predictive maintenance integration with equipment schedules\n- Quick access to spare parts with AR-guided warehouse navigation\n- Historical usage data for data-driven maintenance planning\n- Mobile-first interface for field technician efficiency\n- Integration with CMMS systems for seamless workflow\n\n### For Finance & Procurement\n- Total cost of ownership visibility including storage and obsolescence\n- Automated budget allocation and tracking by department/project\n- Supplier risk assessment and alternative sourcing recommendations\n- ROI analytics for inventory optimization initiatives\n- Compliance monitoring with automated regulatory reporting\n\n## Usage Scenarios\n\n1. **Daily Operations**: Monitor stock levels, process incoming/outgoing inventory, handle urgent purchase requests\n2. **Weekly Planning**: Review low stock items, analyze supplier performance, generate procurement reports\n3. **Monthly Reviews**: Comprehensive inventory analysis, cost optimization, supplier relationship management\n4. **Quarterly Audits**: Full inventory reconciliation, compliance reporting, system performance review\n\n## Implementation Roadmap\n\n### **Phase 1 (Months 1-3): Foundation Enhancement**\n- Mobile PWA development with offline capabilities\n- Advanced search and filtering with AI-powered queries\n- Basic predictive analytics for demand forecasting\n- Enhanced barcode scanning and voice commands\n\n### **Phase 2 (Months 4-6): Integration Focus**\n- ERP integration framework (SAP, Oracle)\n- API development for external systems\n- Supplier portal with self-service capabilities\n- Quality control workflows with inspection checklists\n\n### **Phase 3 (Months 7-9): Advanced Intelligence**\n- AI-powered demand forecasting and anomaly detection\n- Advanced warehouse management with interactive maps\n- Comprehensive business intelligence suite\n- Environmental sustainability tracking and reporting\n\n### **Phase 4 (Months 10-12): Industry 4.0 Ready**\n- IoT integration with smart sensors\n- AR/VR capabilities for warehouse operations\n- Machine learning optimization features\n- Blockchain integration for supply chain transparency\n\n## Success Metrics\n\n### **Operational Efficiency Targets**\n- 80% reduction in stockout incidents\n- 60% decrease in manual data entry time\n- 50% faster purchase request processing\n- 25% improvement in inventory turnover rate\n\n### **Cost Optimization Goals**\n- 15% reduction in carrying costs\n- 10% supplier cost savings\n- 70% decrease in emergency purchases\n- 95% budget accuracy and adherence\n\n### **User Experience Objectives**\n- 85% user adoption rate within 3 months\n- 40% reduction in training time for new users\n- Sub-2 second page load times\n- 50% of transactions via mobile interface\n\n## Getting Started\n\nThe system is ready for immediate deployment with:\n- Modern, intuitive interface with Microsoft-inspired design\n- Comprehensive module ecosystem for all inventory operations\n- Scalable architecture supporting growth from startup to enterprise\n- Extensive API capabilities for seamless integration\n- Progressive enhancement roadmap for continuous improvement\n\nThis next-generation solution represents the future of inventory management, combining proven operational excellence with cutting-edge technology to deliver measurable business value and competitive advantage.","size_bytes":11379},"README-Desktop.md":{"content":"# StockCéramique Desktop Edition\n\n## Overview\nStockCéramique Desktop is a Windows .exe application that runs your inventory management system completely offline with a local SQLite database.\n\n## Key Features\n- **Complete Offline Operation**: No internet required after installation\n- **Local SQLite Database**: All data stored securely on your computer\n- **Windows .exe Application**: Easy to install and distribute\n- **Same Great Interface**: Identical web interface in a desktop app\n- **Cross-Platform Ready**: Can build for Windows, Mac, and Linux\n\n## Development and Building\n\n### Prerequisites\n- Node.js 18+\n- All npm dependencies installed (`npm install`)\n\n### Development Mode\n```bash\n# Start desktop development server\nDESKTOP_PORT=3001 tsx server/index-desktop.ts\n\n# In another terminal, start Electron\nelectron electron/main.js\n```\n\n### Building for Distribution\n```bash\n# Build complete desktop application\n./desktop-build.sh\n```\n\nThe build process:\n1. Builds the React frontend (`npm run build`)\n2. Bundles the desktop server with esbuild\n3. Creates the Electron application package\n4. Generates Windows installer (.exe)\n\n### Output Files\nAfter building, you'll find:\n- **Windows**: `dist-electron/StockCéramique Setup.exe` - Installer for Windows\n- **Portable**: `dist-electron/win-unpacked/` - Portable application folder\n\n## Database Storage\n- **Development**: `./data/stockceramique.db`\n- **Production**: User's AppData directory (Windows) or equivalent\n- **Automatic**: Database schema creates automatically on first run\n\n## Distribution\nThe generated .exe file is a complete installer that:\n- Installs the application to Program Files\n- Creates desktop and start menu shortcuts\n- Sets up the local database automatically\n- Requires no additional dependencies\n\n## Architecture\n- **Frontend**: Same React/TypeScript application\n- **Backend**: Express server with SQLite instead of PostgreSQL\n- **Desktop**: Electron wrapper with native OS integration\n- **Database**: SQLite with same schema as web version\n\n## API Endpoints (Local)\nAll endpoints run on `http://127.0.0.1:3001`:\n- `GET /api/health` - Server health check\n- `GET /api/articles` - List all articles\n- `POST /api/articles` - Create new article  \n- `GET /api/dashboard/stats` - Dashboard statistics\n\n## Security\n- Local-only server (127.0.0.1)\n- No external network dependencies\n- All data remains on user's computer\n- Standard Electron security practices\n\n## Future Enhancements\n- Data import/export features\n- Backup/restore functionality\n- Network sync capabilities (optional)\n- Multi-user support for shared databases","size_bytes":2601},"app.py":{"content":"from flask import Flask, jsonify, request, send_from_directory\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_cors import CORS\nfrom flask_migrate import Migrate\nimport os\nfrom datetime import datetime\nimport uuid\nimport logging\n\n# Initialize Flask app\napp = Flask(__name__, static_folder='dist', static_url_path='')\n\n# Configuration\napp.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL', 'postgresql://localhost/stockceramique')\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-secret-key')\n\n# Initialize extensions\ndb = SQLAlchemy(app)\nmigrate = Migrate(app, db)\nCORS(app)\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Import models and routes after db initialization\nfrom models import Article, Supplier, Requestor, PurchaseRequest, PurchaseRequestItem, Reception, Outbound\nfrom routes import register_routes\n\n# Register all routes\nregister_routes(app, db)\n\n# Error handlers\n@app.errorhandler(404)\ndef not_found(error):\n    return jsonify({'message': 'Endpoint not found'}), 404\n\n@app.errorhandler(500)\ndef internal_error(error):\n    db.session.rollback()\n    return jsonify({'message': 'Internal server error'}), 500\n\n# Serve React app\n@app.route('/')\ndef serve():\n    return send_from_directory(app.static_folder, 'index.html')\n\n@app.route('/<path:path>')\ndef serve_static(path):\n    if path != \"\" and os.path.exists(app.static_folder + '/' + path):\n        return send_from_directory(app.static_folder, path)\n    else:\n        return send_from_directory(app.static_folder, 'index.html')\n\nif __name__ == '__main__':\n    # Create tables if they don't exist\n    with app.app_context():\n        db.create_all()\n    \n    # Run the application\n    port = int(os.environ.get('PORT', 5000))\n    app.run(host='0.0.0.0', port=port, debug=os.environ.get('FLASK_ENV') == 'development')","size_bytes":1918},"build_script.js":{"content":"import { execSync } from 'child_process';\nimport fs from 'fs';\nimport path from 'path';\n\nconsole.log('Building StockCeramique Desktop Application');\n\ntry {\n  // Step 1: Clean previous builds\n  console.log('Step 1: Cleaning previous builds...');\n  if (fs.existsSync('dist')) {\n    fs.rmSync('dist', { recursive: true });\n  }\n  if (fs.existsSync('dist-desktop')) {\n    fs.rmSync('dist-desktop', { recursive: true });\n  }\n  if (fs.existsSync('dist-electron-main')) {\n    fs.rmSync('dist-electron-main', { recursive: true });\n  }\n\n  // Step 2: Build React frontend\n  console.log('Step 2: Building React frontend...');\n  execSync('vite build', { stdio: 'inherit' });\n\n  // Step 3: Build backend server\n  console.log('Step 3: Building backend server...');\n  execSync('esbuild server/index.ts --platform=node --packages=external --bundle --format=esm --outdir=dist', { stdio: 'inherit' });\n\n  // Step 4: Build desktop server\n  console.log('Step 4: Building desktop server...');\n  execSync('esbuild server/index-desktop.ts --platform=node --packages=external --bundle --format=esm --outdir=dist-desktop', { stdio: 'inherit' });\n\n  // Step 5: Build Electron main process\n  console.log('Step 5: Building Electron main process...');\n  execSync('esbuild electron/main.ts --platform=node --packages=external --bundle --format=esm --outdir=dist-electron-main', { stdio: 'inherit' });\n\n  // Step 6: Copy necessary files\n  console.log('Step 5: Copying files...');\n  \n  // Copy package.json to dist-desktop\n  const packageJson = JSON.parse(fs.readFileSync('package.json', 'utf8'));\n  // Remove devDependencies to reduce bundle size\n  delete packageJson.devDependencies;\n  fs.writeFileSync(path.join('dist-desktop', 'package.json'), JSON.stringify(packageJson, null, 2));\n\n  // Step 7: Build Electron app\n  console.log('Step 6: Building Electron application...');\n  execSync('electron-builder --config build-config.json', { stdio: 'inherit' });\n\n  console.log('✅ Build completed successfully!');\n  console.log('📦 Electron app built in: dist-electron/');\n\n} catch (error) {\n  console.error('❌ Build failed:', error.message);\n  process.exit(1);\n}\n","size_bytes":2134},"desktop-build.sh":{"content":"#!/bin/bash\n\necho \"🏗️  Building StockCéramique Desktop Application...\"\n\n# Step 1: Build frontend\necho \"📦 Building frontend...\"\nnpm run build\n\n# Step 2: Build desktop server\necho \"🖥️  Building desktop server...\"\nmkdir -p dist-desktop\nesbuild server/index-desktop.ts --platform=node --packages=external --bundle --format=esm --outdir=dist-desktop\n\n# Step 3: Copy necessary files\necho \"📋 Copying files...\"\ncp -r electron dist-desktop/\ncp electron-builder.json dist-desktop/\ncp -r data dist-desktop/ || mkdir -p dist-desktop/data\n\n# Step 4: Build Electron app\necho \"⚡ Building Electron app...\"\nelectron-builder --config dist-desktop/electron-builder.json\n\necho \"✅ Desktop build complete! Check dist-electron folder for the .exe file.\"\necho \"💾 Database will be stored locally in the user's AppData folder\"\necho \"🚀 You can now distribute the .exe file to users\"","size_bytes":882},"desktop-scripts.md":{"content":"\n# Desktop Scripts\ndesktop-dev: concurrently \"tsx server/index-desktop.ts\" \"wait-on http://127.0.0.1:3001 && electron electron/main.js\"\ndesktop-build: vite build && esbuild server/index-desktop.ts --platform=node --packages=external --bundle --format=esm --outdir=dist-desktop && electron-builder --config electron-builder.json\ndesktop-start: electron electron/main.js\n\n","size_bytes":370},"drizzle.config.ts":{"content":"import { defineConfig } from \"drizzle-kit\";\n\nif (!process.env.DATABASE_URL) {\n  throw new Error(\"DATABASE_URL, ensure the database is provisioned\");\n}\n\nexport default defineConfig({\n  out: \"./migrations\",\n  schema: \"./shared/schema.ts\",\n  dialect: \"postgresql\",\n  dbCredentials: {\n    url: process.env.DATABASE_URL,\n  },\n});\n","size_bytes":325},"flask_app.py":{"content":"from flask import Flask, jsonify, request, send_from_directory, render_template, redirect, url_for\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_cors import CORS\nfrom flask_migrate import Migrate\nimport os\nfrom datetime import datetime\nimport uuid\nimport logging\n# License managers removed for Replit environment\n\n# Initialize extensions\nmigrate = Migrate()\n\ndef create_app():\n    # Initialize Flask app\n    app = Flask(__name__, static_folder='dist', static_url_path='')\n\n    # Configuration - PostgreSQL Database\n    database_url = os.environ.get('DATABASE_URL')\n    if database_url and database_url.startswith('postgresql://'):\n        database_url = database_url.replace('postgresql://', 'postgresql+psycopg2://')\n    app.config['SQLALCHEMY_DATABASE_URI'] = database_url\n    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n    app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {\n        'pool_pre_ping': True,\n        'pool_recycle': 300,\n        'connect_args': {\n            'connect_timeout': 10,\n            'sslmode': 'prefer'\n        }\n    }\n    app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'your-secret-key-here')\n\n    # Import db from models and initialize\n    from flask_models import db\n    db.init_app(app)\n    migrate.init_app(app, db)\n    CORS(app)\n\n    # Configure logging\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(__name__)\n\n    # Import models and routes after db initialization\n    from flask_models import Article, Supplier, Requestor, PurchaseRequest, PurchaseRequestItem, Reception, Outbound, User, UserSession\n    from routes import register_routes\n    from functools import wraps\n    \n    # Authentication middleware\n    def require_auth(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            auth_header = request.headers.get('Authorization')\n            if not auth_header or not auth_header.startswith('Bearer '):\n                return redirect('/login')\n            \n            token = auth_header.split(' ')[1]\n            session = UserSession.query.filter_by(session_token=token).first()\n            \n            if not session or not session.is_valid():\n                return redirect('/login')\n            \n            # Update last activity\n            session.user.last_login = datetime.utcnow()\n            db.session.commit()\n            \n            return f(*args, **kwargs)\n        return decorated_function\n\n    # Register all routes\n    register_routes(app, db)\n\n    # Error handlers\n    @app.errorhandler(404)\n    def not_found(error):\n        return jsonify({'message': 'Endpoint not found'}), 404\n\n    @app.errorhandler(500)\n    def internal_error(error):\n        db.session.rollback()\n        return jsonify({'message': 'Internal server error'}), 500\n\n    # License checking removed for Replit environment\n\n    # License and activation routes removed for Replit environment\n\n    # Login route\n    @app.route('/login')\n    def login_page():\n        return render_template('login.html')\n    \n    # Flask template routes\n    @app.route('/')\n    def dashboard():\n        # Check for session in cookies or localStorage (handled by frontend)\n        return render_template('dashboard.html')\n    \n    @app.route('/articles')\n    def articles():\n        return render_template('articles.html')\n    \n    @app.route('/suppliers')\n    def suppliers():\n        return render_template('suppliers.html')\n    \n    @app.route('/requestors')\n    def requestors():\n        return render_template('requestors.html')\n    \n    @app.route('/purchase-requests')\n    def purchase_requests():\n        return render_template('purchase_requests.html')\n    \n    @app.route('/reception')\n    def reception():\n        return render_template('reception.html')\n    \n    @app.route('/outbound')\n    def outbound():\n        return render_template('outbound.html')\n    \n    @app.route('/analytics')\n    def analytics():\n        return render_template('analytics.html')\n    \n    @app.route('/purchase-follow')\n    def purchase_follow():\n        return render_template('purchase_follow.html')\n    \n    @app.route('/stock-status')\n    def stock_status():\n        return render_template('stock_status.html')\n    \n    @app.route('/reports')\n    def reports():\n        return render_template('reports.html')\n    \n    @app.route('/notifications')\n    def notifications():\n        return render_template('notifications.html')\n    \n    @app.route('/profile')\n    def profile():\n        return render_template('profile.html')\n    \n    @app.route('/settings')\n    def settings():\n        return render_template('settings.html')\n\n    return app\n\nif __name__ == '__main__':\n    app = create_app()\n    \n    # Create tables if they don't exist\n    with app.app_context():\n        from flask_models import db\n        db.create_all()\n    \n    # Run the application\n    port = int(os.environ.get('PORT', 5000))\n    app.run(host='0.0.0.0', port=port, debug=os.environ.get('FLASK_ENV') == 'development')","size_bytes":4973},"flask_models.py":{"content":"from datetime import datetime, timedelta\nimport uuid\nfrom flask_sqlalchemy import SQLAlchemy\nfrom werkzeug.security import generate_password_hash, check_password_hash\n\n# This will be initialized in the app factory\ndb = SQLAlchemy()\n\ndef generate_uuid():\n    return str(uuid.uuid4())\n\n# User Model for Authentication\nclass User(db.Model):\n    __tablename__ = 'users'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    password_hash = db.Column(db.String(255), nullable=False)\n    full_name = db.Column(db.String(100))\n    email = db.Column(db.String(120))\n    is_active = db.Column(db.Boolean, default=True)\n    last_login = db.Column(db.DateTime)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def set_password(self, password):\n        self.password_hash = generate_password_hash(password)\n    \n    def check_password(self, password):\n        return check_password_hash(self.password_hash, password)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'username': self.username,\n            'fullName': self.full_name,\n            'email': self.email,\n            'isActive': self.is_active,\n            'lastLogin': self.last_login.isoformat() if self.last_login else None,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Session Model for Token Management\nclass UserSession(db.Model):\n    __tablename__ = 'user_sessions'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    user_id = db.Column(db.String(36), db.ForeignKey('users.id'), nullable=False)\n    session_token = db.Column(db.String(255), unique=True, nullable=False)\n    expires_at = db.Column(db.DateTime, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    user = db.relationship('User', backref='sessions')\n    \n    @staticmethod\n    def create_session(user_id):\n        # 24-hour session duration\n        expires_at = datetime.utcnow() + timedelta(hours=24)\n        session_token = str(uuid.uuid4())\n        \n        session = UserSession(\n            user_id=user_id,\n            session_token=session_token,\n            expires_at=expires_at\n        )\n        return session\n    \n    def is_valid(self):\n        return datetime.utcnow() < self.expires_at\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'userId': self.user_id,\n            'sessionToken': self.session_token,\n            'expiresAt': self.expires_at.isoformat() if self.expires_at else None,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Articles (Spare Parts)\nclass Article(db.Model):\n    __tablename__ = 'articles'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    code_article = db.Column(db.Text, nullable=False, unique=True)\n    designation = db.Column(db.Text, nullable=False)\n    categorie = db.Column(db.Text, nullable=False)\n    marque = db.Column(db.Text)\n    reference = db.Column(db.Text)\n    stock_initial = db.Column(db.Integer, nullable=False, default=0)\n    stock_actuel = db.Column(db.Integer, nullable=False, default=0)\n    unite = db.Column(db.Text, nullable=False, default='pcs')\n    prix_unitaire = db.Column(db.Numeric(10, 2))\n    seuil_minimum = db.Column(db.Integer, default=10)\n    fournisseur_id = db.Column(db.String(36))\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'codeArticle': self.code_article,\n            'designation': self.designation,\n            'categorie': self.categorie,\n            'marque': self.marque,\n            'reference': self.reference,\n            'stockInitial': self.stock_initial,\n            'stockActuel': self.stock_actuel,\n            'unite': self.unite,\n            'prixUnitaire': float(self.prix_unitaire) if self.prix_unitaire else None,\n            'seuilMinimum': self.seuil_minimum,\n            'fournisseurId': self.fournisseur_id,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Suppliers\nclass Supplier(db.Model):\n    __tablename__ = 'suppliers'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    nom = db.Column(db.Text, nullable=False)\n    contact = db.Column(db.Text)\n    telephone = db.Column(db.Text)\n    email = db.Column(db.Text)\n    adresse = db.Column(db.Text)\n    conditions_paiement = db.Column(db.Text)\n    delai_livraison = db.Column(db.Integer)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'nom': self.nom,\n            'contact': self.contact,\n            'telephone': self.telephone,\n            'email': self.email,\n            'adresse': self.adresse,\n            'conditionsPaiement': self.conditions_paiement,\n            'delaiLivraison': self.delai_livraison,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Requestors\nclass Requestor(db.Model):\n    __tablename__ = 'requestors'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    nom = db.Column(db.Text, nullable=False)\n    prenom = db.Column(db.Text, nullable=False)\n    departement = db.Column(db.Text, nullable=False)\n    poste = db.Column(db.Text)\n    email = db.Column(db.Text)\n    telephone = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'nom': self.nom,\n            'prenom': self.prenom,\n            'departement': self.departement,\n            'poste': self.poste,\n            'email': self.email,\n            'telephone': self.telephone,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Purchase Requests (Header)\nclass PurchaseRequest(db.Model):\n    __tablename__ = 'purchase_requests'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    numero_demande = db.Column(db.String(50), unique=True)\n    date_demande = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    requestor_id = db.Column(db.String(36), nullable=False)\n    observations = db.Column(db.Text)\n    statut = db.Column(db.Text, nullable=False, default='en_attente')  # en_attente, approuve, refuse, commande, recu\n    total_articles = db.Column(db.Integer, nullable=False, default=0)\n    total_estime = db.Column(db.Numeric(10, 2), default=0)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'numeroDemande': self.numero_demande,\n            'dateDemande': self.date_demande.isoformat() if self.date_demande else None,\n            'requestorId': self.requestor_id,\n            'observations': self.observations,\n            'statut': self.statut,\n            'totalArticles': self.total_articles,\n            'totalEstime': float(self.total_estime) if self.total_estime else 0,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Purchase Request Items\nclass PurchaseRequestItem(db.Model):\n    __tablename__ = 'purchase_request_items'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    purchase_request_id = db.Column(db.String(36), db.ForeignKey('purchase_requests.id'), nullable=False)\n    article_id = db.Column(db.String(36), db.ForeignKey('articles.id'), nullable=False)\n    supplier_id = db.Column(db.String(36), db.ForeignKey('suppliers.id'))\n    quantite_demandee = db.Column(db.Integer, nullable=False)\n    prix_unitaire_estime = db.Column(db.Numeric(10, 2))\n    sous_total = db.Column(db.Numeric(10, 2))\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    # Relationships\n    purchase_request = db.relationship('PurchaseRequest', backref='items')\n    article = db.relationship('Article')\n    supplier = db.relationship('Supplier')\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'purchaseRequestId': self.purchase_request_id,\n            'articleId': self.article_id,\n            'quantiteDemandee': self.quantite_demandee,\n            'supplierId': self.supplier_id,\n            'prixUnitaireEstime': float(self.prix_unitaire_estime) if self.prix_unitaire_estime else None,\n            'sousTotal': float(self.sous_total) if self.sous_total else 0,\n            'observations': self.observations,\n            'article': self.article.to_dict() if self.article else None,\n            'supplier': self.supplier.to_dict() if self.supplier else None,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Goods Reception\nclass Reception(db.Model):\n    __tablename__ = 'receptions'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    date_reception = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    supplier_id = db.Column(db.String(36), nullable=False)\n    article_id = db.Column(db.String(36), nullable=False)\n    quantite_recue = db.Column(db.Integer, nullable=False)\n    prix_unitaire = db.Column(db.Numeric(10, 2))\n    numero_bon_livraison = db.Column(db.Text)\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'dateReception': self.date_reception.isoformat() if self.date_reception else None,\n            'supplierId': self.supplier_id,\n            'articleId': self.article_id,\n            'quantiteRecue': self.quantite_recue,\n            'prixUnitaire': float(self.prix_unitaire) if self.prix_unitaire else None,\n            'numeroBonLivraison': self.numero_bon_livraison,\n            'observations': self.observations,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Stock Outbound\nclass Outbound(db.Model):\n    __tablename__ = 'outbounds'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    numero_sortie = db.Column(db.String(50), nullable=False)  # Transaction number for grouping\n    date_sortie = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    requestor_id = db.Column(db.String(36), nullable=True)\n    article_id = db.Column(db.String(36), nullable=False)\n    quantite_sortie = db.Column(db.Integer, nullable=False)\n    motif_sortie = db.Column(db.Text, nullable=False)\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'numeroSortie': self.numero_sortie,\n            'dateSortie': self.date_sortie.isoformat() if self.date_sortie else None,\n            'requestorId': self.requestor_id,\n            'articleId': self.article_id,\n            'quantiteSortie': self.quantite_sortie,\n            'motifSortie': self.motif_sortie,\n            'observations': self.observations,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Activity Log Model\nclass ActivityLog(db.Model):\n    __tablename__ = 'activity_logs'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    user_id = db.Column(db.String(36), nullable=True, default='system')  # For now, using 'system' as default\n    action = db.Column(db.String(50), nullable=False)  # CREATE, UPDATE, DELETE, EXPORT, IMPORT, etc.\n    entity_type = db.Column(db.String(50), nullable=False)  # suppliers, requestors, articles, etc.\n    entity_id = db.Column(db.String(36), nullable=True)  # ID of affected record\n    entity_name = db.Column(db.Text, nullable=True)  # Human readable name/identifier\n    old_values = db.Column(db.Text, nullable=True)  # JSON string of old values\n    new_values = db.Column(db.Text, nullable=True)  # JSON string of new values  \n    ip_address = db.Column(db.String(45), nullable=True)\n    user_agent = db.Column(db.Text, nullable=True)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'userId': self.user_id,\n            'action': self.action,\n            'entityType': self.entity_type,\n            'entityId': self.entity_id,\n            'entityName': self.entity_name,\n            'oldValues': self.old_values,\n            'newValues': self.new_values,\n            'ipAddress': self.ip_address,\n            'userAgent': self.user_agent,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n    \n    def get_description(self):\n        \"\"\"Generate human-readable description of the activity\"\"\"\n        action_descriptions = {\n            'CREATE': 'Ajout',\n            'UPDATE': 'Modification', \n            'DELETE': 'Suppression',\n            'EXPORT': 'Export',\n            'IMPORT': 'Import'\n        }\n        \n        entity_descriptions = {\n            'suppliers': 'fournisseur',\n            'requestors': 'demandeur',\n            'articles': 'article',\n            'purchase_requests': 'demande d\\'achat',\n            'receptions': 'réception',\n            'outbounds': 'sortie'\n        }\n        \n        action_desc = action_descriptions.get(self.action, self.action)\n        entity_desc = entity_descriptions.get(self.entity_type, self.entity_type)\n        \n        if self.entity_name:\n            return f\"{action_desc} {entity_desc}: {self.entity_name}\"\n        else:\n            return f\"{action_desc} {entity_desc}\"","size_bytes":13811},"models.py":{"content":"from datetime import datetime\nimport uuid\nfrom app import db\n\ndef generate_uuid():\n    return str(uuid.uuid4())\n\n# Articles (Spare Parts)\nclass Article(db.Model):\n    __tablename__ = 'articles'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    code_article = db.Column(db.Text, nullable=False, unique=True)\n    designation = db.Column(db.Text, nullable=False)\n    categorie = db.Column(db.Text, nullable=False)\n    marque = db.Column(db.Text)\n    reference = db.Column(db.Text)\n    stock_initial = db.Column(db.Integer, nullable=False, default=0)\n    stock_actuel = db.Column(db.Integer, nullable=False, default=0)\n    unite = db.Column(db.Text, nullable=False, default='pcs')\n    prix_unitaire = db.Column(db.Numeric(10, 2))\n    seuil_minimum = db.Column(db.Integer, default=10)\n    fournisseur_id = db.Column(db.String(36))\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'codeArticle': self.code_article,\n            'designation': self.designation,\n            'categorie': self.categorie,\n            'marque': self.marque,\n            'reference': self.reference,\n            'stockInitial': self.stock_initial,\n            'stockActuel': self.stock_actuel,\n            'unite': self.unite,\n            'prixUnitaire': float(self.prix_unitaire) if self.prix_unitaire else None,\n            'seuilMinimum': self.seuil_minimum,\n            'fournisseurId': self.fournisseur_id,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Suppliers\nclass Supplier(db.Model):\n    __tablename__ = 'suppliers'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    nom = db.Column(db.Text, nullable=False)\n    contact = db.Column(db.Text)\n    telephone = db.Column(db.Text)\n    email = db.Column(db.Text)\n    adresse = db.Column(db.Text)\n    conditions_paiement = db.Column(db.Text)\n    delai_livraison = db.Column(db.Integer)  # in days\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'nom': self.nom,\n            'contact': self.contact,\n            'telephone': self.telephone,\n            'email': self.email,\n            'adresse': self.adresse,\n            'conditionsPaiement': self.conditions_paiement,\n            'delaiLivraison': self.delai_livraison,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Requestors\nclass Requestor(db.Model):\n    __tablename__ = 'requestors'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    nom = db.Column(db.Text, nullable=False)\n    prenom = db.Column(db.Text, nullable=False)\n    departement = db.Column(db.Text, nullable=False)\n    poste = db.Column(db.Text)\n    email = db.Column(db.Text)\n    telephone = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'nom': self.nom,\n            'prenom': self.prenom,\n            'departement': self.departement,\n            'poste': self.poste,\n            'email': self.email,\n            'telephone': self.telephone,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Purchase Requests (Header)\nclass PurchaseRequest(db.Model):\n    __tablename__ = 'purchase_requests'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    date_demande = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    requestor_id = db.Column(db.String(36), nullable=False)\n    date_initiation = db.Column(db.DateTime, default=datetime.utcnow)\n    observations = db.Column(db.Text)\n    statut = db.Column(db.Text, nullable=False, default='en_attente')  # en_attente, approuve, refuse, commande\n    total_articles = db.Column(db.Integer, nullable=False, default=0)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'dateDemande': self.date_demande.isoformat() if self.date_demande else None,\n            'requestorId': self.requestor_id,\n            'dateInitiation': self.date_initiation.isoformat() if self.date_initiation else None,\n            'observations': self.observations,\n            'statut': self.statut,\n            'totalArticles': self.total_articles,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Purchase Request Items (Details for multiple articles)\nclass PurchaseRequestItem(db.Model):\n    __tablename__ = 'purchase_request_items'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    purchase_request_id = db.Column(db.String(36), nullable=False)\n    article_id = db.Column(db.String(36), nullable=False)\n    quantite_demandee = db.Column(db.Integer, nullable=False)\n    supplier_id = db.Column(db.String(36))\n    prix_unitaire_estime = db.Column(db.Numeric(10, 2))\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'purchaseRequestId': self.purchase_request_id,\n            'articleId': self.article_id,\n            'quantiteDemandee': self.quantite_demandee,\n            'supplierId': self.supplier_id,\n            'prixUnitaireEstime': float(self.prix_unitaire_estime) if self.prix_unitaire_estime else None,\n            'observations': self.observations,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Goods Reception\nclass Reception(db.Model):\n    __tablename__ = 'receptions'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    date_reception = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    supplier_id = db.Column(db.String(36), nullable=False)\n    article_id = db.Column(db.String(36), nullable=False)\n    quantite_recue = db.Column(db.Integer, nullable=False)\n    prix_unitaire = db.Column(db.Numeric(10, 2))\n    numero_bon_livraison = db.Column(db.Text)\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'dateReception': self.date_reception.isoformat() if self.date_reception else None,\n            'supplierId': self.supplier_id,\n            'articleId': self.article_id,\n            'quantiteRecue': self.quantite_recue,\n            'prixUnitaire': float(self.prix_unitaire) if self.prix_unitaire else None,\n            'numeroBonLivraison': self.numero_bon_livraison,\n            'observations': self.observations,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }\n\n# Stock Outbound\nclass Outbound(db.Model):\n    __tablename__ = 'outbounds'\n    \n    id = db.Column(db.String(36), primary_key=True, default=generate_uuid)\n    date_sortie = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    requestor_id = db.Column(db.String(36), nullable=False)\n    article_id = db.Column(db.String(36), nullable=False)\n    quantite_sortie = db.Column(db.Integer, nullable=False)\n    motif_sortie = db.Column(db.Text, nullable=False)\n    observations = db.Column(db.Text)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n    \n    def to_dict(self):\n        return {\n            'id': self.id,\n            'dateSortie': self.date_sortie.isoformat() if self.date_sortie else None,\n            'requestorId': self.requestor_id,\n            'articleId': self.article_id,\n            'quantiteSortie': self.quantite_sortie,\n            'motifSortie': self.motif_sortie,\n            'observations': self.observations,\n            'createdAt': self.created_at.isoformat() if self.created_at else None\n        }","size_bytes":7998},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"flask>=3.1.2\",\n    \"flask-cors>=6.0.1\",\n    \"flask-migrate>=4.1.0\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"openpyxl>=3.1.5\",\n    \"pandas>=2.3.2\",\n    \"psutil>=7.0.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pyinstaller>=6.15.0\",\n    \"python-dotenv>=1.1.1\",\n    \"pywebview>=6.0\",\n    \"requests>=2.32.5\",\n    \"sqlalchemy>=2.0.43\",\n    \"weasyprint>=66.0\",\n    \"werkzeug>=3.1.3\",\n]\n","size_bytes":542},"replit.md":{"content":"# StockCéramique - Inventory Management System\n\n## Overview\nStockCéramique is a comprehensive inventory management system for ceramic spare parts. It tracks stock levels, manages suppliers, processes purchase requests, handles receptions and outbound shipments, and generates reports. The system is tailored for industrial environments, offering features like low stock alerts, detailed movement tracking, and comprehensive reporting. Its vision is to provide precise inventory control, ensuring operational efficiency and informed decision-making.\n\n## User Preferences\nPreferred communication style: Simple, everyday language.\n\n## Recent Changes (August 28, 2025)\n**Desktop App Cleanup & Windows 10 Support**: Optimized desktop application setup for Windows 10 compatibility:\n- Removed obsolete files: `initialize_desktop_database.py` and `desktop_main_old.py`\n- Fixed PyInstaller configuration and removed broken import dependencies\n- Updated splash screen and application icon assets\n- Created Windows-specific requirements file for better compatibility\n- Added automated build script (`build-windows.bat`) for easy Windows compilation\n- Enhanced error handling and PyInstaller integration for Windows 10\n- Desktop app now properly handles database initialization without sample data dependencies\n\n## Previous Changes (August 27, 2025)\n**Project Migration & Data Import Completed**: Successfully migrated the StockCéramique application from Replit Agent to standard Replit environment. Key accomplishments:\n- Complete Flask application now running smoothly in Replit environment\n- All Python dependencies (Flask, SQLAlchemy, etc.) properly installed\n- Database initialized with full schema and relationships\n- Imported 2,421 real inventory articles with proper categorization and pricing\n- Application verified working with all 12 modules accessible\n- Enhanced dashboard currency formatting with K/M suffixes for large values (6+ digits)\n- Migration completed with zero data loss and full functionality preserved\n\n## Previous Changes (August 23, 2025)\n**Complete Flask Migration**: Successfully rebuilt the application as a pure server-side Flask application, removing all React, Node.js, and Electron dependencies. Key transformations include:\n- Complete Flask-based architecture with server-side rendering\n- PostgreSQL database integration with SQLAlchemy ORM\n- 12 comprehensive modules covering complete inventory management workflow\n- Microsoft-inspired UI design with Tailwind CSS and Mica effects\n- Advanced interactive features using vanilla JavaScript and Chart.js\n- Real-time dashboard with predictive analytics and visual insights\n- Comprehensive reporting system with multi-format exports\n\n## System Architecture\n\n### Application Architecture\n- **Framework**: Flask (Python) with server-side rendering\n- **Templates**: Jinja2 templates with comprehensive HTML/CSS/JavaScript\n- **Styling**: Tailwind CSS with Microsoft-inspired design system\n- **Interactive Features**: Vanilla JavaScript with modern ES6+ features\n- **Data Visualization**: Chart.js for advanced charts and analytics\n- **Icons**: Font Awesome and Lucide for comprehensive iconography\n- **Responsive Design**: Mobile-first approach with grid layouts\n\n### Backend Architecture\n- **Runtime**: Python 3.11+ with Flask framework\n- **API Design**: RESTful endpoints with JSON responses\n- **Database ORM**: SQLAlchemy with Flask-SQLAlchemy integration\n- **Migrations**: Flask-Migrate for database schema management\n- **Validation**: Server-side validation with comprehensive error handling\n\n### Data Storage\n- **Primary Database**: PostgreSQL with connection pooling\n- **ORM**: SQLAlchemy with declarative models\n- **Schema Management**: Flask-Migrate for version control\n- **Data Integrity**: Foreign key constraints and relationship management\n\n### Core Entities and Relationships\n- **Articles**: Spare parts inventory with stock tracking, pricing, supplier relationships, and QR code generation\n- **Suppliers**: Vendor management with performance tracking and delivery analytics\n- **Requestors**: Employee/department management with role-based permissions and request history\n- **Purchase Requests**: Multi-article workflow with approval states and automated notifications\n- **Receptions**: Incoming inventory tracking with automatic stock updates and quality control\n- **Outbounds**: Stock consumption tracking with project allocation and cost center management\n- **Stock Movements**: Complete audit trail with real-time movement tracking and analytics\n\n### Application Modules (12 Screens)\n1. **Dashboard (/)**: Real-time overview with metrics, charts, alerts, and quick actions\n2. **Articles (/articles)**: Complete inventory management with search, analytics, and QR codes\n3. **Purchase Requests (/purchase-requests)**: Multi-article request creation and management\n4. **Purchase Follow-up (/purchase-follow)**: Kanban-style workflow tracking and approval\n5. **Stock Status (/stock-status)**: Visual monitoring with color-coded status indicators\n6. **Reception (/reception)**: Goods receiving with automatic stock updates\n7. **Outbound (/outbound)**: Stock consumption tracking with project management\n8. **Suppliers (/suppliers)**: Vendor management with performance analytics\n9. **Requestors (/requestors)**: Personnel management with department integration\n10. **Reports (/reports)**: Comprehensive reporting with multi-format exports\n11. **Settings (/settings)**: System configuration and master data management\n12. **Analytics (/analytics)**: Business intelligence with predictive insights\n\n### Authentication and Authorization\nBasic session-based approach with future plans for role-based access control (Administrator, Manager, Employee).\n\n### API Design\nRESTful API with consistent endpoint patterns for CRUD operations, dashboard statistics, and low stock alerts. Includes error handling middleware and request logging.\n\n### Key Features and Design Decisions\n- **Server-Side Architecture**: Pure Flask application with server-side rendering for optimal performance and SEO.\n- **12 Comprehensive Modules**: Complete inventory management workflow from dashboard to analytics.\n- **Microsoft-Inspired Design**: Mica effects, Windows-style UI components, and modern design language.\n- **Real-Time Dashboard**: Live metrics, predictive analytics, and interactive charts with Chart.js.\n- **Advanced Search**: Global search functionality with intelligent filtering across all entities.\n- **Kanban Workflow**: Purchase follow-up with drag-and-drop style interface for request tracking.\n- **Visual Stock Monitoring**: Color-coded stock status with real-time alerts and threshold management.\n- **Multi-Format Reporting**: PDF, Excel, CSV, and JSON export capabilities with custom report builder.\n- **Comprehensive Settings**: Master data management, security policies, backup systems, and integrations.\n- **Dynamic Forms**: AJAX-powered forms with real-time validation and autocomplete features.\n- **French Localization**: Complete French interface with MAD currency formatting.\n- **Responsive Design**: Mobile-first approach with Tailwind CSS grid systems.\n- **Performance Optimized**: Efficient database queries, lazy loading, and optimized asset delivery.\n- **Security Features**: Session management, audit logging, and secure data handling.\n- **Toast Notifications**: Real-time feedback system with contextual alerts and confirmations.\n\n## External Dependencies\n\n### Database Services\n- **PostgreSQL**: Robust relational database with ACID compliance\n- **SQLAlchemy**: Python SQL toolkit and Object-Relational Mapping\n\n### UI and Styling Libraries\n- **Tailwind CSS**: Utility-first CSS framework via CDN\n- **Font Awesome**: Comprehensive icon library\n- **Lucide**: Modern icon system for additional iconography\n- **Chart.js**: Powerful charting library for data visualization\n\n### Python Framework and Extensions\n- **Flask**: Micro web framework for Python\n- **Flask-SQLAlchemy**: SQLAlchemy integration for Flask\n- **Flask-Migrate**: Database migration support\n- **Flask-CORS**: Cross-Origin Resource Sharing support\n- **Gunicorn**: Python WSGI HTTP Server for production\n- **psycopg2-binary**: PostgreSQL adapter for Python\n- **python-dotenv**: Environment variable management\n\n### Development and Runtime\n- **Python 3.11+**: Modern Python runtime\n- **Jinja2**: Template engine (included with Flask)\n- **Werkzeug**: WSGI utility library (included with Flask)\n- **Click**: Command line interface creation toolkit","size_bytes":8498},"routes.py":{"content":"from flask import jsonify, request, send_file, make_response\nfrom datetime import datetime\nimport uuid\nimport time\nfrom sqlalchemy import or_, func, desc, and_\nimport pandas as pd\nimport io\nimport csv\nfrom werkzeug.utils import secure_filename\n\ndef register_routes(app, db):\n    from flask_models import Article, Supplier, Requestor, PurchaseRequest, PurchaseRequestItem, Reception, Outbound, ActivityLog, User, UserSession\n    import logging\n    import json\n    logger = logging.getLogger(__name__)\n    \n    # Activity logging helper functions\n    def log_activity(action, entity_type, entity_id=None, entity_name=None, old_values=None, new_values=None):\n        \"\"\"Log user activity to the database\"\"\"\n        try:\n            activity_log = ActivityLog(\n                action=action,\n                entity_type=entity_type,\n                entity_id=entity_id,\n                entity_name=entity_name,\n                old_values=json.dumps(old_values) if old_values else None,\n                new_values=json.dumps(new_values) if new_values else None,\n                ip_address=request.remote_addr if request else None,\n                user_agent=request.headers.get('User-Agent') if request else None\n            )\n            db.session.add(activity_log)\n            db.session.commit()\n        except Exception as e:\n            logger.error(f\"Failed to log activity: {str(e)}\")\n            # Don't fail the main operation if logging fails\n            pass\n    \n    def get_entity_name(entity_type, entity_data):\n        \"\"\"Generate a human-readable name for the entity\"\"\"\n        if entity_type == 'suppliers':\n            return entity_data.get('nom', 'Fournisseur inconnu')\n        elif entity_type == 'requestors':\n            prenom = entity_data.get('prenom', '')\n            nom = entity_data.get('nom', '')\n            return f\"{prenom} {nom}\".strip() or 'Demandeur inconnu'\n        elif entity_type == 'articles':\n            return entity_data.get('designation', 'Article inconnu')\n        return str(entity_data.get('id', 'Inconnu'))\n    \n    # Load settings at startup  \n    def load_system_settings():\n        try:\n            import json\n            import os\n            if os.path.exists('settings.json'):\n                with open('settings.json', 'r', encoding='utf-8') as f:\n                    app.config['SYSTEM_SETTINGS'] = json.load(f)\n            else:\n                app.config['SYSTEM_SETTINGS'] = {}\n        except Exception as e:\n            app.logger.warning(f'Could not load system settings: {e}')\n    \n    # Load settings when routes are registered\n    load_system_settings()\n    \n    # Authentication API endpoints\n    @app.route(\"/api/auth/login\", methods=['POST'])\n    def login():\n        try:\n            data = request.get_json()\n            username = data.get('username')\n            password = data.get('password')\n            \n            if not username or not password:\n                return jsonify({'message': 'Nom d\\'utilisateur et mot de passe requis'}), 400\n            \n            # Find user\n            user = User.query.filter_by(username=username).first()\n            \n            if not user or not user.check_password(password):\n                return jsonify({'message': 'Nom d\\'utilisateur ou mot de passe incorrect'}), 401\n            \n            if not user.is_active:\n                return jsonify({'message': 'Compte désactivé'}), 401\n            \n            # Create new session (24-hour duration)\n            session = UserSession.create_session(user.id)\n            db.session.add(session)\n            \n            # Update last login\n            user.last_login = datetime.utcnow()\n            db.session.commit()\n            \n            # Log login activity\n            log_activity('LOGIN', 'users', user.id, user.username)\n            \n            return jsonify({\n                'message': 'Connexion réussie',\n                'sessionToken': session.session_token,\n                'expiresAt': session.expires_at.isoformat(),\n                'user': user.to_dict()\n            })\n            \n        except Exception as e:\n            logger.error(f\"Login error: {str(e)}\")\n            return jsonify({'message': 'Erreur interne du serveur'}), 500\n    \n    @app.route(\"/api/auth/logout\", methods=['POST'])\n    def logout():\n        try:\n            auth_header = request.headers.get('Authorization')\n            if auth_header and auth_header.startswith('Bearer '):\n                token = auth_header.split(' ')[1]\n                session = UserSession.query.filter_by(session_token=token).first()\n                \n                if session:\n                    # Log logout activity\n                    log_activity('LOGOUT', 'users', session.user_id, session.user.username)\n                    \n                    # Delete session\n                    db.session.delete(session)\n                    db.session.commit()\n            \n            return jsonify({'message': 'Déconnexion réussie'})\n            \n        except Exception as e:\n            logger.error(f\"Logout error: {str(e)}\")\n            return jsonify({'message': 'Erreur lors de la déconnexion'}), 500\n    \n    @app.route(\"/api/auth/verify\", methods=['GET'])\n    def verify_session():\n        try:\n            auth_header = request.headers.get('Authorization')\n            if not auth_header or not auth_header.startswith('Bearer '):\n                return jsonify({'message': 'Token manquant'}), 401\n            \n            token = auth_header.split(' ')[1]\n            session = UserSession.query.filter_by(session_token=token).first()\n            \n            if not session or not session.is_valid():\n                return jsonify({'message': 'Session expirée'}), 401\n            \n            # Update last activity\n            session.user.last_login = datetime.utcnow()\n            db.session.commit()\n            \n            return jsonify({\n                'valid': True,\n                'user': session.user.to_dict(),\n                'expiresAt': session.expires_at.isoformat()\n            })\n            \n        except Exception as e:\n            logger.error(f\"Session verification error: {str(e)}\")\n            return jsonify({'message': 'Erreur de vérification'}), 500\n    \n    # Smart UX API endpoints\n    @app.route(\"/api/notifications\", methods=['GET'])\n    def get_notifications():\n        try:\n            # Real-time notifications\n            notifications = []\n            \n            # Check low stock articles\n            low_stock = Article.query.filter(Article.stock_actuel <= Article.stock_minimum).all()\n            if low_stock:\n                notifications.append({\n                    'id': 'low_stock',\n                    'type': 'warning',\n                    'title': 'Stock critique',\n                    'message': f'{len(low_stock)} articles en rupture de stock',\n                    'time': 'Il y a 15 minutes',\n                    'icon': 'fas fa-exclamation',\n                    'color': 'red'\n                })\n            \n            # Check pending requests\n            pending_requests = PurchaseRequest.query.filter_by(statut='En attente').count()\n            if pending_requests > 0:\n                notifications.append({\n                    'id': 'pending_requests',\n                    'type': 'info',\n                    'title': 'Demandes en attente',\n                    'message': f'{pending_requests} demandes nécessitent votre attention',\n                    'time': 'Il y a 30 minutes',\n                    'icon': 'fas fa-shopping-cart',\n                    'color': 'blue'\n                })\n            \n            # Check recent receptions\n            from datetime import datetime, timedelta\n            recent_receptions = Reception.query.filter(\n                Reception.date_reception >= datetime.now() - timedelta(hours=24)\n            ).count()\n            \n            if recent_receptions > 0:\n                notifications.append({\n                    'id': 'recent_receptions',\n                    'type': 'success',\n                    'title': 'Nouvelles réceptions',\n                    'message': f'{recent_receptions} livraisons reçues aujourd\\'hui',\n                    'time': 'Il y a 2 heures',\n                    'icon': 'fas fa-truck',\n                    'color': 'green'\n                })\n            \n            # Add recent activities from activity logs\n            recent_activities = ActivityLog.query.order_by(ActivityLog.created_at.desc()).limit(5).all()\n            for activity in recent_activities:\n                # Calculate time ago\n                time_diff = datetime.now() - activity.created_at\n                if time_diff.seconds < 3600:\n                    time_ago = f'Il y a {time_diff.seconds // 60} minutes'\n                elif time_diff.days == 0:\n                    time_ago = f'Il y a {time_diff.seconds // 3600} heures'\n                else:\n                    time_ago = f'Il y a {time_diff.days} jours'\n                \n                # Get icon based on action\n                action_icons = {\n                    'CREATE': 'fas fa-plus-circle',\n                    'UPDATE': 'fas fa-edit',\n                    'DELETE': 'fas fa-trash',\n                    'EXPORT': 'fas fa-download',\n                    'IMPORT': 'fas fa-upload'\n                }\n                \n                notifications.append({\n                    'id': f'activity_{activity.id}',\n                    'type': 'info',\n                    'title': 'Activité récente',\n                    'message': activity.get_description(),\n                    'time': time_ago,\n                    'icon': action_icons.get(activity.action, 'fas fa-info-circle'),\n                    'color': 'blue'\n                })\n                \n            return jsonify({\n                'notifications': notifications,\n                'count': len(notifications)\n            })\n        except Exception as e:\n            return jsonify({'notifications': [], 'count': 0, 'error': str(e)})\n\n    # Activity Logs API\n    @app.route(\"/api/activity-logs\", methods=['GET'])\n    def get_activity_logs():\n        try:\n            page = request.args.get('page', 1, type=int)\n            limit = request.args.get('limit', 50, type=int)\n            entity_type = request.args.get('entity_type')\n            action = request.args.get('action')\n            \n            # Build query\n            query = ActivityLog.query\n            \n            if entity_type:\n                query = query.filter(ActivityLog.entity_type == entity_type)\n            if action:\n                query = query.filter(ActivityLog.action == action)\n            \n            # Paginate and order by newest first\n            logs = query.order_by(ActivityLog.created_at.desc()).limit(limit).offset((page - 1) * limit).all()\n            total_count = query.count()\n            \n            return jsonify({\n                'logs': [log.to_dict() for log in logs],\n                'totalCount': total_count,\n                'page': page,\n                'limit': limit\n            })\n        except Exception as e:\n            logger.error(f\"Activity logs error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de la récupération des logs: {str(e)}'}), 500\n    \n    @app.route(\"/api/quick-stats\", methods=['GET'])\n    def get_quick_stats():\n        try:\n            stats = {\n                'total_articles': Article.query.count(),\n                'low_stock_count': Article.query.filter(Article.stock_actuel <= Article.stock_minimum).count(),\n                'pending_requests': PurchaseRequest.query.filter_by(statut='En attente').count(),\n                'total_suppliers': Supplier.query.count(),\n                'recent_activity': {\n                    'new_articles_today': 0,  # Would calculate based on creation date\n                    'processed_requests_today': 0,\n                    'received_items_today': 0\n                }\n            }\n            return jsonify(stats)\n        except Exception as e:\n            return jsonify({'error': str(e)})\n    \n    # Articles routes\n    @app.route(\"/api/articles\", methods=['GET'])\n    def get_articles():\n        try:\n            # Get pagination parameters\n            page = request.args.get('page', 1, type=int)\n            per_page = request.args.get('per_page', 20, type=int)  # Default 20 per page\n            \n            # Get search and filter parameters\n            search = request.args.get('search', '', type=str)\n            category = request.args.get('category', 'all', type=str)\n            stock_filter = request.args.get('stock_filter', 'all', type=str)\n            \n            # Build query with filters\n            query = Article.query\n            \n            # Apply search filter\n            if search:\n                search_term = f\"%{search}%\"\n                query = query.filter(\n                    or_(\n                        Article.designation.ilike(search_term),\n                        Article.code_article.ilike(search_term),\n                        Article.reference.ilike(search_term),\n                        Article.marque.ilike(search_term)\n                    )\n                )\n            \n            # Apply category filter\n            if category != 'all':\n                query = query.filter(Article.categorie == category)\n            \n            # Apply stock level filter\n            if stock_filter == 'low':\n                query = query.filter(Article.stock_actuel <= Article.seuil_minimum)\n            elif stock_filter == 'normal':\n                query = query.filter(\n                    and_(\n                        Article.stock_actuel > Article.seuil_minimum,\n                        Article.stock_actuel <= Article.seuil_minimum * 3\n                    )\n                )\n            elif stock_filter == 'high':\n                query = query.filter(Article.stock_actuel > Article.seuil_minimum * 3)\n            \n            # Get paginated results\n            pagination = query.paginate(\n                page=page,\n                per_page=per_page,\n                error_out=False\n            )\n            \n            articles = [article.to_dict() for article in pagination.items]\n            \n            return jsonify({\n                'articles': articles,\n                'pagination': {\n                    'page': page,\n                    'per_page': per_page,\n                    'total': pagination.total,\n                    'pages': pagination.pages,\n                    'has_prev': pagination.has_prev,\n                    'has_next': pagination.has_next,\n                    'prev_num': pagination.prev_num,\n                    'next_num': pagination.next_num\n                }\n            })\n        except Exception as e:\n            logger.error(f\"Error getting articles: {str(e)}\")\n            return jsonify({'message': 'Erreur lors de la récupération des articles'}), 500\n\n    @app.route(\"/api/articles/search\", methods=['GET'])\n    def search_articles():\n        try:\n            query = request.args.get('query', '')\n            if not query or len(query) < 3:\n                return jsonify([])\n            \n            search_term = f'%{query.lower()}%'\n            articles = Article.query.filter(\n                or_(\n                    func.lower(Article.designation).like(search_term),\n                    func.lower(Article.code_article).like(search_term),\n                    func.lower(Article.reference).like(search_term),\n                    func.lower(Article.categorie).like(search_term)\n                )\n            ).limit(10).all()\n            \n            return jsonify([article.to_dict() for article in articles])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la recherche d\\'articles'}), 500\n\n    @app.route(\"/api/search/global\", methods=['GET'])\n    def global_search():\n        try:\n            query = request.args.get('query', '')\n            if not query or len(query) < 2:\n                return jsonify({'results': [], 'totalCount': 0})\n            \n            search_term = f'%{query.lower()}%'\n            results = []\n            \n            # Search Articles\n            articles = Article.query.filter(\n                or_(\n                    func.lower(Article.designation).like(search_term),\n                    func.lower(Article.code_article).like(search_term),\n                    func.lower(Article.reference).like(search_term),\n                    func.lower(Article.categorie).like(search_term)\n                )\n            ).limit(5).all()\n            \n            for article in articles:\n                results.append({\n                    'type': 'article',\n                    'id': article.id,\n                    'title': article.designation,\n                    'subtitle': f'{article.code_article} - {article.categorie}',\n                    'extra': f'Stock: {article.stock_actuel}',\n                    'path': '/articles',\n                    'data': article.to_dict()\n                })\n            \n            # Search Suppliers\n            suppliers = Supplier.query.filter(\n                or_(\n                    func.lower(Supplier.nom).like(search_term),\n                    func.lower(Supplier.contact).like(search_term)\n                )\n            ).limit(5).all()\n            \n            for supplier in suppliers:\n                results.append({\n                    'type': 'supplier',\n                    'id': supplier.id,\n                    'title': supplier.nom,\n                    'subtitle': supplier.contact or 'Pas de contact',\n                    'extra': supplier.adresse or '',\n                    'path': '/suppliers',\n                    'data': supplier.to_dict()\n                })\n            \n            # Search Requestors\n            requestors = Requestor.query.filter(\n                or_(\n                    func.lower(func.concat(Requestor.prenom, ' ', Requestor.nom)).like(search_term),\n                    func.lower(Requestor.departement).like(search_term),\n                    func.lower(Requestor.poste).like(search_term)\n                )\n            ).limit(5).all()\n            \n            for requestor in requestors:\n                results.append({\n                    'type': 'requestor',\n                    'id': requestor.id,\n                    'title': f'{requestor.prenom} {requestor.nom}',\n                    'subtitle': requestor.departement,\n                    'extra': requestor.poste or '',\n                    'path': '/requestors',\n                    'data': requestor.to_dict()\n                })\n            \n            return jsonify({\n                'results': results[:15],\n                'totalCount': len(results),\n                'categories': {\n                    'articles': len([r for r in results if r['type'] == 'article']),\n                    'suppliers': len([r for r in results if r['type'] == 'supplier']),\n                    'requestors': len([r for r in results if r['type'] == 'requestor'])\n                }\n            })\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la recherche globale'}), 500\n\n    @app.route(\"/api/articles/<article_id>\", methods=['GET'])\n    def get_article(article_id):\n        try:\n            article = Article.query.get(article_id)\n            if not article:\n                return jsonify({'message': 'Article non trouvé'}), 404\n            return jsonify(article.to_dict())\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération de l\\'article'}), 500\n\n    @app.route(\"/api/articles\", methods=['POST'])\n    def create_article():\n        try:\n            data = request.get_json()\n            article = Article(\n                code_article=data['codeArticle'],\n                designation=data['designation'],\n                categorie=data['categorie'],\n                marque=data.get('marque'),\n                reference=data.get('reference'),\n                stock_initial=data.get('stockInitial', 0),\n                stock_actuel=data.get('stockInitial', 0),\n                unite=data.get('unite', 'pcs'),\n                prix_unitaire=data.get('prixUnitaire'),\n                seuil_minimum=data.get('seuilMinimum', 10),\n                fournisseur_id=data.get('fournisseurId')\n            )\n            db.session.add(article)\n            db.session.commit()\n            return jsonify(article.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    @app.route(\"/api/articles/<article_id>\", methods=['PUT'])\n    def update_article(article_id):\n        try:\n            article = Article.query.get(article_id)\n            if not article:\n                return jsonify({'message': 'Article non trouvé'}), 404\n            \n            data = request.get_json()\n            for key, value in data.items():\n                if hasattr(article, key.replace('C', '_c').replace('A', '_a').replace('I', '_i').replace('M', '_m').replace('S', '_s').replace('P', '_p').replace('F', '_f').lower()):\n                    setattr(article, key.replace('C', '_c').replace('A', '_a').replace('I', '_i').replace('M', '_m').replace('S', '_s').replace('P', '_p').replace('F', '_f').lower(), value)\n            \n            db.session.commit()\n            return jsonify(article.to_dict())\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la mise à jour', 'error': str(e)}), 400\n\n    @app.route(\"/api/articles/<article_id>\", methods=['DELETE'])\n    def delete_article(article_id):\n        try:\n            article = Article.query.get(article_id)\n            if not article:\n                return jsonify({'message': 'Article non trouvé'}), 404\n            \n            db.session.delete(article)\n            db.session.commit()\n            return '', 204\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la suppression'}), 500\n\n    @app.route(\"/api/articles/bulk-delete\", methods=['POST'])\n    def bulk_delete_articles():\n        try:\n            data = request.get_json()\n            article_ids = data.get('ids', [])\n            \n            if not article_ids:\n                return jsonify({'message': 'Aucun ID fourni'}), 400\n            \n            # Find articles to delete\n            articles = Article.query.filter(Article.id.in_(article_ids)).all()\n            deleted_count = len(articles)\n            \n            # Delete articles\n            for article in articles:\n                db.session.delete(article)\n            \n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='BULK_DELETE',\n                entity_type='articles',\n                entity_name=f'{deleted_count} articles',\n                old_values={'count': deleted_count, 'ids': article_ids}\n            )\n            \n            return jsonify({\n                'message': f'{deleted_count} articles supprimés avec succès',\n                'deletedCount': deleted_count\n            }), 200\n            \n        except Exception as e:\n            db.session.rollback()\n            logger.error(f\"Bulk delete articles error: {str(e)}\")\n            return jsonify({'message': 'Erreur lors de la suppression en masse'}), 500\n\n    @app.route(\"/api/articles/low-stock\", methods=['GET'])\n    def get_low_stock_articles():\n        try:\n            articles = Article.query.filter(Article.stock_actuel <= Article.seuil_minimum).all()\n            return jsonify([article.to_dict() for article in articles])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des articles en stock bas'}), 500\n\n    # Suppliers routes\n    @app.route(\"/api/suppliers\", methods=['GET'])\n    def get_suppliers():\n        try:\n            suppliers = Supplier.query.all()\n            return jsonify([supplier.to_dict() for supplier in suppliers])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des fournisseurs'}), 500\n\n    @app.route(\"/api/suppliers\", methods=['POST'])\n    def create_supplier():\n        try:\n            data = request.get_json()\n            supplier = Supplier(\n                nom=data['nom'],\n                contact=data.get('contact'),\n                telephone=data.get('telephone'),\n                email=data.get('email'),\n                adresse=data.get('adresse'),\n                conditions_paiement=data.get('conditionsPaiement'),\n                delai_livraison=data.get('delaiLivraison')\n            )\n            db.session.add(supplier)\n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='CREATE',\n                entity_type='suppliers',\n                entity_id=supplier.id,\n                entity_name=get_entity_name('suppliers', data),\n                new_values=data\n            )\n            \n            return jsonify(supplier.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    @app.route(\"/api/suppliers/<supplier_id>\", methods=['PUT'])\n    def update_supplier(supplier_id):\n        try:\n            supplier = Supplier.query.get(supplier_id)\n            if not supplier:\n                return jsonify({'message': 'Fournisseur non trouvé'}), 404\n            \n            data = request.get_json()\n            \n            # Store old values for logging\n            old_values = supplier.to_dict()\n            \n            for key, value in data.items():\n                snake_key = key.replace('conditionsPaiement', 'conditions_paiement').replace('delaiLivraison', 'delai_livraison')\n                if hasattr(supplier, snake_key):\n                    setattr(supplier, snake_key, value)\n            \n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='UPDATE',\n                entity_type='suppliers',\n                entity_id=supplier.id,\n                entity_name=get_entity_name('suppliers', data),\n                old_values=old_values,\n                new_values=data\n            )\n            \n            return jsonify(supplier.to_dict())\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la mise à jour', 'error': str(e)}), 400\n\n    @app.route(\"/api/suppliers/<supplier_id>\", methods=['DELETE'])\n    def delete_supplier(supplier_id):\n        try:\n            supplier = Supplier.query.get(supplier_id)\n            if not supplier:\n                return jsonify({'message': 'Fournisseur non trouvé'}), 404\n            \n            # Store values for logging before deletion\n            old_values = supplier.to_dict()\n            entity_name = get_entity_name('suppliers', old_values)\n            \n            db.session.delete(supplier)\n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='DELETE',\n                entity_type='suppliers',\n                entity_id=supplier_id,\n                entity_name=entity_name,\n                old_values=old_values\n            )\n            \n            return '', 204\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la suppression'}), 500\n\n    @app.route(\"/api/suppliers/bulk-delete\", methods=['POST'])\n    def bulk_delete_suppliers():\n        try:\n            data = request.get_json()\n            supplier_ids = data.get('ids', [])\n            \n            if not supplier_ids:\n                return jsonify({'message': 'Aucun ID fourni'}), 400\n            \n            # Find suppliers to delete\n            suppliers = Supplier.query.filter(Supplier.id.in_(supplier_ids)).all()\n            deleted_count = len(suppliers)\n            \n            # Delete suppliers\n            for supplier in suppliers:\n                db.session.delete(supplier)\n            \n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='BULK_DELETE',\n                entity_type='suppliers',\n                entity_name=f'{deleted_count} fournisseurs',\n                old_values={'count': deleted_count, 'ids': supplier_ids}\n            )\n            \n            return jsonify({\n                'message': f'{deleted_count} fournisseurs supprimés avec succès',\n                'deletedCount': deleted_count\n            }), 200\n            \n        except Exception as e:\n            db.session.rollback()\n            logger.error(f\"Bulk delete suppliers error: {str(e)}\")\n            return jsonify({'message': 'Erreur lors de la suppression en masse'}), 500\n\n    # Requestors routes\n    @app.route(\"/api/requestors\", methods=['GET'])\n    def get_requestors():\n        try:\n            requestors = Requestor.query.all()\n            return jsonify([requestor.to_dict() for requestor in requestors])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des demandeurs'}), 500\n\n    @app.route(\"/api/requestors\", methods=['POST'])\n    def create_requestor():\n        try:\n            data = request.get_json()\n            requestor = Requestor(\n                nom=data['nom'],\n                prenom=data['prenom'],\n                departement=data['departement'],\n                poste=data.get('poste'),\n                email=data.get('email'),\n                telephone=data.get('telephone')\n            )\n            db.session.add(requestor)\n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='CREATE',\n                entity_type='requestors',\n                entity_id=requestor.id,\n                entity_name=get_entity_name('requestors', data),\n                new_values=data\n            )\n            \n            return jsonify(requestor.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    @app.route(\"/api/requestors/<requestor_id>\", methods=['PUT'])\n    def update_requestor(requestor_id):\n        try:\n            requestor = Requestor.query.get(requestor_id)\n            if not requestor:\n                return jsonify({'message': 'Demandeur non trouvé'}), 404\n            \n            data = request.get_json()\n            \n            # Store old values for logging\n            old_values = requestor.to_dict()\n            \n            for key, value in data.items():\n                if hasattr(requestor, key):\n                    setattr(requestor, key, value)\n            \n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='UPDATE',\n                entity_type='requestors',\n                entity_id=requestor.id,\n                entity_name=get_entity_name('requestors', data),\n                old_values=old_values,\n                new_values=data\n            )\n            \n            return jsonify(requestor.to_dict())\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la mise à jour', 'error': str(e)}), 400\n\n    @app.route(\"/api/requestors/<requestor_id>\", methods=['DELETE'])\n    def delete_requestor(requestor_id):\n        try:\n            requestor = Requestor.query.get(requestor_id)\n            if not requestor:\n                return jsonify({'message': 'Demandeur non trouvé'}), 404\n            \n            # Store values for logging before deletion\n            old_values = requestor.to_dict()\n            entity_name = get_entity_name('requestors', old_values)\n            \n            db.session.delete(requestor)\n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='DELETE',\n                entity_type='requestors',\n                entity_id=requestor_id,\n                entity_name=entity_name,\n                old_values=old_values\n            )\n            \n            return '', 204\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la suppression'}), 500\n\n    @app.route(\"/api/requestors/bulk-delete\", methods=['POST'])\n    def bulk_delete_requestors():\n        try:\n            data = request.get_json()\n            requestor_ids = data.get('ids', [])\n            \n            if not requestor_ids:\n                return jsonify({'message': 'Aucun ID fourni'}), 400\n            \n            # Find requestors to delete\n            requestors = Requestor.query.filter(Requestor.id.in_(requestor_ids)).all()\n            deleted_count = len(requestors)\n            \n            # Delete requestors\n            for requestor in requestors:\n                db.session.delete(requestor)\n            \n            db.session.commit()\n            \n            # Log activity\n            log_activity(\n                action='BULK_DELETE',\n                entity_type='requestors',\n                entity_name=f'{deleted_count} demandeurs',\n                old_values={'count': deleted_count, 'ids': requestor_ids}\n            )\n            \n            return jsonify({\n                'message': f'{deleted_count} demandeurs supprimés avec succès',\n                'deletedCount': deleted_count\n            }), 200\n            \n        except Exception as e:\n            db.session.rollback()\n            logger.error(f\"Bulk delete requestors error: {str(e)}\")\n            return jsonify({'message': 'Erreur lors de la suppression en masse'}), 500\n\n    # Suppliers Import/Export routes\n    @app.route(\"/api/suppliers/export\", methods=['GET'])\n    def export_suppliers():\n        try:\n            suppliers = Supplier.query.all()\n            \n            # Create DataFrame with supplier data\n            data = []\n            for supplier in suppliers:\n                data.append({\n                    'Nom': supplier.nom,\n                    'Contact': supplier.contact or '',\n                    'Téléphone': supplier.telephone or '',\n                    'Email': supplier.email or '',\n                    'Adresse': supplier.adresse or '',\n                    'Conditions de paiement': supplier.conditions_paiement or '',\n                    'Délai de livraison (jours)': supplier.delai_livraison or ''\n                })\n            \n            df = pd.DataFrame(data)\n            \n            # Create Excel file in memory\n            output = io.BytesIO()\n            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                df.to_excel(writer, sheet_name='Fournisseurs', index=False)\n            \n            output.seek(0)\n            \n            # Create response\n            filename = f\"fournisseurs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n            response = make_response(output.getvalue())\n            response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n            response.headers['Content-Disposition'] = f'attachment; filename={filename}'\n            return response\n            \n        except Exception as e:\n            logger.error(f\"Suppliers export error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de l\\'export: {str(e)}'}), 500\n\n    @app.route(\"/api/suppliers/import\", methods=['POST'])\n    def import_suppliers():\n        try:\n            if 'file' not in request.files:\n                return jsonify({'message': 'Aucun fichier fourni'}), 400\n            \n            file = request.files['file']\n            if file.filename == '' or not file.filename.endswith(('.xlsx', '.xls')):\n                return jsonify({'message': 'Fichier Excel requis (.xlsx ou .xls)'}), 400\n            \n            # Read Excel file\n            df = pd.read_excel(file)\n            \n            # Expected columns\n            expected_columns = ['Nom', 'Contact', 'Téléphone', 'Email', 'Adresse', 'Conditions de paiement', 'Délai de livraison (jours)']\n            \n            # Check if required column exists\n            if 'Nom' not in df.columns:\n                return jsonify({'message': 'Colonne \"Nom\" requise dans le fichier Excel'}), 400\n            \n            imported_count = 0\n            errors = []\n            \n            for index, row in df.iterrows():\n                try:\n                    # Check if supplier name is provided\n                    if pd.isna(row.get('Nom')) or str(row.get('Nom')).strip() == '':\n                        errors.append(f\"Ligne {index + 2}: Nom requis\")\n                        continue\n                    \n                    # Check if supplier already exists\n                    existing = Supplier.query.filter_by(nom=str(row['Nom']).strip()).first()\n                    if existing:\n                        errors.append(f\"Ligne {index + 2}: Fournisseur '{row['Nom']}' existe déjà\")\n                        continue\n                    \n                    # Create new supplier\n                    supplier = Supplier(\n                        nom=str(row['Nom']).strip(),\n                        contact=str(row.get('Contact', '')).strip() if not pd.isna(row.get('Contact')) else None,\n                        telephone=str(row.get('Téléphone', '')).strip() if not pd.isna(row.get('Téléphone')) else None,\n                        email=str(row.get('Email', '')).strip() if not pd.isna(row.get('Email')) else None,\n                        adresse=str(row.get('Adresse', '')).strip() if not pd.isna(row.get('Adresse')) else None,\n                        conditions_paiement=str(row.get('Conditions de paiement', '')).strip() if not pd.isna(row.get('Conditions de paiement')) else None,\n                        delai_livraison=int(row.get('Délai de livraison (jours)', 0)) if not pd.isna(row.get('Délai de livraison (jours)')) and str(row.get('Délai de livraison (jours)')).strip() != '' else None\n                    )\n                    \n                    db.session.add(supplier)\n                    imported_count += 1\n                    \n                except Exception as e:\n                    errors.append(f\"Ligne {index + 2}: {str(e)}\")\n            \n            db.session.commit()\n            \n            # Log activity\n            if imported_count > 0:\n                log_activity(\n                    action='IMPORT',\n                    entity_type='suppliers',\n                    entity_name=f'{imported_count} fournisseurs'\n                )\n            \n            return jsonify({\n                'message': f'{imported_count} fournisseur(s) importé(s) avec succès',\n                'imported': imported_count,\n                'errors': errors\n            })\n            \n        except Exception as e:\n            db.session.rollback()\n            logger.error(f\"Suppliers import error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de l\\'import: {str(e)}'}), 500\n\n    # Requestors Import/Export routes\n    @app.route(\"/api/requestors/export\", methods=['GET'])\n    def export_requestors():\n        try:\n            requestors = Requestor.query.all()\n            \n            # Create DataFrame with requestor data\n            data = []\n            for requestor in requestors:\n                data.append({\n                    'Prénom': requestor.prenom,\n                    'Nom': requestor.nom,\n                    'Département': requestor.departement,\n                    'Poste': requestor.poste or '',\n                    'Email': requestor.email or '',\n                    'Téléphone': requestor.telephone or ''\n                })\n            \n            df = pd.DataFrame(data)\n            \n            # Create Excel file in memory\n            output = io.BytesIO()\n            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                df.to_excel(writer, sheet_name='Demandeurs', index=False)\n            \n            output.seek(0)\n            \n            # Log activity\n            log_activity(\n                action='EXPORT',\n                entity_type='requestors',\n                entity_name=f'{len(requestors)} demandeurs'\n            )\n            \n            # Create response\n            filename = f\"demandeurs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n            response = make_response(output.getvalue())\n            response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n            response.headers['Content-Disposition'] = f'attachment; filename={filename}'\n            return response\n            \n        except Exception as e:\n            logger.error(f\"Requestors export error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de l\\'export: {str(e)}'}), 500\n\n    @app.route(\"/api/requestors/import\", methods=['POST'])\n    def import_requestors():\n        try:\n            if 'file' not in request.files:\n                return jsonify({'message': 'Aucun fichier fourni'}), 400\n            \n            file = request.files['file']\n            if file.filename == '' or not file.filename.endswith(('.xlsx', '.xls')):\n                return jsonify({'message': 'Fichier Excel requis (.xlsx ou .xls)'}), 400\n            \n            # Read Excel file\n            df = pd.read_excel(file)\n            \n            # Check required columns\n            required_columns = ['Prénom', 'Nom', 'Département']\n            missing_columns = [col for col in required_columns if col not in df.columns]\n            \n            if missing_columns:\n                return jsonify({'message': f'Colonnes requises manquantes: {\", \".join(missing_columns)}'}), 400\n            \n            imported_count = 0\n            errors = []\n            \n            for index, row in df.iterrows():\n                try:\n                    # Check required fields\n                    prenom = str(row.get('Prénom', '')).strip() if not pd.isna(row.get('Prénom')) else ''\n                    nom = str(row.get('Nom', '')).strip() if not pd.isna(row.get('Nom')) else ''\n                    departement = str(row.get('Département', '')).strip() if not pd.isna(row.get('Département')) else ''\n                    \n                    if not prenom or not nom or not departement:\n                        errors.append(f\"Ligne {index + 2}: Prénom, Nom et Département requis\")\n                        continue\n                    \n                    # Check if requestor already exists\n                    existing = Requestor.query.filter_by(nom=nom, prenom=prenom, departement=departement).first()\n                    if existing:\n                        errors.append(f\"Ligne {index + 2}: Demandeur '{prenom} {nom}' du département '{departement}' existe déjà\")\n                        continue\n                    \n                    # Create new requestor\n                    requestor = Requestor(\n                        prenom=prenom,\n                        nom=nom,\n                        departement=departement,\n                        poste=str(row.get('Poste', '')).strip() if not pd.isna(row.get('Poste')) else None,\n                        email=str(row.get('Email', '')).strip() if not pd.isna(row.get('Email')) else None,\n                        telephone=str(row.get('Téléphone', '')).strip() if not pd.isna(row.get('Téléphone')) else None\n                    )\n                    \n                    db.session.add(requestor)\n                    imported_count += 1\n                    \n                except Exception as e:\n                    errors.append(f\"Ligne {index + 2}: {str(e)}\")\n            \n            db.session.commit()\n            \n            # Log activity\n            if imported_count > 0:\n                log_activity(\n                    action='IMPORT',\n                    entity_type='requestors',\n                    entity_name=f'{imported_count} demandeurs'\n                )\n            \n            return jsonify({\n                'message': f'{imported_count} demandeur(s) importé(s) avec succès',\n                'imported': imported_count,\n                'errors': errors\n            })\n            \n        except Exception as e:\n            db.session.rollback()\n            logger.error(f\"Requestors import error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de l\\'import: {str(e)}'}), 500\n\n    # Purchase Requests routes\n    @app.route(\"/api/purchase-requests\", methods=['GET'])\n    def get_purchase_requests():\n        try:\n            requests = PurchaseRequest.query.all()\n            return jsonify([request.to_dict() for request in requests])\n        except Exception as e:\n            print(f\"Purchase requests error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de la récupération des demandes d\\'achat: {str(e)}'}), 500\n\n    @app.route(\"/api/purchase-requests\", methods=['POST'])\n    def create_purchase_request():\n        try:\n            data = request.get_json()\n            \n            # Generate request number\n            count = PurchaseRequest.query.count() + 1\n            numero_demande = f\"DA-{datetime.utcnow().strftime('%Y')}-{count:04d}\"\n            \n            # Calculate total\n            total_estime = sum(item['quantiteDemandee'] * item['prixUnitaireEstime'] \n                             for item in data.get('articles', []))\n            \n            purchase_request = PurchaseRequest(\n                numero_demande=numero_demande,\n                date_demande=datetime.fromisoformat(data['dateDemande'].replace('Z', '+00:00')) if 'dateDemande' in data else datetime.utcnow(),\n                requestor_id=data['requestorId'],\n                observations=data.get('observations'),\n                statut=data.get('statut', 'en_attente'),\n                total_articles=len(data.get('articles', [])),\n                total_estime=total_estime\n            )\n            db.session.add(purchase_request)\n            db.session.flush()  # Get the ID\n            \n            # Add articles\n            for article_data in data.get('articles', []):\n                sous_total = article_data['quantiteDemandee'] * article_data['prixUnitaireEstime']\n                \n                item = PurchaseRequestItem(\n                    purchase_request_id=purchase_request.id,\n                    article_id=article_data['articleId'],\n                    supplier_id=article_data.get('supplierId'),\n                    quantite_demandee=article_data['quantiteDemandee'],\n                    prix_unitaire_estime=article_data['prixUnitaireEstime'],\n                    sous_total=sous_total\n                )\n                db.session.add(item)\n            \n            db.session.commit()\n            return jsonify(purchase_request.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    @app.route(\"/api/purchase-requests/<request_id>\", methods=['PUT'])\n    def update_purchase_request(request_id):\n        try:\n            purchase_request = PurchaseRequest.query.get(request_id)\n            if not purchase_request:\n                return jsonify({'message': 'Demande non trouvée'}), 404\n            \n            data = request.get_json()\n            \n            # Handle status updates\n            if 'statut' in data:\n                purchase_request.statut = data['statut']\n            \n            if 'observations' in data:\n                purchase_request.observations = data['observations']\n            \n            # If updating articles, delete existing and recreate\n            if 'articles' in data:\n                # Delete existing items\n                PurchaseRequestItem.query.filter_by(purchase_request_id=request_id).delete()\n                \n                # Add new articles\n                total_estime = 0\n                for article_data in data['articles']:\n                    sous_total = article_data['quantiteDemandee'] * article_data['prixUnitaireEstime']\n                    total_estime += sous_total\n                    \n                    item = PurchaseRequestItem(\n                        purchase_request_id=request_id,\n                        article_id=article_data['articleId'],\n                        supplier_id=article_data.get('supplierId'),\n                        quantite_demandee=article_data['quantiteDemandee'],\n                        prix_unitaire_estime=article_data['prixUnitaireEstime'],\n                        sous_total=sous_total\n                    )\n                    db.session.add(item)\n                \n                purchase_request.total_articles = len(data['articles'])\n                purchase_request.total_estime = total_estime\n            \n            db.session.commit()\n            return jsonify(purchase_request.to_dict())\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la mise à jour', 'error': str(e)}), 400\n\n    @app.route(\"/api/purchase-requests/<request_id>\", methods=['DELETE'])\n    def delete_purchase_request(request_id):\n        try:\n            purchase_request = PurchaseRequest.query.get(request_id)\n            if not purchase_request:\n                return jsonify({'message': 'Demande non trouvée'}), 404\n            \n            # Also delete related items\n            PurchaseRequestItem.query.filter_by(purchase_request_id=request_id).delete()\n            db.session.delete(purchase_request)\n            db.session.commit()\n            return '', 204\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Erreur lors de la suppression'}), 500\n\n    # Purchase Request Items routes\n    @app.route(\"/api/purchase-request-items\", methods=['POST'])\n    def create_purchase_request_item():\n        try:\n            data = request.get_json()\n            item = PurchaseRequestItem(\n                purchase_request_id=data['purchaseRequestId'],\n                article_id=data['articleId'],\n                quantite_demandee=data['quantiteDemandee'],\n                supplier_id=data.get('supplierId'),\n                prix_unitaire_estime=data.get('prixUnitaireEstime'),\n                observations=data.get('observations')\n            )\n            db.session.add(item)\n            \n            # Update total articles count\n            item_count = PurchaseRequestItem.query.filter_by(purchase_request_id=data['purchaseRequestId']).count() + 1\n            purchase_request = PurchaseRequest.query.get(data['purchaseRequestId'])\n            if purchase_request:\n                purchase_request.total_articles = item_count\n            \n            db.session.commit()\n            return jsonify(item.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    @app.route(\"/api/purchase-requests/<request_id>/items\", methods=['GET'])\n    def get_purchase_request_items(request_id):\n        try:\n            items = PurchaseRequestItem.query.filter_by(purchase_request_id=request_id).all()\n            return jsonify([item.to_dict() for item in items])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des éléments'}), 500\n    \n    # Convert Purchase Request to Reception\n    @app.route(\"/api/purchase-requests/<request_id>/convert-reception\", methods=['POST'])\n    def convert_purchase_request_to_reception(request_id):\n        try:\n            data = request.get_json()\n            \n            # Get purchase request and items\n            purchase_request = PurchaseRequest.query.get_or_404(request_id)\n            items = PurchaseRequestItem.query.filter_by(purchase_request_id=request_id).all()\n            \n            # Create reception records for each article\n            receptions_created = []\n            \n            for reception_article in data.get('articles', []):\n                # Find corresponding item\n                item = next((i for i in items if i.id == reception_article['itemId']), None)\n                if not item:\n                    continue\n                \n                # Get supplier_id from form data first, then from item, then from article's default supplier\n                supplier_id = reception_article.get('supplierId') or item.supplier_id\n                if not supplier_id:\n                    # Fallback: get from article's default supplier\n                    article = Article.query.get(item.article_id)\n                    if article and article.fournisseur_id:\n                        supplier_id = article.fournisseur_id\n                \n                # If no supplier found, create with null supplier (will be updated later)\n                if not supplier_id:\n                    # Try to get the default supplier from the first available supplier\n                    default_supplier = Supplier.query.first()\n                    if default_supplier:\n                        supplier_id = default_supplier.id\n                    else:\n                        return jsonify({'message': f'Aucun fournisseur disponible dans le système pour l\\'article {item.article.designation if item.article else \"inconnu\"}'}), 400\n                \n                # Create reception record\n                reception = Reception(\n                    date_reception=datetime.strptime(data['dateReception'], '%Y-%m-%d').date(),\n                    supplier_id=supplier_id,\n                    article_id=item.article_id,\n                    quantite_recue=reception_article['quantiteRecue'],\n                    prix_unitaire=reception_article['prixUnitaire'],\n                    numero_bon_livraison=data.get('numeroBonLivraison'),\n                    observations=data.get('observations', f\"Réception pour demande d'achat #{purchase_request.id[:8]}\")\n                )\n                db.session.add(reception)\n                \n                # Update article stock\n                article = Article.query.get(item.article_id)\n                if article:\n                    article.stock_actuel += reception_article['quantiteRecue']\n                \n                receptions_created.append(reception)\n            \n            db.session.commit()\n            \n            return jsonify({\n                'message': f'{len(receptions_created)} réceptions créées avec succès',\n                'receptions': [r.to_dict() for r in receptions_created]\n            }), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': f'Erreur lors de la conversion: {str(e)}'}), 500\n\n    # Complete purchase request creation\n    @app.route(\"/api/purchase-requests/complete\", methods=['POST'])\n    def create_complete_purchase_request():\n        try:\n            data = request.get_json()\n            \n            # Create purchase request header\n            purchase_request = PurchaseRequest(\n                date_demande=datetime.fromisoformat(data['dateDemande'].replace('Z', '+00:00')) if 'dateDemande' in data else datetime.utcnow(),\n                requestor_id=data['requestorId'],\n                observations=data.get('observations'),\n                total_articles=len(data['items']),\n                statut='en_attente'\n            )\n            db.session.add(purchase_request)\n            db.session.flush()  # Get the ID\n            \n            # Create items\n            items = []\n            for item_data in data['items']:\n                item = PurchaseRequestItem(\n                    purchase_request_id=purchase_request.id,\n                    article_id=item_data['articleId'],\n                    quantite_demandee=item_data['quantiteDemandee'],\n                    supplier_id=item_data.get('supplierId'),\n                    prix_unitaire_estime=item_data.get('prixUnitaireEstime'),\n                    observations=item_data.get('observations')\n                )\n                db.session.add(item)\n                items.append(item)\n            \n            db.session.commit()\n            \n            return jsonify({\n                **purchase_request.to_dict(),\n                'items': [item.to_dict() for item in items]\n            }), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    # Reception routes\n    @app.route(\"/api/receptions\", methods=['GET'])\n    def get_receptions():\n        try:\n            receptions = Reception.query.all()\n            return jsonify([reception.to_dict() for reception in receptions])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des réceptions'}), 500\n\n    @app.route(\"/api/receptions\", methods=['POST'])\n    def create_reception():\n        try:\n            data = request.get_json()\n            reception = Reception(\n                date_reception=datetime.fromisoformat(data['dateReception'].replace('Z', '+00:00')) if 'dateReception' in data else datetime.utcnow(),\n                supplier_id=data['supplierId'],\n                article_id=data['articleId'],\n                quantite_recue=data['quantiteRecue'],\n                prix_unitaire=data.get('prixUnitaire'),\n                numero_bon_livraison=data.get('numeroBonLivraison'),\n                observations=data.get('observations')\n            )\n            db.session.add(reception)\n            \n            # Update article stock\n            article = Article.query.get(data['articleId'])\n            if article:\n                article.stock_actuel += data['quantiteRecue']\n            \n            db.session.commit()\n            return jsonify(reception.to_dict()), 201\n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': 'Données invalides', 'error': str(e)}), 400\n\n    # Outbound routes\n    @app.route(\"/api/outbounds\", methods=['GET'])\n    def get_outbounds():\n        try:\n            outbounds = Outbound.query.all()\n            return jsonify([outbound.to_dict() for outbound in outbounds])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des sorties'}), 500\n\n    @app.route(\"/api/outbounds\", methods=['POST'])\n    def create_outbound():\n        try:\n            data = request.get_json()\n            \n            # Generate a unique transaction number\n            numero_sortie = f\"OUT-{datetime.now().strftime('%Y%m%d')}-{str(int(time.time()))[-6:]}\"\n            \n            # Handle multi-article outbound transaction\n            articles_data = data.get('articles', [])\n            if not articles_data:\n                return jsonify({'message': 'Aucun article spécifié'}), 400\n            \n            created_outbounds = []\n            \n            for article_item in articles_data:\n                outbound = Outbound(\n                    numero_sortie=numero_sortie,\n                    date_sortie=datetime.now(),\n                    requestor_id=data.get('requestorId'),\n                    article_id=article_item['articleId'],\n                    quantite_sortie=article_item['quantiteSortie'],\n                    motif_sortie=data['motifSortie'],\n                    observations=data.get('observations', '')\n                )\n                \n                db.session.add(outbound)\n                created_outbounds.append(outbound)\n                \n                # Update article stock\n                article = Article.query.get(article_item['articleId'])\n                if article:\n                    article.stock_actuel -= article_item['quantiteSortie']\n                    if article.stock_actuel < 0:\n                        article.stock_actuel = 0\n            \n            db.session.commit()\n            return jsonify({\n                'message': 'Sortie créée avec succès',\n                'numeroSortie': numero_sortie,\n                'outbounds': [outbound.to_dict() for outbound in created_outbounds]\n            }), 201\n            \n        except Exception as e:\n            db.session.rollback()\n            return jsonify({'message': f'Erreur lors de la création de la sortie: {str(e)}'}), 500\n\n    # Analytics routes\n    @app.route(\"/api/analytics/overview\", methods=['GET'])\n    def get_analytics_overview():\n        try:\n            total_articles = Article.query.count()\n            total_suppliers = Supplier.query.count()\n            total_requests = PurchaseRequest.query.count()\n            low_stock_count = Article.query.filter(Article.stock_actuel <= Article.seuil_minimum).count()\n            \n            return jsonify({\n                'totalArticles': total_articles,\n                'totalSuppliers': total_suppliers,\n                'totalRequests': total_requests,\n                'lowStockCount': low_stock_count\n            })\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des analytics'}), 500\n\n    # Dashboard stats endpoint  \n    @app.route(\"/api/dashboard/stats\", methods=['GET'])\n    def get_dashboard_stats():\n        try:\n            # Basic counts\n            total_articles = Article.query.count()\n            total_suppliers = Supplier.query.count()\n            total_requestors = Requestor.query.count()\n            total_requests = PurchaseRequest.query.count()\n            total_receptions = Reception.query.count()\n            total_outbounds = Outbound.query.count()\n            \n            # Low stock count (articles at or below minimum threshold)\n            low_stock_count = Article.query.filter(Article.stock_actuel <= Article.seuil_minimum).count()\n            \n            # Pending purchase requests\n            pending_requests = PurchaseRequest.query.filter(PurchaseRequest.statut == 'en_attente').count()\n            \n            # Calculate total stock value\n            articles = Article.query.all()\n            stock_value = 0\n            for article in articles:\n                if article.stock_actuel > 0 and article.prix_unitaire:\n                    stock_value += article.stock_actuel * article.prix_unitaire\n            \n            # Get purchase request status distribution for charts\n            status_counts = {\n                'en_attente': PurchaseRequest.query.filter(PurchaseRequest.statut == 'en_attente').count(),\n                'approuve': PurchaseRequest.query.filter(PurchaseRequest.statut == 'approuve').count(),\n                'refuse': PurchaseRequest.query.filter(PurchaseRequest.statut == 'refuse').count(),\n                'commande': PurchaseRequest.query.filter(PurchaseRequest.statut == 'commande').count(),\n                'recu': PurchaseRequest.query.filter(PurchaseRequest.statut == 'recu').count()\n            }\n            \n            # Get recent activity\n            recent_receptions = Reception.query.order_by(desc(Reception.date_reception)).limit(5).all()\n            recent_outbounds = Outbound.query.order_by(desc(Outbound.date_sortie)).limit(5).all()\n            \n            return jsonify({\n                'totalArticles': total_articles,\n                'totalSuppliers': total_suppliers,\n                'totalRequestors': total_requestors,\n                'totalRequests': total_requests,\n                'totalReceptions': total_receptions,\n                'totalOutbounds': total_outbounds,\n                'lowStock': low_stock_count,\n                'pendingRequests': pending_requests,\n                'stockValue': stock_value,\n                'statusCounts': status_counts,\n                'recentReceptions': [reception.to_dict() for reception in recent_receptions],\n                'recentOutbounds': [outbound.to_dict() for outbound in recent_outbounds]\n            })\n        except Exception as e:\n            print(f\"Dashboard stats error: {str(e)}\")\n            return jsonify({'message': f'Erreur lors de la récupération des statistiques: {str(e)}'}), 500\n\n    # Stock status analytics\n    @app.route(\"/api/stock-status/analytics\", methods=['GET'])\n    def get_stock_status_analytics():\n        try:\n            articles = Article.query.all()\n            \n            # Categorize by stock levels\n            critical = []  # 0 stock\n            low = []       # below minimum\n            medium = []    # 1-2x minimum\n            good = []      # above 2x minimum\n            \n            for article in articles:\n                seuil = article.seuil_minimum or 10\n                if article.stock_actuel == 0:\n                    critical.append(article.to_dict())\n                elif article.stock_actuel <= seuil:\n                    low.append(article.to_dict())\n                elif article.stock_actuel <= seuil * 2:\n                    medium.append(article.to_dict())\n                else:\n                    good.append(article.to_dict())\n            \n            return jsonify({\n                'critical': critical,\n                'low': low,\n                'medium': medium,\n                'good': good,\n                'summary': {\n                    'critical_count': len(critical),\n                    'low_count': len(low),\n                    'medium_count': len(medium),\n                    'good_count': len(good),\n                    'total_count': len(articles)\n                }\n            })\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération du statut stock'}), 500\n\n    # Purchase follow-up analytics\n    @app.route(\"/api/purchase-follow/status\", methods=['GET'])\n    def get_purchase_follow_status():\n        try:\n            pending = PurchaseRequest.query.filter_by(statut='en_attente').all()\n            approved = PurchaseRequest.query.filter_by(statut='approuve').all()\n            ordered = PurchaseRequest.query.filter_by(statut='commande').all()\n            refused = PurchaseRequest.query.filter_by(statut='refuse').all()\n            \n            return jsonify({\n                'pending': [req.to_dict() for req in pending],\n                'approved': [req.to_dict() for req in approved],\n                'ordered': [req.to_dict() for req in ordered],\n                'refused': [req.to_dict() for req in refused]\n            })\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération du suivi'}), 500\n\n    # Reports endpoints\n    @app.route(\"/api/reports/stock\", methods=['GET'])\n    def generate_stock_report():\n        try:\n            articles = Article.query.all()\n            report_data = {\n                'timestamp': datetime.utcnow().isoformat(),\n                'total_articles': len(articles),\n                'articles': [article.to_dict() for article in articles],\n                'summary': {\n                    'total_value': sum(article.prix_unitaire * article.stock_actuel for article in articles if article.prix_unitaire),\n                    'low_stock_count': len([a for a in articles if a.stock_actuel <= (a.seuil_minimum or 10)])\n                }\n            }\n            return jsonify(report_data)\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la génération du rapport'}), 500\n\n    # Settings endpoints\n    @app.route(\"/api/settings\", methods=['GET'])\n    def get_settings():\n        try:\n            # Load settings from file or database\n            import json\n            import os\n            settings_file = 'settings.json'\n            \n            if os.path.exists(settings_file):\n                with open(settings_file, 'r', encoding='utf-8') as f:\n                    settings = json.load(f)\n            else:\n                # Default settings\n                settings = {\n                    'currency': 'MAD',\n                    'language': 'fr',\n                    'dateFormat': 'dd/mm/yyyy',\n                    'theme': 'light',\n                    'notifications': {\n                        'stock': True,\n                        'requests': True,\n                        'deliveries': True,\n                        'reports': False\n                    },\n                    'paginationLimit': 50,\n                    'autoRefresh': True,\n                    'security': {\n                        'passwordLength': 8,\n                        'passwordExpiry': 90,\n                        'requireUppercase': True,\n                        'requireNumbers': True,\n                        'requireSpecial': False,\n                        'sessionTimeout': 30,\n                        'autoLogout': True,\n                        'logLogins': True,\n                        'logDataChanges': True,\n                        'logExports': False\n                    },\n                    'backup': {\n                        'frequency': 'daily',\n                        'time': '02:00',\n                        'retention': 7\n                    },\n                    'integrations': {\n                        'apiEnabled': False,\n                        'scannerEnabled': False,\n                        'scannerType': 'camera'\n                    },\n                    'advanced': {\n                        'dbPoolSize': 10,\n                        'dbTimeout': 30,\n                        'dbAutoVacuum': False,\n                        'debugMode': False,\n                        'smartCache': True,\n                        'strictValidation': False,\n                        'maintenanceMode': False,\n                        'searchLimit': 500,\n                        'cacheDuration': 15,\n                        'batchSize': 100,\n                        'metricsCpu': True,\n                        'metricsMemory': True,\n                        'metricsDisk': False,\n                        'alertSlowQueries': False,\n                        'alertHighCpu': False,\n                        'alertErrors': False\n                    },\n                    'customization': {\n                        'primaryColor': '#003d9d',\n                        'secondaryColor': '#6B7280',\n                        'navStyle': 'top',\n                        'displayDensity': 'comfortable',\n                        'roundedCorners': True,\n                        'companyName': 'StockCéramique',\n                        'companyTagline': '',\n                        'moduleAnalytics': True,\n                        'moduleQr': True,\n                        'moduleExport': True,\n                        'moduleWorkflow': False,\n                        'moduleSmartAlerts': False,\n                        'moduleOffline': False,\n                        'widgetStats': True,\n                        'widgetCharts': True,\n                        'widgetAlerts': True,\n                        'widgetRecent': True,\n                        'widgetRequests': False,\n                        'dashboardLayout': 'masonry'\n                    }\n                }\n                \n            return jsonify(settings)\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors du chargement des paramètres'}), 500\n    \n    @app.route(\"/api/settings\", methods=['POST'])\n    def save_settings():\n        try:\n            import json\n            settings = request.get_json()\n            \n            # Save settings to file\n            with open('settings.json', 'w', encoding='utf-8') as f:\n                json.dump(settings, f, indent=2, ensure_ascii=False)\n                \n            return jsonify({'message': 'Paramètres sauvegardés avec succès'})\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de la sauvegarde: {str(e)}'}), 500\n    \n    @app.route(\"/api/settings/backup\", methods=['POST'])\n    def create_backup():\n        try:\n            import json\n            import shutil\n            from datetime import datetime\n            \n            # Create backup of database and settings\n            backup_name = f\"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n            backup_dir = f\"backups/{backup_name}\"\n            \n            import os\n            os.makedirs(backup_dir, exist_ok=True)\n            \n            # Copy database file\n            if os.path.exists('instance/stockceramique.db'):\n                shutil.copy2('instance/stockceramique.db', f\"{backup_dir}/database.db\")\n            \n            # Copy settings\n            if os.path.exists('settings.json'):\n                shutil.copy2('settings.json', f\"{backup_dir}/settings.json\")\n                \n            # Create backup info file\n            backup_info = {\n                'name': backup_name,\n                'created': datetime.now().isoformat(),\n                'type': 'manual',\n                'size': 0  # Would calculate actual size\n            }\n            \n            with open(f\"{backup_dir}/info.json\", 'w') as f:\n                json.dump(backup_info, f, indent=2)\n                \n            return jsonify({\n                'message': 'Sauvegarde créée avec succès',\n                'backup': backup_info\n            })\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de la création de sauvegarde: {str(e)}'}), 500\n    \n    @app.route(\"/api/settings/system-info\", methods=['GET'])\n    def get_system_info():\n        try:\n            import psutil\n            import os\n            from datetime import datetime\n            \n            # Get system metrics\n            system_info = {\n                'cpu': {\n                    'usage': psutil.cpu_percent(interval=1),\n                    'cores': psutil.cpu_count()\n                },\n                'memory': {\n                    'total': psutil.virtual_memory().total,\n                    'used': psutil.virtual_memory().used,\n                    'percent': psutil.virtual_memory().percent\n                },\n                'disk': {\n                    'total': psutil.disk_usage('.').total,\n                    'used': psutil.disk_usage('.').used,\n                    'percent': (psutil.disk_usage('.').used / psutil.disk_usage('.').total) * 100\n                },\n                'database': {\n                    'size': os.path.getsize('instance/stockceramique.db') if os.path.exists('instance/stockceramique.db') else 0,\n                    'articles': Article.query.count(),\n                    'suppliers': Supplier.query.count(),\n                    'requests': PurchaseRequest.query.count()\n                },\n                'uptime': datetime.now().isoformat(),\n                'version': '1.0.0'\n            }\n            \n            return jsonify(system_info)\n        except ImportError:\n            # If psutil is not available, return basic info\n            return jsonify({\n                'message': 'Informations système limitées',\n                'database': {\n                    'articles': Article.query.count(),\n                    'suppliers': Supplier.query.count(),\n                    'requests': PurchaseRequest.query.count()\n                },\n                'version': '1.0.0'\n            })\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de la récupération des informations système: {str(e)}'}), 500\n\n    @app.route(\"/api/settings/categories\", methods=['GET'])\n    def get_categories():\n        try:\n            categories = db.session.query(Article.categorie).distinct().all()\n            return jsonify([cat[0] for cat in categories if cat[0]])\n        except Exception as e:\n            return jsonify({'message': 'Erreur lors de la récupération des catégories'}), 500\n            \n    @app.route(\"/api/settings/categories\", methods=['POST'])\n    def add_category():\n        try:\n            data = request.get_json()\n            category_name = data.get('name')\n            \n            if not category_name:\n                return jsonify({'message': 'Nom de catégorie requis'}), 400\n                \n            # Check if category already exists\n            existing = db.session.query(Article.categorie).filter_by(categorie=category_name).first()\n            if existing:\n                return jsonify({'message': 'Cette catégorie existe déjà'}), 400\n                \n            return jsonify({'message': 'Catégorie ajoutée avec succès'})\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'ajout de catégorie: {str(e)}'}), 500\n\n    @app.route(\"/api/settings/units\", methods=['POST'])\n    def add_unit():\n        try:\n            data = request.get_json()\n            code = data.get('code')\n            description = data.get('description')\n            \n            if not code or not description:\n                return jsonify({'message': 'Code et description requis'}), 400\n                \n            # This would typically save to a units configuration table\n            return jsonify({'message': 'Unité ajoutée avec succès'})\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'ajout d\\'unité: {str(e)}'}), 500\n    \n    @app.route(\"/api/settings/departments\", methods=['POST'])\n    def add_department():\n        try:\n            data = request.get_json()\n            department_name = data.get('name')\n            \n            if not department_name:\n                return jsonify({'message': 'Nom de département requis'}), 400\n                \n            # This would save to departments table or update requestors config\n            return jsonify({'message': 'Département ajouté avec succès'})\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'ajout de département: {str(e)}'}), 500\n    \n    @app.route(\"/api/profile\", methods=['GET'])\n    def get_profile():\n        try:\n            # Mock user profile data - in real app would get from session/auth\n            profile = {\n                'firstName': 'Admin',\n                'lastName': 'User',\n                'email': 'admin@stockceramique.com',\n                'phone': '+212 123 456 789',\n                'position': 'Gestionnaire Inventaire',\n                'department': 'administration',\n                'address': '123 Rue de l\\'Industrie',\n                'city': 'Casablanca',\n                'postalCode': '20000',\n                'avatar': None,\n                'lastLogin': '2024-08-23T09:15:00',\n                'preferences': {\n                    'language': 'fr',\n                    'timezone': 'Africa/Casablanca',\n                    'defaultPage': '/',\n                    'pagination': 50,\n                    'notifications': {\n                        'email': True,\n                        'push': False,\n                        'weekly': True\n                    }\n                },\n                'statistics': {\n                    'requestsCreated': 127,\n                    'articlesAdded': 89,\n                    'receptionsProcessed': 45,\n                    'loginCount': 156\n                }\n            }\n            return jsonify(profile)\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors du chargement du profil: {str(e)}'}), 500\n    \n    @app.route(\"/api/profile\", methods=['POST'])\n    def save_profile():\n        try:\n            profile_data = request.get_json()\n            # In real app, would save to user database\n            return jsonify({'message': 'Profil sauvegardé avec succès'})\n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de la sauvegarde du profil: {str(e)}'}), 500\n\n    # Bulk Import/Export Articles\n    @app.route(\"/api/articles/export\", methods=['GET'])\n    def export_articles():\n        try:\n            # Get export format from query parameters\n            format_type = request.args.get('format', 'csv')\n            \n            # Get all articles\n            articles = Article.query.all()\n            \n            # Convert to list of dictionaries\n            data = []\n            for article in articles:\n                data.append({\n                    'Code Article': article.code_article,\n                    'Désignation': article.designation,\n                    'Catégorie': article.categorie,\n                    'Marque': article.marque or '',\n                    'Référence': article.reference or '',\n                    'Stock Initial': article.stock_initial,\n                    'Stock Actuel': article.stock_actuel,\n                    'Unité': article.unite,\n                    'Prix Unitaire': float(article.prix_unitaire) if article.prix_unitaire else 0,\n                    'Seuil Minimum': article.seuil_minimum,\n                    'Fournisseur ID': article.fournisseur_id or '',\n                    'Date Création': article.created_at.strftime('%Y-%m-%d %H:%M:%S') if article.created_at else ''\n                })\n            \n            # Create dataframe\n            df = pd.DataFrame(data)\n            \n            if format_type == 'excel':\n                # Export to Excel\n                output = io.BytesIO()\n                with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                    df.to_excel(writer, sheet_name='Articles', index=False)\n                output.seek(0)\n                \n                response = make_response(output.getvalue())\n                response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n                response.headers['Content-Disposition'] = f'attachment; filename=articles_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n                return response\n            else:\n                # Export to CSV\n                output = io.StringIO()\n                df.to_csv(output, index=False, encoding='utf-8')\n                output.seek(0)\n                \n                response = make_response(output.getvalue())\n                response.headers['Content-Type'] = 'text/csv; charset=utf-8'\n                response.headers['Content-Disposition'] = f'attachment; filename=articles_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n                return response\n                \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'export: {str(e)}'}), 500\n\n    # Modern export endpoints with options\n    @app.route(\"/api/articles/export/pdf\", methods=['POST'])\n    def export_articles_pdf():\n        try:\n            # Get export options from request body\n            options = request.get_json() or {}\n            include_stock = options.get('includeStock', True)\n            include_prices = options.get('includePrices', True)\n            include_suppliers = options.get('includeSuppliers', True)\n            \n            # Get all articles\n            articles = Article.query.all()\n            \n            # Prepare data based on options\n            data = []\n            for article in articles:\n                row = {\n                    'Code Article': article.code_article,\n                    'Désignation': article.designation,\n                    'Catégorie': article.categorie,\n                    'Marque': article.marque or '',\n                    'Référence': article.reference or '',\n                    'Unité': article.unite,\n                }\n                \n                if include_stock:\n                    row.update({\n                        'Stock Initial': article.stock_initial,\n                        'Stock Actuel': article.stock_actuel,\n                        'Seuil Minimum': article.seuil_minimum,\n                    })\n                \n                if include_prices:\n                    row['Prix Unitaire'] = f\"{float(article.prix_unitaire):.2f} MAD\" if article.prix_unitaire else \"0.00 MAD\"\n                \n                if include_suppliers:\n                    row['Fournisseur ID'] = article.fournisseur_id or ''\n                \n                row['Date Création'] = article.created_at.strftime('%Y-%m-%d') if article.created_at else ''\n                data.append(row)\n            \n            # Create HTML content for PDF\n            html_content = f\"\"\"\n            <!DOCTYPE html>\n            <html>\n            <head>\n                <meta charset=\"UTF-8\">\n                <title>Export Articles - StockCéramique</title>\n                <style>\n                    body {{ font-family: Arial, sans-serif; margin: 20px; }}\n                    .header {{ text-align: center; margin-bottom: 30px; }}\n                    .company {{ color: #003d9d; font-size: 24px; font-weight: bold; }}\n                    .title {{ color: #666; font-size: 18px; margin-top: 10px; }}\n                    .date {{ color: #999; font-size: 12px; margin-top: 5px; }}\n                    table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}\n                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; font-size: 10px; }}\n                    th {{ background-color: #003d9d; color: white; font-weight: bold; }}\n                    tr:nth-child(even) {{ background-color: #f9f9f9; }}\n                    .footer {{ margin-top: 30px; text-align: center; font-size: 10px; color: #666; }}\n                </style>\n            </head>\n            <body>\n                <div class=\"header\">\n                    <div class=\"company\">StockCéramique</div>\n                    <div class=\"title\">Export Articles</div>\n                    <div class=\"date\">Généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}</div>\n                </div>\n                \n                <table>\n                    <thead>\n                        <tr>\n                            {''.join(f'<th>{col}</th>' for col in data[0].keys() if data)}\n                        </tr>\n                    </thead>\n                    <tbody>\n                        {''.join('<tr>' + ''.join(f'<td>{value}</td>' for value in row.values()) + '</tr>' for row in data)}\n                    </tbody>\n                </table>\n                \n                <div class=\"footer\">\n                    <p>Total: {len(data)} articles</p>\n                    <p>StockCéramique - Système de Gestion d'Inventaire</p>\n                </div>\n            </body>\n            </html>\n            \"\"\"\n            \n            # Generate actual PDF using weasyprint\n            from weasyprint import HTML\n            pdf_buffer = io.BytesIO()\n            HTML(string=html_content).write_pdf(pdf_buffer)\n            pdf_buffer.seek(0)\n            \n            response = make_response(pdf_buffer.getvalue())\n            response.headers['Content-Type'] = 'application/pdf'\n            response.headers['Content-Disposition'] = f'attachment; filename=articles_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pdf'\n            return response\n            \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'export PDF: {str(e)}'}), 500\n\n    @app.route(\"/api/articles/export/excel\", methods=['POST'])\n    def export_articles_excel():\n        try:\n            # Get export options from request body\n            options = request.get_json() or {}\n            include_stock = options.get('includeStock', True)\n            include_prices = options.get('includePrices', True)\n            include_suppliers = options.get('includeSuppliers', True)\n            \n            # Get all articles\n            articles = Article.query.all()\n            \n            # Prepare data based on options\n            data = []\n            for article in articles:\n                row = {\n                    'Code Article': article.code_article,\n                    'Désignation': article.designation,\n                    'Catégorie': article.categorie,\n                    'Marque': article.marque or '',\n                    'Référence': article.reference or '',\n                    'Unité': article.unite,\n                }\n                \n                if include_stock:\n                    row.update({\n                        'Stock Initial': article.stock_initial,\n                        'Stock Actuel': article.stock_actuel,\n                        'Seuil Minimum': article.seuil_minimum,\n                    })\n                \n                if include_prices:\n                    row['Prix Unitaire'] = float(article.prix_unitaire) if article.prix_unitaire else 0\n                \n                if include_suppliers:\n                    row['Fournisseur ID'] = article.fournisseur_id or ''\n                \n                row['Date Création'] = article.created_at.strftime('%Y-%m-%d %H:%M:%S') if article.created_at else ''\n                data.append(row)\n            \n            # Create dataframe\n            df = pd.DataFrame(data)\n            \n            # Export to Excel with styling\n            output = io.BytesIO()\n            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                df.to_excel(writer, sheet_name='Articles', index=False)\n                \n                # Get the workbook and worksheet for styling\n                workbook = writer.book\n                worksheet = writer.sheets['Articles']\n                \n                # Style the header row\n                from openpyxl.styles import Font, PatternFill, Alignment\n                header_font = Font(bold=True, color='FFFFFF')\n                header_fill = PatternFill(start_color='003d9d', end_color='003d9d', fill_type='solid')\n                \n                for col_num, column_title in enumerate(df.columns, 1):\n                    cell = worksheet.cell(row=1, column=col_num)\n                    cell.font = header_font\n                    cell.fill = header_fill\n                    cell.alignment = Alignment(horizontal='center')\n                \n                # Auto-adjust column widths\n                for column in worksheet.columns:\n                    max_length = 0\n                    column_letter = column[0].column_letter\n                    for cell in column:\n                        try:\n                            if len(str(cell.value)) > max_length:\n                                max_length = len(str(cell.value))\n                        except:\n                            pass\n                    adjusted_width = min(max_length + 2, 50)\n                    worksheet.column_dimensions[column_letter].width = adjusted_width\n            \n            output.seek(0)\n            \n            response = make_response(output.getvalue())\n            response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n            response.headers['Content-Disposition'] = f'attachment; filename=articles_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n            return response\n            \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'export Excel: {str(e)}'}), 500\n\n    @app.route(\"/api/articles/export/csv\", methods=['POST'])\n    def export_articles_csv():\n        try:\n            # Get export options from request body\n            options = request.get_json() or {}\n            include_stock = options.get('includeStock', True)\n            include_prices = options.get('includePrices', True)\n            include_suppliers = options.get('includeSuppliers', True)\n            \n            # Get all articles\n            articles = Article.query.all()\n            \n            # Prepare data based on options\n            data = []\n            for article in articles:\n                row = {\n                    'Code Article': article.code_article,\n                    'Désignation': article.designation,\n                    'Catégorie': article.categorie,\n                    'Marque': article.marque or '',\n                    'Référence': article.reference or '',\n                    'Unité': article.unite,\n                }\n                \n                if include_stock:\n                    row.update({\n                        'Stock Initial': article.stock_initial,\n                        'Stock Actuel': article.stock_actuel,\n                        'Seuil Minimum': article.seuil_minimum,\n                    })\n                \n                if include_prices:\n                    row['Prix Unitaire'] = float(article.prix_unitaire) if article.prix_unitaire else 0\n                \n                if include_suppliers:\n                    row['Fournisseur ID'] = article.fournisseur_id or ''\n                \n                row['Date Création'] = article.created_at.strftime('%Y-%m-%d %H:%M:%S') if article.created_at else ''\n                data.append(row)\n            \n            # Create dataframe\n            df = pd.DataFrame(data)\n            \n            # Export to CSV\n            output = io.StringIO()\n            df.to_csv(output, index=False, encoding='utf-8')\n            output.seek(0)\n            \n            response = make_response(output.getvalue())\n            response.headers['Content-Type'] = 'text/csv; charset=utf-8'\n            response.headers['Content-Disposition'] = f'attachment; filename=articles_export_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n            return response\n            \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'export CSV: {str(e)}'}), 500\n\n    @app.route(\"/api/articles/import\", methods=['POST'])\n    def import_articles():\n        try:\n            if 'file' not in request.files:\n                return jsonify({'message': 'Aucun fichier fourni'}), 400\n            \n            file = request.files['file']\n            if file.filename == '':\n                return jsonify({'message': 'Nom de fichier vide'}), 400\n            \n            # Check file extension\n            filename = secure_filename(file.filename)\n            file_ext = filename.rsplit('.', 1)[1].lower() if '.' in filename else ''\n            \n            if file_ext not in ['csv', 'xlsx', 'xls']:\n                return jsonify({'message': 'Format de fichier non supporté. Utilisez CSV ou Excel.'}), 400\n            \n            # Read file content\n            try:\n                if file_ext == 'csv':\n                    df = pd.read_csv(file)\n                else:\n                    df = pd.read_excel(file)\n            except Exception as e:\n                return jsonify({'message': f'Erreur lors de la lecture du fichier: {str(e)}'}), 400\n            \n            # Expected columns (mapping from display names to database fields)\n            expected_columns = {\n                'Code Article': 'code_article',\n                'Désignation': 'designation', \n                'Catégorie': 'categorie',\n                'Marque': 'marque',\n                'Référence': 'reference',\n                'Stock Initial': 'stock_initial',\n                'Stock Actuel': 'stock_actuel',\n                'Unité': 'unite',\n                'Prix Unitaire': 'prix_unitaire',\n                'Seuil Minimum': 'seuil_minimum',\n                'Fournisseur ID': 'fournisseur_id'\n            }\n            \n            # Check required columns\n            required_columns = ['Code Article', 'Désignation', 'Catégorie']\n            missing_columns = [col for col in required_columns if col not in df.columns]\n            if missing_columns:\n                return jsonify({'message': f'Colonnes manquantes: {\", \".join(missing_columns)}'}), 400\n            \n            # Process rows\n            created_count = 0\n            updated_count = 0\n            errors = []\n            \n            for index, row in df.iterrows():\n                try:\n                    # Check if article exists\n                    existing_article = Article.query.filter_by(code_article=row['Code Article']).first()\n                    \n                    if existing_article:\n                        # Update existing article\n                        for display_name, db_field in expected_columns.items():\n                            if display_name in df.columns and pd.notna(row[display_name]):\n                                value = row[display_name]\n                                if db_field in ['stock_initial', 'stock_actuel', 'seuil_minimum']:\n                                    value = int(value) if pd.notna(value) else 0\n                                elif db_field == 'prix_unitaire':\n                                    value = float(value) if pd.notna(value) else None\n                                elif db_field in ['marque', 'reference', 'fournisseur_id']:\n                                    value = str(value) if pd.notna(value) else None\n                                else:\n                                    value = str(value) if pd.notna(value) else ''\n                                setattr(existing_article, db_field, value)\n                        updated_count += 1\n                    else:\n                        # Create new article\n                        article_data = {}\n                        for display_name, db_field in expected_columns.items():\n                            if display_name in df.columns:\n                                value = row[display_name]\n                                if db_field in ['stock_initial', 'stock_actuel', 'seuil_minimum']:\n                                    article_data[db_field] = int(value) if pd.notna(value) else (10 if db_field == 'seuil_minimum' else 0)\n                                elif db_field == 'prix_unitaire':\n                                    article_data[db_field] = float(value) if pd.notna(value) else None\n                                elif db_field in ['marque', 'reference', 'fournisseur_id']:\n                                    article_data[db_field] = str(value) if pd.notna(value) else None\n                                else:\n                                    article_data[db_field] = str(value) if pd.notna(value) else ('pcs' if db_field == 'unite' else '')\n                        \n                        # Set defaults for required fields\n                        if 'unite' not in article_data or not article_data['unite']:\n                            article_data['unite'] = 'pcs'\n                        if 'seuil_minimum' not in article_data:\n                            article_data['seuil_minimum'] = 10\n                        if 'stock_initial' not in article_data:\n                            article_data['stock_initial'] = 0\n                        if 'stock_actuel' not in article_data:\n                            article_data['stock_actuel'] = article_data['stock_initial']\n                        \n                        article = Article(**article_data)\n                        db.session.add(article)\n                        created_count += 1\n                        \n                except Exception as e:\n                    errors.append(f'Ligne {index + 2}: {str(e)}')\n                    continue\n            \n            # Commit changes\n            try:\n                db.session.commit()\n                message = f'Import terminé: {created_count} articles créés, {updated_count} articles mis à jour'\n                if errors:\n                    message += f'. Erreurs: {len(errors)} lignes ignorées'\n                return jsonify({\n                    'message': message,\n                    'created': created_count,\n                    'updated': updated_count,\n                    'errors': errors[:5]  # Show first 5 errors only\n                }), 200\n            except Exception as e:\n                db.session.rollback()\n                return jsonify({'message': f'Erreur lors de la sauvegarde: {str(e)}'}), 500\n                \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de l\\'import: {str(e)}'}), 500\n\n    @app.route(\"/api/articles/template\", methods=['GET'])\n    def get_import_template():\n        try:\n            # Create template with headers and example data\n            template_data = [{\n                'Code Article': 'ART001',\n                'Désignation': 'Exemple Article',\n                'Catégorie': 'Électronique',\n                'Marque': 'Samsung',\n                'Référence': 'REF001',\n                'Stock Initial': 100,\n                'Stock Actuel': 95,\n                'Unité': 'pcs',\n                'Prix Unitaire': 25.50,\n                'Seuil Minimum': 10,\n                'Fournisseur ID': '',\n                'Date Création': ''\n            }]\n            \n            df = pd.DataFrame(template_data)\n            \n            # Export as Excel template\n            output = io.BytesIO()\n            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                df.to_excel(writer, sheet_name='Template Articles', index=False)\n            output.seek(0)\n            \n            response = make_response(output.getvalue())\n            response.headers['Content-Type'] = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n            response.headers['Content-Disposition'] = 'attachment; filename=template_import_articles.xlsx'\n            return response\n            \n        except Exception as e:\n            return jsonify({'message': f'Erreur lors de la génération du template: {str(e)}'}), 500","size_bytes":101632},"run.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nStockCeramique Flask Application\nRun script for the Flask-based inventory management system\n\"\"\"\n\nfrom flask_app import create_app\nimport os\n\nif __name__ == '__main__':\n    app = create_app()\n    \n    # Create database tables\n    with app.app_context():\n        from flask_models import db\n        db.create_all()\n        print(\"Database tables created successfully\")\n    \n    # Get port from environment or default to 5000\n    port = int(os.environ.get('PORT', 5000))\n    \n    print(f\"Starting StockCeramique Flask application on port {port}\")\n    print(\"Access the application at: http://localhost:5000\")\n    \n    # Run the Flask application\n    app.run(\n        host='0.0.0.0', \n        port=port, \n        debug=os.environ.get('FLASK_ENV') == 'development'\n    )","size_bytes":792},"dist-desktop/index-desktop.js":{"content":"var __defProp = Object.defineProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\n\n// server/index-desktop.ts\nimport express from \"express\";\nimport path2 from \"path\";\nimport { fileURLToPath } from \"url\";\n\n// server/db-local.ts\nimport Database from \"better-sqlite3\";\nimport { drizzle } from \"drizzle-orm/better-sqlite3\";\n\n// shared/schema.ts\nvar schema_exports = {};\n__export(schema_exports, {\n  articles: () => articles,\n  auditLogs: () => auditLogs,\n  backupLogs: () => backupLogs,\n  categories: () => categories,\n  convertToReceptionSchema: () => convertToReceptionSchema,\n  departements: () => departements,\n  insertArticleSchema: () => insertArticleSchema,\n  insertAuditLogSchema: () => insertAuditLogSchema,\n  insertBackupLogSchema: () => insertBackupLogSchema,\n  insertCategorySchema: () => insertCategorySchema,\n  insertCompletePurchaseRequestSchema: () => insertCompletePurchaseRequestSchema,\n  insertDepartementSchema: () => insertDepartementSchema,\n  insertMarqueSchema: () => insertMarqueSchema,\n  insertOutboundSchema: () => insertOutboundSchema,\n  insertPosteSchema: () => insertPosteSchema,\n  insertPurchaseRequestItemSchema: () => insertPurchaseRequestItemSchema,\n  insertPurchaseRequestSchema: () => insertPurchaseRequestSchema,\n  insertReceptionSchema: () => insertReceptionSchema,\n  insertRequestorSchema: () => insertRequestorSchema,\n  insertStockMovementSchema: () => insertStockMovementSchema,\n  insertSupplierSchema: () => insertSupplierSchema,\n  insertSystemSettingSchema: () => insertSystemSettingSchema,\n  insertUserSchema: () => insertUserSchema,\n  marques: () => marques,\n  outbounds: () => outbounds,\n  postes: () => postes,\n  purchaseRequestItems: () => purchaseRequestItems,\n  purchaseRequests: () => purchaseRequests,\n  receptions: () => receptions,\n  requestors: () => requestors,\n  stockMovements: () => stockMovements,\n  suppliers: () => suppliers,\n  systemSettings: () => systemSettings,\n  users: () => users\n});\nimport { pgTable, text, varchar, integer, decimal, timestamp } from \"drizzle-orm/pg-core\";\nimport { createInsertSchema } from \"drizzle-zod\";\nimport { z } from \"zod\";\nvar articles = pgTable(\"articles\", {\n  id: varchar(\"id\").primaryKey(),\n  codeArticle: text(\"code_article\").notNull().unique(),\n  designation: text(\"designation\").notNull(),\n  categorie: text(\"categorie\").notNull(),\n  marque: text(\"marque\"),\n  reference: text(\"reference\"),\n  stockInitial: integer(\"stock_initial\").notNull().default(0),\n  stockActuel: integer(\"stock_actuel\").notNull().default(0),\n  unite: text(\"unite\").notNull().default(\"pcs\"),\n  prixUnitaire: decimal(\"prix_unitaire\", { precision: 10, scale: 2 }),\n  seuilMinimum: integer(\"seuil_minimum\").default(10),\n  fournisseurId: varchar(\"fournisseur_id\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar suppliers = pgTable(\"suppliers\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull(),\n  contact: text(\"contact\"),\n  telephone: text(\"telephone\"),\n  email: text(\"email\"),\n  adresse: text(\"adresse\"),\n  conditionsPaiement: text(\"conditions_paiement\"),\n  delaiLivraison: integer(\"delai_livraison\"),\n  // in days\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar requestors = pgTable(\"requestors\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull(),\n  prenom: text(\"prenom\").notNull(),\n  departement: text(\"departement\").notNull(),\n  poste: text(\"poste\"),\n  email: text(\"email\"),\n  telephone: text(\"telephone\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar purchaseRequests = pgTable(\"purchase_requests\", {\n  id: varchar(\"id\").primaryKey(),\n  dateDemande: timestamp(\"date_demande\").notNull().defaultNow(),\n  requestorId: varchar(\"requestor_id\").notNull(),\n  dateInitiation: timestamp(\"date_initiation\").defaultNow(),\n  observations: text(\"observations\"),\n  statut: text(\"statut\").notNull().default(\"en_attente\"),\n  // en_attente, approuve, refuse, commande\n  totalArticles: integer(\"total_articles\").notNull().default(0),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar purchaseRequestItems = pgTable(\"purchase_request_items\", {\n  id: varchar(\"id\").primaryKey(),\n  purchaseRequestId: varchar(\"purchase_request_id\").notNull(),\n  articleId: varchar(\"article_id\").notNull(),\n  quantiteDemandee: integer(\"quantite_demandee\").notNull(),\n  supplierId: varchar(\"supplier_id\"),\n  prixUnitaireEstime: decimal(\"prix_unitaire_estime\", { precision: 10, scale: 2 }),\n  observations: text(\"observations\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar receptions = pgTable(\"receptions\", {\n  id: varchar(\"id\").primaryKey(),\n  dateReception: timestamp(\"date_reception\").notNull().defaultNow(),\n  supplierId: varchar(\"supplier_id\").notNull(),\n  articleId: varchar(\"article_id\").notNull(),\n  quantiteRecue: integer(\"quantite_recue\").notNull(),\n  prixUnitaire: decimal(\"prix_unitaire\", { precision: 10, scale: 2 }),\n  numeroBonLivraison: text(\"numero_bon_livraison\"),\n  observations: text(\"observations\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar outbounds = pgTable(\"outbounds\", {\n  id: varchar(\"id\").primaryKey(),\n  dateSortie: timestamp(\"date_sortie\").notNull().defaultNow(),\n  requestorId: varchar(\"requestor_id\").notNull(),\n  articleId: varchar(\"article_id\").notNull(),\n  quantiteSortie: integer(\"quantite_sortie\").notNull(),\n  motifSortie: text(\"motif_sortie\").notNull(),\n  observations: text(\"observations\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar stockMovements = pgTable(\"stock_movements\", {\n  id: varchar(\"id\").primaryKey(),\n  articleId: varchar(\"article_id\").notNull(),\n  type: text(\"type\").notNull(),\n  // entree, sortie\n  quantite: integer(\"quantite\").notNull(),\n  quantiteAvant: integer(\"quantite_avant\").notNull(),\n  quantiteApres: integer(\"quantite_apres\").notNull(),\n  reference: text(\"reference\"),\n  // Reference to reception/outbound ID\n  dateMovement: timestamp(\"date_movement\").notNull().defaultNow(),\n  description: text(\"description\")\n});\nvar users = pgTable(\"users\", {\n  id: varchar(\"id\").primaryKey(),\n  username: text(\"username\").notNull().unique(),\n  email: text(\"email\").unique(),\n  hashedPassword: text(\"hashed_password\").notNull(),\n  role: text(\"role\").notNull().default(\"demandeur\"),\n  // admin, super_admin, magasinier, demandeur, read_only\n  isActive: integer(\"is_active\").notNull().default(1),\n  // 1 = active, 0 = inactive\n  lastLogin: timestamp(\"last_login\"),\n  createdAt: timestamp(\"created_at\").defaultNow(),\n  updatedAt: timestamp(\"updated_at\").defaultNow()\n});\nvar systemSettings = pgTable(\"system_settings\", {\n  id: varchar(\"id\").primaryKey(),\n  category: text(\"category\").notNull(),\n  // stock_management, security, backup, etc.\n  key: text(\"key\").notNull(),\n  value: text(\"value\"),\n  dataType: text(\"data_type\").notNull().default(\"string\"),\n  // string, number, boolean, json\n  description: text(\"description\"),\n  isEditable: integer(\"is_editable\").notNull().default(1),\n  createdAt: timestamp(\"created_at\").defaultNow(),\n  updatedAt: timestamp(\"updated_at\").defaultNow()\n});\nvar auditLogs = pgTable(\"audit_logs\", {\n  id: varchar(\"id\").primaryKey(),\n  userId: varchar(\"user_id\"),\n  action: text(\"action\").notNull(),\n  // CREATE, UPDATE, DELETE, LOGIN, LOGOUT, etc.\n  entityType: text(\"entity_type\"),\n  // articles, suppliers, etc.\n  entityId: varchar(\"entity_id\"),\n  oldValues: text(\"old_values\"),\n  // JSON string\n  newValues: text(\"new_values\"),\n  // JSON string\n  ipAddress: text(\"ip_address\"),\n  userAgent: text(\"user_agent\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar backupLogs = pgTable(\"backup_logs\", {\n  id: varchar(\"id\").primaryKey(),\n  fileName: text(\"file_name\").notNull(),\n  filePath: text(\"file_path\").notNull(),\n  fileSize: integer(\"file_size\"),\n  // bytes\n  backupType: text(\"backup_type\").notNull(),\n  // manual, scheduled\n  status: text(\"status\").notNull().default(\"in_progress\"),\n  // in_progress, completed, failed\n  createdBy: varchar(\"created_by\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar insertArticleSchema = createInsertSchema(articles).omit({\n  id: true,\n  createdAt: true,\n  stockActuel: true\n}).extend({\n  prixUnitaire: z.coerce.number().nullable().optional(),\n  fournisseurId: z.coerce.string().nullable().optional()\n});\nvar insertSupplierSchema = createInsertSchema(suppliers).omit({\n  id: true,\n  createdAt: true\n});\nvar insertRequestorSchema = createInsertSchema(requestors).omit({\n  id: true,\n  createdAt: true\n});\nvar insertPurchaseRequestSchema = createInsertSchema(purchaseRequests).omit({\n  id: true,\n  createdAt: true,\n  dateInitiation: true,\n  totalArticles: true\n}).extend({\n  dateDemande: z.string().transform((str) => new Date(str))\n});\nvar insertPurchaseRequestItemSchema = createInsertSchema(purchaseRequestItems).omit({\n  id: true,\n  createdAt: true\n}).extend({\n  prixUnitaireEstime: z.coerce.number().nullable().optional(),\n  supplierId: z.string().nullable().optional()\n});\nvar insertCompletePurchaseRequestSchema = z.object({\n  dateDemande: z.string().transform((str) => new Date(str)),\n  requestorId: z.string(),\n  observations: z.string().optional(),\n  items: z.array(z.object({\n    articleId: z.string(),\n    quantiteDemandee: z.number().positive(),\n    supplierId: z.string().nullable().optional(),\n    prixUnitaireEstime: z.coerce.number().nullable().optional(),\n    observations: z.string().optional()\n  })).min(1, \"Au moins un article est requis\")\n});\nvar insertReceptionSchema = createInsertSchema(receptions).omit({\n  id: true,\n  createdAt: true\n}).extend({\n  prixUnitaire: z.coerce.number().nullable().optional(),\n  dateReception: z.string().transform((str) => new Date(str))\n});\nvar insertOutboundSchema = createInsertSchema(outbounds).omit({\n  id: true,\n  createdAt: true\n}).extend({\n  dateSortie: z.string().transform((str) => new Date(str))\n});\nvar insertStockMovementSchema = createInsertSchema(stockMovements).omit({\n  id: true\n});\nvar insertUserSchema = createInsertSchema(users).omit({\n  id: true,\n  createdAt: true,\n  updatedAt: true,\n  lastLogin: true\n});\nvar insertSystemSettingSchema = createInsertSchema(systemSettings).omit({\n  id: true,\n  createdAt: true,\n  updatedAt: true\n});\nvar insertAuditLogSchema = createInsertSchema(auditLogs).omit({\n  id: true,\n  createdAt: true\n});\nvar insertBackupLogSchema = createInsertSchema(backupLogs).omit({\n  id: true,\n  createdAt: true\n});\nvar convertToReceptionSchema = z.object({\n  quantiteRecue: z.number().positive().optional(),\n  prixUnitaire: z.coerce.number().nullable().optional(),\n  numeroBonLivraison: z.string().optional(),\n  observations: z.string().optional(),\n  dateReception: z.string().optional()\n});\nvar categories = pgTable(\"categories\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull().unique(),\n  description: text(\"description\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar marques = pgTable(\"marques\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull().unique(),\n  description: text(\"description\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar departements = pgTable(\"departements\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull().unique(),\n  description: text(\"description\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar postes = pgTable(\"postes\", {\n  id: varchar(\"id\").primaryKey(),\n  nom: text(\"nom\").notNull().unique(),\n  departementId: varchar(\"departement_id\"),\n  description: text(\"description\"),\n  createdAt: timestamp(\"created_at\").defaultNow()\n});\nvar insertCategorySchema = createInsertSchema(categories).omit({\n  id: true,\n  createdAt: true\n});\nvar insertMarqueSchema = createInsertSchema(marques).omit({\n  id: true,\n  createdAt: true\n});\nvar insertDepartementSchema = createInsertSchema(departements).omit({\n  id: true,\n  createdAt: true\n});\nvar insertPosteSchema = createInsertSchema(postes).omit({\n  id: true,\n  createdAt: true\n});\n\n// server/db-local.ts\nimport path from \"path\";\nimport fs from \"fs\";\nvar getUserDataPath = () => {\n  if (process.env.NODE_ENV === \"development\") {\n    return path.join(process.cwd(), \"data\");\n  }\n  return path.join(process.cwd(), \"data\");\n};\nvar dataDir = getUserDataPath();\nif (!fs.existsSync(dataDir)) {\n  fs.mkdirSync(dataDir, { recursive: true });\n}\nvar dbPath = path.join(dataDir, \"stockceramique.db\");\nvar sqlite = new Database(dbPath);\nsqlite.pragma(\"foreign_keys = ON\");\nvar db = drizzle(sqlite, { schema: schema_exports });\nvar initializeDatabase = () => {\n  try {\n    console.log(\"Initializing local SQLite database...\");\n    console.log(\"Database path:\", dbPath);\n    const schemaSQL = `\n      -- Articles table\n      CREATE TABLE IF NOT EXISTS articles (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        reference TEXT NOT NULL UNIQUE,\n        designation TEXT NOT NULL,\n        stock_quantity INTEGER NOT NULL DEFAULT 0,\n        min_stock INTEGER NOT NULL DEFAULT 0,\n        unit_price REAL NOT NULL DEFAULT 0,\n        supplier_id INTEGER,\n        category TEXT,\n        location TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch()),\n        FOREIGN KEY (supplier_id) REFERENCES suppliers(id)\n      );\n\n      -- Suppliers table\n      CREATE TABLE IF NOT EXISTS suppliers (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        name TEXT NOT NULL,\n        contact_person TEXT,\n        email TEXT,\n        phone TEXT,\n        address TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch())\n      );\n\n      -- Requestors table\n      CREATE TABLE IF NOT EXISTS requestors (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        name TEXT NOT NULL,\n        department TEXT,\n        email TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch())\n      );\n\n      -- Purchase Requests table\n      CREATE TABLE IF NOT EXISTS purchase_requests (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        requestor_id INTEGER NOT NULL,\n        status TEXT NOT NULL DEFAULT 'pending',\n        total_amount REAL NOT NULL DEFAULT 0,\n        notes TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch()),\n        FOREIGN KEY (requestor_id) REFERENCES requestors(id)\n      );\n\n      -- Purchase Request Items table\n      CREATE TABLE IF NOT EXISTS purchase_request_items (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        purchase_request_id INTEGER NOT NULL,\n        article_id INTEGER NOT NULL,\n        quantity INTEGER NOT NULL,\n        unit_price REAL NOT NULL,\n        supplier_id INTEGER,\n        FOREIGN KEY (purchase_request_id) REFERENCES purchase_requests(id) ON DELETE CASCADE,\n        FOREIGN KEY (article_id) REFERENCES articles(id),\n        FOREIGN KEY (supplier_id) REFERENCES suppliers(id)\n      );\n\n      -- Receptions table\n      CREATE TABLE IF NOT EXISTS receptions (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        purchase_request_id INTEGER,\n        supplier_id INTEGER NOT NULL,\n        delivery_note TEXT,\n        total_amount REAL NOT NULL DEFAULT 0,\n        status TEXT NOT NULL DEFAULT 'pending',\n        received_at INTEGER DEFAULT (unixepoch()),\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch()),\n        FOREIGN KEY (purchase_request_id) REFERENCES purchase_requests(id),\n        FOREIGN KEY (supplier_id) REFERENCES suppliers(id)\n      );\n\n      -- Reception Items table\n      CREATE TABLE IF NOT EXISTS reception_items (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        reception_id INTEGER NOT NULL,\n        article_id INTEGER NOT NULL,\n        quantity INTEGER NOT NULL,\n        unit_price REAL NOT NULL,\n        FOREIGN KEY (reception_id) REFERENCES receptions(id) ON DELETE CASCADE,\n        FOREIGN KEY (article_id) REFERENCES articles(id)\n      );\n\n      -- Outbounds table\n      CREATE TABLE IF NOT EXISTS outbounds (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        requestor_id INTEGER NOT NULL,\n        total_quantity INTEGER NOT NULL DEFAULT 0,\n        notes TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        updated_at INTEGER DEFAULT (unixepoch()),\n        FOREIGN KEY (requestor_id) REFERENCES requestors(id)\n      );\n\n      -- Outbound Items table\n      CREATE TABLE IF NOT EXISTS outbound_items (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        outbound_id INTEGER NOT NULL,\n        article_id INTEGER NOT NULL,\n        quantity INTEGER NOT NULL,\n        FOREIGN KEY (outbound_id) REFERENCES outbounds(id) ON DELETE CASCADE,\n        FOREIGN KEY (article_id) REFERENCES articles(id)\n      );\n\n      -- Stock Movements table\n      CREATE TABLE IF NOT EXISTS stock_movements (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        article_id INTEGER NOT NULL,\n        type TEXT NOT NULL,\n        quantity INTEGER NOT NULL,\n        reference_id INTEGER,\n        reference_type TEXT,\n        notes TEXT,\n        created_at INTEGER DEFAULT (unixepoch()),\n        FOREIGN KEY (article_id) REFERENCES articles(id)\n      );\n\n      -- Create indexes for better performance\n      CREATE INDEX IF NOT EXISTS idx_articles_reference ON articles(reference);\n      CREATE INDEX IF NOT EXISTS idx_articles_supplier ON articles(supplier_id);\n      CREATE INDEX IF NOT EXISTS idx_stock_movements_article ON stock_movements(article_id);\n      CREATE INDEX IF NOT EXISTS idx_stock_movements_type ON stock_movements(type);\n      CREATE INDEX IF NOT EXISTS idx_purchase_requests_status ON purchase_requests(status);\n      CREATE INDEX IF NOT EXISTS idx_receptions_status ON receptions(status);\n    `;\n    sqlite.exec(schemaSQL);\n    console.log(\"\\u2705 Database initialized successfully\");\n    return true;\n  } catch (error) {\n    console.error(\"\\u274C Error initializing database:\", error);\n    return false;\n  }\n};\nvar sqlite3 = sqlite;\nprocess.on(\"exit\", () => {\n  sqlite.close();\n});\nprocess.on(\"SIGINT\", () => {\n  sqlite.close();\n  process.exit(0);\n});\n\n// server/index-desktop.ts\nvar __filename = typeof __filename !== \"undefined\" ? __filename : fileURLToPath(import.meta.url);\nvar __dirname = typeof __dirname !== \"undefined\" ? __dirname : path2.dirname(__filename);\nvar app = express();\nvar PORT = parseInt(process.env.DESKTOP_PORT || \"3001\");\napp.use(express.json({ limit: \"10mb\" }));\napp.use(express.urlencoded({ extended: true }));\napp.use((req, res, next) => {\n  res.header(\"Access-Control-Allow-Origin\", \"*\");\n  res.header(\"Access-Control-Allow-Methods\", \"GET, POST, PUT, DELETE, OPTIONS, PATCH\");\n  res.header(\"Access-Control-Allow-Headers\", \"Origin, X-Requested-With, Content-Type, Accept, Authorization\");\n  if (req.method === \"OPTIONS\") {\n    res.sendStatus(200);\n  } else {\n    next();\n  }\n});\nvar dbInitialized = initializeDatabase();\nif (!dbInitialized) {\n  console.error(\"Failed to initialize database\");\n  process.exit(1);\n}\napp.get(\"/api/health\", (req, res) => {\n  res.json({\n    status: \"Desktop server running\",\n    database: \"SQLite connected\",\n    dbPath: sqlite3.name\n  });\n});\napp.get(\"/api/articles\", (req, res) => {\n  try {\n    const articles2 = sqlite3.prepare(\"SELECT * FROM articles ORDER BY created_at DESC\").all();\n    res.json(articles2);\n  } catch (error) {\n    console.error(\"Error fetching articles:\", error);\n    res.status(500).json({ error: \"Failed to fetch articles\" });\n  }\n});\napp.post(\"/api/articles\", (req, res) => {\n  try {\n    const { reference, designation, stock_quantity, min_stock, unit_price, supplier_id, category, location } = req.body;\n    const stmt = sqlite3.prepare(`\n      INSERT INTO articles (reference, designation, stock_quantity, min_stock, unit_price, supplier_id, category, location)\n      VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n    `);\n    const result = stmt.run(reference, designation, stock_quantity || 0, min_stock || 0, unit_price || 0, supplier_id, category, location);\n    const newArticle = sqlite3.prepare(\"SELECT * FROM articles WHERE id = ?\").get(result.lastInsertRowid);\n    res.status(201).json(newArticle);\n  } catch (error) {\n    console.error(\"Error creating article:\", error);\n    res.status(500).json({ error: \"Failed to create article\" });\n  }\n});\napp.get(\"/api/dashboard/stats\", (req, res) => {\n  try {\n    const totalArticles = sqlite3.prepare(\"SELECT COUNT(*) as count FROM articles\").get();\n    const lowStock = sqlite3.prepare(\"SELECT COUNT(*) as count FROM articles WHERE stock_quantity <= min_stock\").get();\n    const totalValue = sqlite3.prepare(\"SELECT SUM(stock_quantity * unit_price) as total FROM articles\").get();\n    res.json({\n      totalArticles: totalArticles.count || 0,\n      lowStock: lowStock.count || 0,\n      totalValue: totalValue.total || 0,\n      pendingRequests: 0\n      // Placeholder\n    });\n  } catch (error) {\n    console.error(\"Error fetching dashboard stats:\", error);\n    res.status(500).json({ error: \"Failed to fetch dashboard stats\" });\n  }\n});\nif (process.env.NODE_ENV === \"production\") {\n  const publicPath = path2.join(__dirname, \"../dist/public\");\n  app.use(express.static(publicPath));\n  app.get(\"*\", (req, res) => {\n    if (!req.path.startsWith(\"/api/\")) {\n      res.sendFile(path2.join(publicPath, \"index.html\"));\n    }\n  });\n}\napp.use((err, req, res, next) => {\n  console.error(\"Server error:\", err);\n  res.status(500).json({ error: \"Internal server error\" });\n});\nvar server = app.listen(PORT, \"127.0.0.1\", () => {\n  console.log(`\\u{1F5A5}\\uFE0F  Desktop server running on http://127.0.0.1:${PORT}`);\n  console.log(`\\u{1F4C1} Database path: ${sqlite3.name}`);\n  console.log(`\\u{1F680} Mode: ${process.env.NODE_ENV || \"development\"}`);\n});\nvar index_desktop_default = server;\nexport {\n  index_desktop_default as default\n};\n","size_bytes":21657},".local/state/replit/agent/progress_tracker.md":{"content":"[x] 1. Install the required packages\n[x] 2. Restart the workflow to see if the project is working\n[x] 3. Verify the project is working using the feedback tool\n[x] 4. Migration completed successfully - Application running with 2,421 articles imported","size_bytes":249},"import_articles.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nArticle Data Import Script for StockCéramique\nImports articles from the provided CSV data file\n\"\"\"\n\nimport csv\nimport os\nimport sys\nfrom flask_app import create_app\nfrom flask_models import db, Article\nfrom decimal import Decimal\nimport uuid\n\ndef generate_code_article(designation, reference):\n    \"\"\"Generate a unique article code based on designation and reference\"\"\"\n    # Use reference if available, otherwise generate from designation\n    if reference and reference.strip() and reference.strip() != designation.strip():\n        return reference.strip()[:50]  # Limit to 50 chars\n    else:\n        # Generate code from first words of designation\n        words = designation.strip().split()[:3]  # First 3 words\n        code = ''.join(word[:4].upper() for word in words if word)\n        return code[:20] if code else str(uuid.uuid4())[:8].upper()\n\ndef determine_category(designation):\n    \"\"\"Determine category based on designation keywords\"\"\"\n    designation_lower = designation.lower()\n    \n    if any(word in designation_lower for word in ['moteur', 'motor', 'electrique']):\n        return 'MOTEURS'\n    elif any(word in designation_lower for word in ['huile', 'oil', 'lubrifiant']):\n        return 'LUBRIFIANTS'\n    elif any(word in designation_lower for word in ['courroie', 'belt']):\n        return 'COURROIES'\n    elif any(word in designation_lower for word in ['tube', 'tuyau', 'pipe']):\n        return 'TUYAUTERIE'\n    elif any(word in designation_lower for word in ['vis', 'boulon', 'ecrou', 'screw']):\n        return 'VISSERIE'\n    elif any(word in designation_lower for word in ['cable', 'fil', 'electrique']):\n        return 'ELECTRICITE'\n    elif any(word in designation_lower for word in ['gant', 'protection', 'securite']):\n        return 'PROTECTION'\n    elif any(word in designation_lower for word in ['peinture', 'diluant', 'paint']):\n        return 'PEINTURE'\n    elif any(word in designation_lower for word in ['roulement', 'bearing']):\n        return 'ROULEMENTS'\n    elif any(word in designation_lower for word in ['pompe', 'pump']):\n        return 'POMPES'\n    elif any(word in designation_lower for word in ['valve', 'vanne', 'robinet']):\n        return 'VANNES'\n    elif any(word in designation_lower for word in ['contacteur', 'disjoncteur', 'electrique']):\n        return 'ELECTRICITE'\n    elif any(word in designation_lower for word in ['cle', 'outil', 'tool']):\n        return 'OUTILS'\n    elif any(word in designation_lower for word in ['tole', 'fer', 'metal']):\n        return 'METALLURGIE'\n    else:\n        return 'DIVERS'\n\ndef import_articles_from_file():\n    \"\"\"Import articles from the CSV file\"\"\"\n    app = create_app()\n    \n    with app.app_context():\n        # Read the data file\n        file_path = 'attached_assets/Pasted-DESIGNATION-REFERENCE-QUANTITE-PRIX-UNITAIRE-POMPE-FREIN-2559540302-2559540302-1-00-900-0000-SCOTC-1756304976142_1756304976144.txt'\n        \n        if not os.path.exists(file_path):\n            print(f\"Error: File {file_path} not found\")\n            return False\n            \n        imported_count = 0\n        skipped_count = 0\n        \n        try:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                # Skip the header line\n                next(file)\n                \n                for line_num, line in enumerate(file, 2):\n                    # Skip empty lines\n                    if not line.strip():\n                        continue\n                        \n                    # Split line by tabs\n                    parts = line.strip().split('\\t')\n                    \n                    # Skip malformed lines\n                    if len(parts) < 4:\n                        print(f\"Line {line_num}: Skipping malformed line: {line.strip()[:100]}\")\n                        skipped_count += 1\n                        continue\n                    \n                    designation = parts[0].strip()\n                    reference = parts[1].strip()\n                    \n                    # Skip if designation is empty\n                    if not designation:\n                        skipped_count += 1\n                        continue\n                    \n                    try:\n                        quantite = float(parts[2].replace(',', '.'))\n                        prix_unitaire = float(parts[3].replace(',', '.'))\n                    except (ValueError, IndexError):\n                        print(f\"Line {line_num}: Invalid quantity or price: {line.strip()[:100]}\")\n                        skipped_count += 1\n                        continue\n                    \n                    # Generate unique code_article\n                    code_article = generate_code_article(designation, reference)\n                    \n                    # Check if article already exists\n                    existing = Article.query.filter_by(code_article=code_article).first()\n                    if existing:\n                        # Update existing article stock and price\n                        existing.stock_actuel = int(quantite)\n                        existing.stock_initial = int(quantite)\n                        existing.prix_unitaire = Decimal(str(prix_unitaire))\n                        print(f\"Updated existing article: {code_article}\")\n                    else:\n                        # Create new article\n                        article = Article(\n                            code_article=code_article,\n                            designation=designation,\n                            categorie=determine_category(designation),\n                            reference=reference if reference != designation else None,\n                            stock_initial=int(quantite),\n                            stock_actuel=int(quantite),\n                            unite='pcs',\n                            prix_unitaire=Decimal(str(prix_unitaire)),\n                            seuil_minimum=max(1, int(quantite * 0.1))  # 10% of initial stock as minimum\n                        )\n                        \n                        db.session.add(article)\n                        imported_count += 1\n                        \n                    # Commit every 50 records to avoid memory issues\n                    if (imported_count + skipped_count) % 50 == 0:\n                        db.session.commit()\n                        print(f\"Processed {imported_count + skipped_count} lines...\")\n                \n                # Final commit\n                db.session.commit()\n                \n        except Exception as e:\n            print(f\"Error importing articles: {str(e)}\")\n            db.session.rollback()\n            return False\n        \n        print(f\"\\nImport completed!\")\n        print(f\"Articles imported: {imported_count}\")\n        print(f\"Lines skipped: {skipped_count}\")\n        print(f\"Total articles in database: {Article.query.count()}\")\n        \n        return True\n\nif __name__ == '__main__':\n    print(\"Starting article import...\")\n    success = import_articles_from_file()\n    \n    if success:\n        print(\"\\n✅ Article import completed successfully!\")\n        sys.exit(0)\n    else:\n        print(\"\\n❌ Article import failed!\")\n        sys.exit(1)","size_bytes":7210},"desktop_main.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nStockCeramique Desktop Application\nDesktop entry point for the Flask-based inventory management system using webview with splash screen\n\"\"\"\n\nimport threading\nimport time\nimport webview\nimport webbrowser\nfrom flask_app import create_app\nfrom flask_models import db\nimport sys\nimport os\nimport socket\nimport logging\nimport requests\nfrom tkinter import filedialog\nimport tkinter as tk\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Get base path for PyInstaller and set up database path\nif getattr(sys, 'frozen', False):\n    # Running as compiled executable\n    BASE_PATH = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))\n    # Use user's AppData directory for database\n    DB_DIR = os.path.join(os.path.expanduser(\"~\"), \"StockCeramique\")\n    os.makedirs(DB_DIR, exist_ok=True)\n    \n    # Create instance directory for database\n    INSTANCE_DIR = os.path.join(DB_DIR, \"instance\")\n    os.makedirs(INSTANCE_DIR, exist_ok=True)\n    \n    DB_PATH = os.path.join(INSTANCE_DIR, \"stockceramique.db\")\n    # Set environment variable for Flask app to use SQLite\n    os.environ['DATABASE_URL'] = f'sqlite:///{DB_PATH}'\n    logger.info(f\"Database will be created at: {DB_PATH}\")\n    logger.info(f\"Instance directory: {INSTANCE_DIR}\")\nelse:\n    # Running as script - use local instance directory\n    BASE_PATH = os.path.dirname(os.path.abspath(__file__))\n    INSTANCE_DIR = os.path.join(BASE_PATH, \"instance\")\n    os.makedirs(INSTANCE_DIR, exist_ok=True)\n    DB_PATH = os.path.join(INSTANCE_DIR, \"stockceramique.db\")\n    # Set SQLite database URL for development/script mode\n    os.environ['DATABASE_URL'] = f'sqlite:///{DB_PATH}'\n    logger.info(f\"Development database at: {DB_PATH}\")\n\nclass DownloadAPI:\n    \"\"\"API class to handle download operations from webview\"\"\"\n\n    def __init__(self, server_port):\n        self.server_port = server_port\n        self.downloads_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n\n    def download_file(self, url_path, suggested_filename=None):\n        \"\"\"Download a file from the Flask server\"\"\"\n        try:\n            # Create full URL\n            full_url = f\"http://127.0.0.1:{self.server_port}{url_path}\"\n\n            # Get the file from Flask server\n            response = requests.get(full_url, stream=True, timeout=30)\n            response.raise_for_status()\n\n            # Determine filename\n            if not suggested_filename:\n                # Try to get filename from Content-Disposition header\n                cd_header = response.headers.get('Content-Disposition', '')\n                if 'filename=' in cd_header:\n                    suggested_filename = cd_header.split('filename=')[1].strip('\"\\'')\n                else:\n                    suggested_filename = \"download_file\"\n\n            # Show file save dialog\n            root = tk.Tk()\n            root.withdraw()  # Hide the main window\n            root.attributes('-topmost', True)  # Keep dialog on top\n\n            # Get file extension from suggested filename\n            file_ext = os.path.splitext(suggested_filename)[1]\n            if file_ext:\n                filetypes = [\n                    (f\"{file_ext.upper()} files\", f\"*{file_ext}\"),\n                    (\"All files\", \"*.*\")\n                ]\n            else:\n                filetypes = [(\"All files\", \"*.*\")]\n\n            # Show save dialog\n            file_path = filedialog.asksaveasfilename(\n                title=\"Save file as...\",\n                initialdir=self.downloads_dir,\n                defaultextension=file_ext,\n                filetypes=filetypes\n            )\n\n            root.destroy()\n\n            if file_path:\n                # Save the file\n                with open(file_path, 'wb') as f:\n                    for chunk in response.iter_content(chunk_size=8192):\n                        if chunk:\n                            f.write(chunk)\n\n                logger.info(f\"✅ File downloaded successfully: {file_path}\")\n                return {\"success\": True, \"path\": file_path, \"message\": \"File downloaded successfully!\"}\n            else:\n                return {\"success\": False, \"message\": \"Download cancelled by user\"}\n\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"❌ Download request failed: {e}\")\n            return {\"success\": False, \"message\": f\"Download failed: {str(e)}\"}\n        except Exception as e:\n            logger.error(f\"❌ Download failed: {e}\")\n            return {\"success\": False, \"message\": f\"Download failed: {str(e)}\"}\n\n    def show_downloads_folder(self):\n        \"\"\"Open the downloads folder in file explorer\"\"\"\n        try:\n            if os.name == 'nt':  # Windows\n                os.startfile(self.downloads_dir)\n            elif os.name == 'posix':  # macOS/Linux\n                os.system(f'open \"{self.downloads_dir}\"' if sys.platform == 'darwin' else f'xdg-open \"{self.downloads_dir}\"')\n            return {\"success\": True, \"message\": \"Downloads folder opened\"}\n        except Exception as e:\n            logger.error(f\"❌ Failed to open downloads folder: {e}\")\n            return {\"success\": False, \"message\": f\"Failed to open downloads folder: {str(e)}\"}\n\ndef find_free_port():\n    \"\"\"Find a free port from a list of common ports\"\"\"\n    ports_to_try = [5001, 5002, 5003, 8001, 8002, 8003, 8080, 8081, 5000]\n\n    for port in ports_to_try:\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                s.bind(('127.0.0.1', port))\n                logger.info(f\"✅ Using port: {port}\")\n                return port\n        except OSError:\n            logger.debug(f\"❌ Port {port} is busy\")\n            continue\n\n    # Find any available port\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind(('127.0.0.1', 0))\n        port = s.getsockname()[1]\n        logger.info(f\"✅ Using dynamic port: {port}\")\n        return port\n\ndef run_flask(port):\n    \"\"\"Run Flask server in a separate thread\"\"\"\n    try:\n        logger.info(f\"🚀 Starting Flask server on port {port}...\")\n        app = create_app()\n\n        # Ensure database exists and tables are created\n        with app.app_context():\n            db.create_all()\n            logger.info(\"✅ Database tables created successfully\")\n            \n            # Database tables are now ready for use\n            logger.info(\"📦 Database initialized and ready\")\n\n        app.run(host='127.0.0.1', port=port, debug=False, use_reloader=False, threaded=True)\n    except Exception as e:\n        logger.error(f\"Failed to start Flask server: {e}\")\n\ndef wait_for_server(port, timeout=30):\n    \"\"\"Wait for Flask server to be ready using HTTP requests\"\"\"\n    start_time = time.time()\n    url = f\"http://127.0.0.1:{port}\"\n\n    logger.info(\"⏳ Waiting for Flask server to start...\")\n    while time.time() - start_time < timeout:\n        try:\n            response = requests.get(url, timeout=2)\n            if response.status_code == 200:\n                logger.info(\"✅ Flask server is ready!\")\n                return True\n        except requests.exceptions.RequestException:\n            pass\n        time.sleep(0.5)\n\n    logger.error(\"❌ Flask server failed to start within timeout\")\n    return False\n\ndef safe_splash_operation(operation, *args, **kwargs):\n    \"\"\"Safely perform splash screen operations\"\"\"\n    try:\n        import pyi_splash\n        if hasattr(pyi_splash, 'is_alive') and not pyi_splash.is_alive():\n            return False\n        return getattr(pyi_splash, operation)(*args, **kwargs)\n    except (ImportError, RuntimeError, AttributeError) as e:\n        logger.debug(f\"Splash operation '{operation}' failed: {e}\")\n        return False\n\ndef open_with_webview_direct(url, port):\n    \"\"\"Open webview directly to the main application\"\"\"\n    try:\n        logger.info(\"🖥️ Opening webview with main application...\")\n\n        # Create download API instance\n        download_api = DownloadAPI(port)\n\n        # Create webview window directly with the main app URL\n        webview.create_window(\n            \"StockCeramique - Inventory Management\",\n            url,\n            width=1200,\n            height=800,\n            min_size=(800, 600),\n            resizable=True,\n            maximized=False,\n            js_api=download_api  # Expose download API to JavaScript\n        )\n\n        # Start webview (this blocks until window is closed)\n        webview.start(debug=False)\n        return True\n\n    except Exception as e:\n        logger.error(f\"❌ Webview failed: {e}\")\n        return False\n\ndef open_with_browser(url):\n    \"\"\"Open with default browser\"\"\"\n    try:\n        logger.info(\"🌐 Opening with default browser...\")\n        webbrowser.open(url)\n        logger.info(\"✅ Browser opened successfully!\")\n        logger.info(\"📋 Keep this console window open to keep the server running\")\n        logger.info(\"📋 Close this window or press Ctrl+C to stop the server\")\n        return True\n    except Exception as e:\n        logger.error(f\"❌ Browser failed: {e}\")\n        return False\n\ndef keep_alive():\n    \"\"\"Keep the application running when using browser\"\"\"\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        logger.info(\"👋 Application stopped by user\")\n\ndef main():\n    \"\"\"Main function to run the desktop application\"\"\"\n    try:\n        logger.info(\"🚀 Starting StockCeramique Desktop Application...\")\n\n        # Update PyInstaller splash screen\n        safe_splash_operation('update_text', 'Initializing application...')\n\n        # Find available port\n        port = find_free_port()\n\n        # Update splash\n        safe_splash_operation('update_text', 'Starting Flask server...')\n\n        # Start Flask server\n        flask_thread = threading.Thread(target=run_flask, args=(port,), daemon=True)\n        flask_thread.start()\n\n        # Update splash\n        safe_splash_operation('update_text', 'Waiting for server...')\n\n        # Wait for server to be ready before showing webview\n        if wait_for_server(port):\n            logger.info(\"✅ Server is ready!\")\n\n            # Update splash one more time\n            safe_splash_operation('update_text', 'Loading interface...')\n            time.sleep(0.5)  # Brief pause to show the message\n\n            # Close PyInstaller splash screen\n            safe_splash_operation('close')\n\n            # Server URL\n            url = f\"http://127.0.0.1:{port}\"\n            logger.info(f\"🌐 Server ready at: {url}\")\n\n            # Try webview first, fallback to browser\n            if not open_with_webview_direct(url, port):\n                logger.info(\"🔄 Webview failed, trying browser fallback...\")\n\n                if open_with_browser(url):\n                    # Keep server running for browser\n                    keep_alive()\n                else:\n                    logger.error(\"❌ Both webview and browser failed!\")\n                    logger.info(f\"📋 Try manually opening: {url}\")\n                    input(\"Both webview and browser failed. Press any key to exit...\")\n        else:\n            logger.error(\"❌ Flask server failed to start\")\n            safe_splash_operation('close')\n            input(\"Flask server failed to start. Press any key to exit...\")\n\n    except Exception as e:\n        logger.error(f\"❌ Application failed to start: {e}\")\n        import traceback\n        logger.error(traceback.format_exc())\n\n        # Try to close splash screen\n        safe_splash_operation('close')\n\n        input(\"Application failed to start. Press any key to exit...\")\n        sys.exit(1)\n\nif __name__ == '__main__':\n    main()","size_bytes":11657},"admin_tools.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nAdmin Tools for StockCeramique License Management\nTools for administrators to manage licenses\n\"\"\"\n\nfrom license_manager import license_manager\nimport sqlite3\nimport json\n\ndef get_all_valid_licenses():\n    \"\"\"Get all valid license keys for admin purposes\"\"\"\n    try:\n        conn = sqlite3.connect(license_manager.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT mac_address, license_data, activation_date, machine_name, is_active, checksum\n            FROM licenses \n            ORDER BY activation_date DESC\n        ''')\n        \n        licenses = []\n        results = cursor.fetchall()\n        \n        for row in results:\n            mac_address, license_data, activation_date, machine_name, is_active, checksum = row\n            \n            # Decrypt license key\n            decrypted_key = license_manager._decrypt_data(license_data)\n            \n            if decrypted_key:\n                # Generate expected key to verify validity\n                expected_key = license_manager.generate_license_key(mac_address)\n                is_valid = (decrypted_key == expected_key and \n                           license_manager._create_checksum(decrypted_key) == checksum)\n                \n                licenses.append({\n                    'mac_address': mac_address,\n                    'license_key': decrypted_key,\n                    'activation_date': activation_date,\n                    'machine_name': machine_name or 'Unknown',\n                    'is_active': bool(is_active),\n                    'is_valid': is_valid,\n                    'status': 'Active' if is_active and is_valid else 'Inactive'\n                })\n        \n        conn.close()\n        return licenses\n        \n    except Exception as e:\n        print(f\"Error retrieving licenses: {e}\")\n        return []\n\ndef generate_license_for_mac(mac_address):\n    \"\"\"Generate a valid license key for a specific MAC address\"\"\"\n    try:\n        license_key = license_manager.generate_license_key(mac_address)\n        return license_key\n    except Exception as e:\n        print(f\"Error generating license: {e}\")\n        return None\n\ndef print_license_report():\n    \"\"\"Print a formatted report of all licenses\"\"\"\n    licenses = get_all_valid_licenses()\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STOCKCERAMIQUE LICENSE REPORT\")\n    print(\"=\"*80)\n    \n    if not licenses:\n        print(\"No licenses found in database.\")\n        return\n    \n    print(f\"Total licenses: {len(licenses)}\")\n    active_count = sum(1 for l in licenses if l['is_active'])\n    print(f\"Active licenses: {active_count}\")\n    print(f\"Inactive licenses: {len(licenses) - active_count}\")\n    print(\"-\"*80)\n    \n    for i, license_info in enumerate(licenses, 1):\n        print(f\"\\n{i}. LICENSE ENTRY\")\n        print(f\"   MAC Address: {license_info['mac_address']}\")\n        print(f\"   License Key: {license_info['license_key']}\")\n        print(f\"   Machine Name: {license_info['machine_name']}\")\n        print(f\"   Activation Date: {license_info['activation_date']}\")\n        print(f\"   Status: {license_info['status']}\")\n        print(f\"   Valid: {'Yes' if license_info['is_valid'] else 'No'}\")\n    \n    print(\"\\n\" + \"=\"*80)\n\nif __name__ == \"__main__\":\n    print_license_report()","size_bytes":3292},"license_generator.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nLicense Key Generator for StockCeramique\nAdmin tool to generate one-time use license keys\n\"\"\"\n\nfrom onetime_license_manager import onetime_license_manager\nimport argparse\n\ndef generate_license_keys(count=10):\n    \"\"\"Generate a batch of one-time use license keys\"\"\"\n    print(f\"\\n🔑 Generating {count} one-time use license keys...\")\n    print(\"=\"*60)\n    \n    keys = onetime_license_manager.generate_license_keys_batch(count)\n    \n    print(f\"✅ Successfully generated {len(keys)} license keys:\\n\")\n    \n    for i, key in enumerate(keys, 1):\n        print(f\"{i:2d}. {key}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"📋 License keys have been stored in the database\")\n    print(\"🔒 Each key can only be used once for activation\")\n    print(\"\\n\")\n\ndef show_all_license_keys():\n    \"\"\"Show all generated license keys and their status\"\"\"\n    licenses = onetime_license_manager.get_all_license_keys()\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STOCKCERAMIQUE ONE-TIME LICENSE KEYS\")\n    print(\"=\"*80)\n    \n    if not licenses:\n        print(\"No license keys found in database.\")\n        return\n    \n    total = len(licenses)\n    used = sum(1 for l in licenses if l['is_used'])\n    available = total - used\n    \n    print(f\"Total license keys: {total}\")\n    print(f\"Used license keys: {used}\")\n    print(f\"Available license keys: {available}\")\n    print(\"-\"*80)\n    \n    for i, license_info in enumerate(licenses, 1):\n        status_icon = \"🔴\" if license_info['is_used'] else \"🟢\"\n        print(f\"\\n{i:2d}. {status_icon} {license_info['license_key']} [{license_info['status']}]\")\n        \n        if license_info['is_used']:\n            print(f\"     Used by: {license_info['used_by_machine']} ({license_info['used_by_mac']})\")\n            print(f\"     Activated: {license_info['activation_date']}\")\n        else:\n            print(f\"     Created: {license_info['created_date']}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"🟢 = Available  🔴 = Used\")\n    print()\n\ndef show_available_keys_only():\n    \"\"\"Show only available (unused) license keys\"\"\"\n    licenses = onetime_license_manager.get_all_license_keys()\n    available_keys = [l for l in licenses if not l['is_used']]\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"AVAILABLE LICENSE KEYS\")\n    print(\"=\"*60)\n    \n    if not available_keys:\n        print(\"No available license keys found.\")\n        print(\"Generate new keys using: python license_generator.py --generate 10\")\n        return\n    \n    print(f\"Available license keys: {len(available_keys)}\\n\")\n    \n    for i, license_info in enumerate(available_keys, 1):\n        print(f\"{i:2d}. {license_info['license_key']}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"Each key can be used once for activation\")\n    print()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='StockCeramique License Key Generator')\n    parser.add_argument('--generate', '-g', type=int, metavar='COUNT', \n                       help='Generate COUNT license keys (default: 10)')\n    parser.add_argument('--list', '-l', action='store_true',\n                       help='Show all license keys and their status')\n    parser.add_argument('--available', '-a', action='store_true',\n                       help='Show only available (unused) license keys')\n    \n    args = parser.parse_args()\n    \n    if args.generate:\n        generate_license_keys(args.generate)\n    elif args.list:\n        show_all_license_keys()\n    elif args.available:\n        show_available_keys_only()\n    else:\n        # Default: show available keys\n        show_available_keys_only()","size_bytes":3585},"license_manager.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nLicense Manager for StockCeramique\nHandles software licensing, MAC address detection, and activation\n\"\"\"\n\nimport hashlib\nimport uuid\nimport sqlite3\nimport os\nfrom datetime import datetime, timedelta\nimport psutil\nimport json\nimport base64\n\nclass LicenseManager:\n    def __init__(self, db_path=None):\n        # Use hidden/obfuscated database path\n        if db_path is None:\n            # Create hidden database in system directory with obfuscated name\n            self.db_path = os.path.join(os.path.expanduser('~'), '.sys', 'cfg', 'app.dat')\n        else:\n            self.db_path = db_path\n        self.ensure_db_exists()\n        self.max_licenses = 1  # Limit to 1 license per installation\n    \n    def ensure_db_exists(self):\n        \"\"\"Create license database and table if it doesn't exist\"\"\"\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS licenses (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                mac_address TEXT UNIQUE NOT NULL,\n                license_data TEXT NOT NULL,\n                activation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                is_active BOOLEAN DEFAULT TRUE,\n                machine_name TEXT,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                checksum TEXT\n            )\n        ''')\n        \n        conn.commit()\n        conn.close()\n    \n    def get_mac_address(self):\n        \"\"\"Get the primary MAC address of the machine\"\"\"\n        try:\n            # Get all network interfaces\n            interfaces = psutil.net_if_addrs()\n            \n            # Look for the primary active interface (not loopback)\n            for interface_name, interface_addresses in interfaces.items():\n                if interface_name.lower() != 'lo' and interface_name.lower() != 'loopback':\n                    for address in interface_addresses:\n                        if address.family == psutil.AF_LINK:  # MAC address\n                            mac = address.address\n                            if mac and mac != '00:00:00:00:00:00':\n                                return mac.upper()\n            \n            # Fallback: get MAC address of any interface\n            return ':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) \n                           for elements in range(0,2*6,2)][::-1]).upper()\n        except Exception as e:\n            # Ultimate fallback\n            return ':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) \n                           for elements in range(0,2*6,2)][::-1]).upper()\n    \n    def get_machine_name(self):\n        \"\"\"Get the machine name/hostname\"\"\"\n        try:\n            return os.environ.get('COMPUTERNAME', os.environ.get('HOSTNAME', 'Unknown'))\n        except:\n            return 'Unknown'\n    \n    def _encrypt_data(self, data):\n        \"\"\"Simple encryption for license data\"\"\"\n        encoded = base64.b64encode(data.encode()).decode()\n        # Add additional obfuscation\n        obfuscated = ''.join(chr(ord(c) + 3) for c in encoded)\n        return base64.b64encode(obfuscated.encode()).decode()\n    \n    def _decrypt_data(self, encrypted_data):\n        \"\"\"Decrypt license data\"\"\"\n        try:\n            decoded = base64.b64decode(encrypted_data.encode()).decode()\n            deobfuscated = ''.join(chr(ord(c) - 3) for c in decoded)\n            return base64.b64decode(deobfuscated.encode()).decode()\n        except:\n            return None\n    \n    def _create_checksum(self, data):\n        \"\"\"Create checksum for data integrity\"\"\"\n        return hashlib.sha256(data.encode()).hexdigest()[:16]\n\n    def generate_license_key(self, mac_address, secret_seed=\"StockCeramique2025\"):\n        \"\"\"Generate a license key based on MAC address\"\"\"\n        # Create a hash using MAC address and secret\n        data = f\"{mac_address}{secret_seed}\".encode()\n        hash_obj = hashlib.sha256(data)\n        hex_dig = hash_obj.hexdigest()\n        \n        # Format as a license key: XXXX-XXXX-XXXX-XXXX\n        key_parts = [hex_dig[i:i+4].upper() for i in range(0, 16, 4)]\n        return '-'.join(key_parts)\n    \n    def validate_license_key(self, license_key, mac_address):\n        \"\"\"Validate if the license key is correct for the MAC address\"\"\"\n        expected_key = self.generate_license_key(mac_address)\n        return license_key.strip().upper() == expected_key\n    \n    def check_license_limit(self):\n        \"\"\"Check if license limit has been reached\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('SELECT COUNT(*) FROM licenses WHERE is_active = TRUE')\n        active_count = cursor.fetchone()[0]\n        \n        conn.close()\n        return active_count < self.max_licenses\n\n    def is_machine_licensed(self):\n        \"\"\"Check if the current machine is licensed\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_data, is_active, checksum FROM licenses \n            WHERE mac_address = ? AND is_active = TRUE\n        ''', (current_mac,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if result:\n            license_data, is_active, checksum = result\n            # Verify data integrity\n            decrypted_key = self._decrypt_data(license_data)\n            if decrypted_key and self._create_checksum(decrypted_key) == checksum:\n                return True\n        \n        return False\n    \n    def activate_license(self, license_key):\n        \"\"\"Activate license for current machine\"\"\"\n        current_mac = self.get_mac_address()\n        machine_name = self.get_machine_name()\n        \n        # Validate license key\n        if not self.validate_license_key(license_key, current_mac):\n            return False, \"Invalid license key for this machine\"\n        \n        # Check license limits\n        if not self.check_license_limit():\n            return False, \"License limit reached. Maximum activations exceeded.\"\n        \n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # Encrypt license data\n            encrypted_key = self._encrypt_data(license_key)\n            checksum = self._create_checksum(license_key)\n            \n            # Check if this MAC is already licensed\n            cursor.execute('SELECT id FROM licenses WHERE mac_address = ?', (current_mac,))\n            existing = cursor.fetchone()\n            \n            if existing:\n                # Update existing license\n                cursor.execute('''\n                    UPDATE licenses \n                    SET license_data = ?, is_active = TRUE, activation_date = CURRENT_TIMESTAMP, \n                        machine_name = ?, checksum = ?\n                    WHERE mac_address = ?\n                ''', (encrypted_key, machine_name, checksum, current_mac))\n            else:\n                # Insert new license\n                cursor.execute('''\n                    INSERT INTO licenses (mac_address, license_data, machine_name, checksum)\n                    VALUES (?, ?, ?, ?)\n                ''', (current_mac, encrypted_key, machine_name, checksum))\n            \n            conn.commit()\n            conn.close()\n            return True, \"License activated successfully\"\n            \n        except Exception as e:\n            return False, f\"Database error: {str(e)}\"\n    \n    def deactivate_license(self):\n        \"\"\"Deactivate license for current machine\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            UPDATE licenses SET is_active = FALSE \n            WHERE mac_address = ?\n        ''', (current_mac,))\n        \n        conn.commit()\n        conn.close()\n    \n    def get_license_info(self):\n        \"\"\"Get license information for current machine\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_data, activation_date, machine_name, is_active, checksum\n            FROM licenses WHERE mac_address = ?\n        ''', (current_mac,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if result:\n            license_data, activation_date, machine_name, is_active, checksum = result\n            decrypted_key = self._decrypt_data(license_data)\n            \n            # Verify integrity\n            if decrypted_key and self._create_checksum(decrypted_key) == checksum:\n                return {\n                    'mac_address': current_mac,\n                    'license_key': decrypted_key[:8] + '****',  # Partially mask the key\n                    'activation_date': activation_date,\n                    'machine_name': machine_name,\n                    'is_active': bool(is_active)\n                }\n        return None\n    \n    def get_machine_identifier(self):\n        \"\"\"Get unique machine identifier for license generation\"\"\"\n        mac = self.get_mac_address()\n        return f\"MAC: {mac}\"\n\n# Global license manager instance\nlicense_manager = LicenseManager()","size_bytes":9449},"onetime_license_manager.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nOne-Time License Manager for StockCeramique\nHandles one-time use license keys that can be activated once on any machine\n\"\"\"\n\nimport hashlib\nimport uuid\nimport sqlite3\nimport os\nfrom datetime import datetime\nimport secrets\nimport string\nimport base64\n\nclass OneTimeLicenseManager:\n    def __init__(self, db_path=None):\n        # Use hidden database path\n        if db_path is None:\n            self.db_path = os.path.join(os.path.expanduser('~'), '.sys', 'cfg', 'licenses.dat')\n        else:\n            self.db_path = db_path\n        self.ensure_db_exists()\n    \n    def ensure_db_exists(self):\n        \"\"\"Create license database and tables if they don't exist\"\"\"\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # One-time license keys table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS onetime_licenses (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                license_key TEXT UNIQUE NOT NULL,\n                is_used BOOLEAN DEFAULT FALSE,\n                used_by_mac TEXT,\n                used_by_machine TEXT,\n                activation_date TIMESTAMP,\n                created_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                checksum TEXT\n            )\n        ''')\n        \n        # Activated machines table (for the old MAC-based system)\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS activated_machines (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                mac_address TEXT UNIQUE NOT NULL,\n                license_key TEXT NOT NULL,\n                machine_name TEXT,\n                activation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                is_active BOOLEAN DEFAULT TRUE\n            )\n        ''')\n        \n        conn.commit()\n        conn.close()\n    \n    def get_mac_address(self):\n        \"\"\"Get the primary MAC address of the machine\"\"\"\n        try:\n            import psutil\n            interfaces = psutil.net_if_addrs()\n            \n            for interface_name, interface_addresses in interfaces.items():\n                if interface_name.lower() != 'lo' and interface_name.lower() != 'loopback':\n                    for address in interface_addresses:\n                        if address.family == psutil.AF_LINK:\n                            mac = address.address\n                            if mac and mac != '00:00:00:00:00:00':\n                                return mac.upper()\n            \n            return ':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) \n                           for elements in range(0,2*6,2)][::-1]).upper()\n        except Exception as e:\n            return ':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff) \n                           for elements in range(0,2*6,2)][::-1]).upper()\n    \n    def get_machine_name(self):\n        \"\"\"Get the machine name/hostname\"\"\"\n        try:\n            return os.environ.get('COMPUTERNAME', os.environ.get('HOSTNAME', 'Unknown'))\n        except:\n            return 'Unknown'\n    \n    def _create_checksum(self, data):\n        \"\"\"Create checksum for data integrity\"\"\"\n        return hashlib.sha256(data.encode()).hexdigest()[:16]\n    \n    def generate_license_key(self):\n        \"\"\"Generate a random one-time use license key\"\"\"\n        # Generate random license key\n        chars = string.ascii_uppercase + string.digits\n        # Remove confusing characters\n        chars = chars.replace('0', '').replace('O', '').replace('I', '').replace('L', '')\n        \n        key_parts = []\n        for _ in range(4):\n            part = ''.join(secrets.choice(chars) for _ in range(4))\n            key_parts.append(part)\n        \n        return '-'.join(key_parts)\n    \n    def generate_license_keys_batch(self, count=10):\n        \"\"\"Generate a batch of one-time use license keys\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        generated_keys = []\n        \n        for _ in range(count):\n            # Generate unique key\n            while True:\n                license_key = self.generate_license_key()\n                \n                # Check if key already exists\n                cursor.execute('SELECT id FROM onetime_licenses WHERE license_key = ?', (license_key,))\n                if not cursor.fetchone():\n                    break\n            \n            # Create checksum\n            checksum = self._create_checksum(license_key)\n            \n            # Insert into database\n            cursor.execute('''\n                INSERT INTO onetime_licenses (license_key, checksum)\n                VALUES (?, ?)\n            ''', (license_key, checksum))\n            \n            generated_keys.append(license_key)\n        \n        conn.commit()\n        conn.close()\n        \n        return generated_keys\n    \n    def is_license_key_valid(self, license_key):\n        \"\"\"Check if a license key exists and is valid\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_key, is_used, checksum FROM onetime_licenses \n            WHERE license_key = ?\n        ''', (license_key.strip().upper(),))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if result:\n            stored_key, is_used, checksum = result\n            # Verify checksum\n            if self._create_checksum(stored_key) == checksum:\n                return True, is_used\n        \n        return False, False\n    \n    def activate_license_key(self, license_key):\n        \"\"\"Activate a one-time license key\"\"\"\n        license_key = license_key.strip().upper()\n        current_mac = self.get_mac_address()\n        machine_name = self.get_machine_name()\n        \n        # Check if license key is valid\n        is_valid, is_used = self.is_license_key_valid(license_key)\n        \n        if not is_valid:\n            return False, \"Invalid license key\"\n        \n        if is_used:\n            return False, \"This license key has already been used. Contact support for assistance.\"\n        \n        try:\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # Mark license as used\n            cursor.execute('''\n                UPDATE onetime_licenses \n                SET is_used = TRUE, used_by_mac = ?, used_by_machine = ?, activation_date = CURRENT_TIMESTAMP\n                WHERE license_key = ?\n            ''', (current_mac, machine_name, license_key))\n            \n            # Also record in activated machines table\n            cursor.execute('''\n                INSERT OR REPLACE INTO activated_machines (mac_address, license_key, machine_name)\n                VALUES (?, ?, ?)\n            ''', (current_mac, license_key, machine_name))\n            \n            conn.commit()\n            conn.close()\n            \n            return True, \"License activated successfully\"\n            \n        except Exception as e:\n            return False, f\"Database error: {str(e)}\"\n    \n    def is_machine_licensed(self):\n        \"\"\"Check if the current machine has an active license\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_key FROM activated_machines \n            WHERE mac_address = ? AND is_active = TRUE\n        ''', (current_mac,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        return result is not None\n    \n    def get_machine_license_info(self):\n        \"\"\"Get license information for current machine\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_key, activation_date, machine_name\n            FROM activated_machines \n            WHERE mac_address = ? AND is_active = TRUE\n        ''', (current_mac,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if result:\n            license_key, activation_date, machine_name = result\n            return {\n                'mac_address': current_mac,\n                'license_key': license_key[:8] + '****',  # Partially mask\n                'activation_date': activation_date,\n                'machine_name': machine_name,\n                'is_active': True\n            }\n        return None\n    \n    def deactivate_license(self):\n        \"\"\"Deactivate license for current machine\"\"\"\n        current_mac = self.get_mac_address()\n        \n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            UPDATE activated_machines SET is_active = FALSE \n            WHERE mac_address = ?\n        ''', (current_mac,))\n        \n        conn.commit()\n        conn.close()\n    \n    def get_all_license_keys(self):\n        \"\"\"Get all generated license keys (for admin purposes)\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT license_key, is_used, used_by_mac, used_by_machine, activation_date, created_date\n            FROM onetime_licenses \n            ORDER BY created_date DESC\n        ''')\n        \n        results = cursor.fetchall()\n        conn.close()\n        \n        licenses = []\n        for row in results:\n            license_key, is_used, used_by_mac, used_by_machine, activation_date, created_date = row\n            licenses.append({\n                'license_key': license_key,\n                'is_used': bool(is_used),\n                'used_by_mac': used_by_mac or 'Not used',\n                'used_by_machine': used_by_machine or 'Not used',\n                'activation_date': activation_date or 'Not activated',\n                'created_date': created_date,\n                'status': 'Used' if is_used else 'Available'\n            })\n        \n        return licenses\n\n# Global instance\nonetime_license_manager = OneTimeLicenseManager()","size_bytes":10148},"import_articles_batch.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nBatch Article Import Script for StockCeramique\nImports articles in smaller batches to avoid timeout\n\"\"\"\n\nimport os\nfrom flask_app import create_app\nfrom flask_models import db, Supplier, Article\n\ndef determine_article_category(designation):\n    \"\"\"Determine article category based on designation keywords\"\"\"\n    designation_lower = designation.lower()\n    \n    categories = {\n        'Hydraulique': ['hydraulique', 'flexible', 'pompe', 'verin', 'huile', 'filtre hydraulique'],\n        'Mécanique': ['roulement', 'palier', 'coussinet', 'axe', 'bague', 'courroie', 'poulie'],\n        'Électrique': ['cable', 'bobine', 'contacteur', 'disjoncteur', 'moteur', 'electrique', 'lampe'],\n        'Pneumatique': ['pneumatique', 'compresseur', 'air comprime', 'floteur'],\n        'Outils': ['foret', 'cle', 'tournevis', 'pince', 'outil'],\n        'Consommables': ['vis', 'boulon', 'ecrou', 'joint', 'collier', 'filtre'],\n        'Divers': []\n    }\n    \n    for category, keywords in categories.items():\n        if any(keyword in designation_lower for keyword in keywords):\n            return category\n    \n    return 'Divers'\n\ndef import_articles_batch(batch_size=50):\n    \"\"\"Import articles in batches\"\"\"\n    articles_file = 'attached_assets/Pasted-ID-P-NOM-P-Designation-P-109653-30X860-100X640-AXE-TAMBOUR-CYLINDRIQUE-30X860-100X640-159-2442100--1756385528917_1756385528918.txt'\n    \n    app = create_app()\n    \n    with app.app_context():\n        # Get default supplier\n        default_supplier = Supplier.query.first()\n        default_supplier_id = default_supplier.id if default_supplier else None\n        \n        imported_count = 0\n        skipped_count = 0\n        \n        with open(articles_file, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n        \n        # Skip header line\n        article_lines = lines[1:]\n        total_lines = len(article_lines)\n        \n        print(f\"Processing {total_lines} articles in batches of {batch_size}...\")\n        \n        for i in range(0, total_lines, batch_size):\n            batch_lines = article_lines[i:i+batch_size]\n            batch_num = i // batch_size + 1\n            \n            print(f\"Processing batch {batch_num}/{(total_lines + batch_size - 1) // batch_size}...\")\n            \n            for line in batch_lines:\n                if not line.strip():\n                    continue\n                    \n                parts = line.strip().split('\\t')\n                if len(parts) < 3:\n                    continue\n                \n                try:\n                    id_original = parts[0].strip() if parts[0] else ''\n                    nom_p = parts[1].strip() if parts[1] else ''\n                    designation = parts[2].strip() if parts[2] else ''\n                    \n                    if not designation:\n                        continue\n                    \n                    # Create unique code_article\n                    code_article = nom_p or designation[:50]\n                    \n                    # Check if already exists\n                    existing = Article.query.filter_by(code_article=code_article).first()\n                    if existing:\n                        skipped_count += 1\n                        continue\n                    \n                    # Determine category\n                    category = determine_article_category(designation)\n                    \n                    # Create article\n                    article = Article(\n                        code_article=code_article,\n                        designation=designation,\n                        categorie=category,\n                        marque='',\n                        reference=nom_p,\n                        stock_initial=0,\n                        stock_actuel=0,\n                        unite='pcs',\n                        prix_unitaire=0.00,\n                        seuil_minimum=5,\n                        fournisseur_id=default_supplier_id\n                    )\n                    \n                    db.session.add(article)\n                    imported_count += 1\n                    \n                except Exception as e:\n                    print(f\"Error processing line: {e}\")\n                    continue\n            \n            # Commit batch\n            try:\n                db.session.commit()\n                print(f\"✅ Batch {batch_num} committed: {imported_count} imported, {skipped_count} skipped\")\n            except Exception as e:\n                db.session.rollback()\n                print(f\"❌ Error committing batch {batch_num}: {e}\")\n        \n        print(f\"\\n✅ Final results: {imported_count} articles imported, {skipped_count} skipped\")\n\nif __name__ == '__main__':\n    import_articles_batch(50)","size_bytes":4748},"import_data.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nData Import Script for StockCeramique\nImports suppliers and articles from tab-separated text files\n\"\"\"\n\nimport re\nimport os\nfrom flask_app import create_app\nfrom flask_models import db, Supplier, Article\nfrom datetime import datetime\n\ndef clean_phone_number(phone):\n    \"\"\"Clean and normalize phone numbers\"\"\"\n    if not phone or phone in ['00', '000', '0000000000', '00000000000', '000000000']:\n        return None\n    # Remove common invalid patterns\n    phone = str(phone).strip()\n    if phone.startswith('0') and len(phone) > 1:\n        return phone\n    return phone if phone != '0' else None\n\ndef clean_email(email):\n    \"\"\"Clean and validate email addresses\"\"\"\n    if not email or email.strip() == '':\n        return None\n    email = email.strip()\n    # Basic email validation\n    if '@' in email and '.' in email:\n        return email\n    return None\n\ndef clean_text(text):\n    \"\"\"Clean text fields\"\"\"\n    if not text or str(text).strip() == '':\n        return None\n    return str(text).strip()\n\ndef parse_suppliers_file(file_path):\n    \"\"\"Parse the suppliers tab-separated file\"\"\"\n    suppliers = []\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    \n    # Skip header line\n    for line in lines[1:]:\n        if not line.strip():\n            continue\n            \n        # Split by tabs\n        parts = line.strip().split('\\t')\n        if len(parts) < 8:\n            continue\n            \n        try:\n            supplier_data = {\n                'id_original': clean_text(parts[0]),\n                'nom': clean_text(parts[1]),\n                'adresse': clean_text(parts[2]),\n                'telephone': clean_phone_number(parts[3]),\n                'fax': clean_phone_number(parts[4]),\n                'email': clean_email(parts[5]),\n                'id_d': clean_text(parts[6]),\n                'remarque': clean_text(parts[7]) if len(parts) > 7 else None\n            }\n            \n            if supplier_data['nom']:  # Only add if name exists\n                suppliers.append(supplier_data)\n                \n        except Exception as e:\n            print(f\"Error parsing supplier line: {line.strip()[:100]}... - {e}\")\n            continue\n    \n    return suppliers\n\ndef parse_articles_file(file_path):\n    \"\"\"Parse the articles tab-separated file\"\"\"\n    articles = []\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        lines = f.readlines()\n    \n    # Skip header line\n    for line in lines[1:]:\n        if not line.strip():\n            continue\n            \n        # Split by tabs\n        parts = line.strip().split('\\t')\n        if len(parts) < 3:\n            continue\n            \n        try:\n            article_data = {\n                'id_original': clean_text(parts[0]),\n                'nom_p': clean_text(parts[1]),\n                'designation': clean_text(parts[2])\n            }\n            \n            if article_data['designation']:  # Only add if designation exists\n                articles.append(article_data)\n                \n        except Exception as e:\n            print(f\"Error parsing article line: {line.strip()[:100]}... - {e}\")\n            continue\n    \n    return articles\n\ndef determine_article_category(designation):\n    \"\"\"Determine article category based on designation keywords\"\"\"\n    designation_lower = designation.lower()\n    \n    # Category mapping based on keywords\n    categories = {\n        'Hydraulique': ['hydraulique', 'flexible', 'pompe', 'verin', 'huile', 'filtre hydraulique'],\n        'Mécanique': ['roulement', 'palier', 'coussinet', 'axe', 'bague', 'courroie', 'poulie'],\n        'Électrique': ['cable', 'bobine', 'contacteur', 'disjoncteur', 'moteur', 'electrique', 'lampe'],\n        'Pneumatique': ['pneumatique', 'compresseur', 'air comprime', 'floteur'],\n        'Outils': ['foret', 'cle', 'tournevis', 'pince', 'outil'],\n        'Consommables': ['vis', 'boulon', 'ecrou', 'joint', 'collier', 'filtre'],\n        'Divers': []\n    }\n    \n    for category, keywords in categories.items():\n        if any(keyword in designation_lower for keyword in keywords):\n            return category\n    \n    return 'Divers'\n\ndef import_suppliers(suppliers_data):\n    \"\"\"Import suppliers into the database\"\"\"\n    imported_count = 0\n    skipped_count = 0\n    \n    print(f\"Importing {len(suppliers_data)} suppliers...\")\n    \n    for supplier_data in suppliers_data:\n        try:\n            # Check if supplier already exists\n            existing = Supplier.query.filter_by(nom=supplier_data['nom']).first()\n            if existing:\n                print(f\"Supplier already exists: {supplier_data['nom']}\")\n                skipped_count += 1\n                continue\n            \n            # Create new supplier\n            supplier = Supplier(\n                nom=supplier_data['nom'],\n                adresse=supplier_data['adresse'],\n                telephone=supplier_data['telephone'],\n                email=supplier_data['email'],\n                contact=supplier_data['remarque'],  # Use remarque as contact info\n                conditions_paiement='Net 30',  # Default payment terms\n                delai_livraison=7  # Default delivery time\n            )\n            \n            db.session.add(supplier)\n            imported_count += 1\n            \n            if imported_count % 50 == 0:\n                print(f\"Imported {imported_count} suppliers...\")\n                \n        except Exception as e:\n            print(f\"Error importing supplier {supplier_data['nom']}: {e}\")\n            continue\n    \n    try:\n        db.session.commit()\n        print(f\"✅ Successfully imported {imported_count} suppliers, skipped {skipped_count}\")\n    except Exception as e:\n        db.session.rollback()\n        print(f\"❌ Error committing suppliers: {e}\")\n        return 0\n    \n    return imported_count\n\ndef import_articles(articles_data):\n    \"\"\"Import articles into the database\"\"\"\n    imported_count = 0\n    skipped_count = 0\n    \n    print(f\"Importing {len(articles_data)} articles...\")\n    \n    # Get first supplier as default (you can modify this logic)\n    default_supplier = Supplier.query.first()\n    default_supplier_id = default_supplier.id if default_supplier else None\n    \n    for article_data in articles_data:\n        try:\n            # Create code_article from nom_p or use designation\n            code_article = article_data['nom_p'] or article_data['designation'][:50]\n            \n            # Check if article already exists\n            existing = Article.query.filter_by(code_article=code_article).first()\n            if existing:\n                print(f\"Article already exists: {code_article}\")\n                skipped_count += 1\n                continue\n            \n            # Determine category\n            category = determine_article_category(article_data['designation'])\n            \n            # Create new article\n            article = Article(\n                code_article=code_article,\n                designation=article_data['designation'],\n                categorie=category,\n                marque='',  # Empty for now\n                reference=article_data['nom_p'],\n                stock_initial=0,\n                stock_actuel=0,\n                unite='pcs',\n                prix_unitaire=0.00,\n                seuil_minimum=5,\n                fournisseur_id=default_supplier_id\n            )\n            \n            db.session.add(article)\n            imported_count += 1\n            \n            if imported_count % 100 == 0:\n                print(f\"Imported {imported_count} articles...\")\n                \n        except Exception as e:\n            print(f\"Error importing article {article_data.get('designation', 'Unknown')}: {e}\")\n            continue\n    \n    try:\n        db.session.commit()\n        print(f\"✅ Successfully imported {imported_count} articles, skipped {skipped_count}\")\n    except Exception as e:\n        db.session.rollback()\n        print(f\"❌ Error committing articles: {e}\")\n        return 0\n    \n    return imported_count\n\ndef main():\n    \"\"\"Main import function\"\"\"\n    print(\"🚀 Starting data import for StockCeramique...\")\n    \n    # File paths\n    suppliers_file = 'attached_assets/Pasted-ID-F-NOM-F-ADRESSE-F-TEL-F-FAX-F-EMAIL-F-ID-D-REMARQUE-F-384-A-D-S-INDUSTRIE-MAROC-0539714269-1--1756385420545_1756385420546.txt'\n    articles_file = 'attached_assets/Pasted-ID-P-NOM-P-Designation-P-109653-30X860-100X640-AXE-TAMBOUR-CYLINDRIQUE-30X860-100X640-159-2442100--1756385528917_1756385528918.txt'\n    \n    # Check if files exist\n    if not os.path.exists(suppliers_file):\n        print(f\"❌ Suppliers file not found: {suppliers_file}\")\n        return\n    \n    if not os.path.exists(articles_file):\n        print(f\"❌ Articles file not found: {articles_file}\")\n        return\n    \n    # Create Flask app context\n    app = create_app()\n    \n    with app.app_context():\n        try:\n            # Parse data files\n            print(\"📖 Parsing suppliers file...\")\n            suppliers_data = parse_suppliers_file(suppliers_file)\n            print(f\"Found {len(suppliers_data)} suppliers to import\")\n            \n            print(\"📖 Parsing articles file...\")\n            articles_data = parse_articles_file(articles_file)\n            print(f\"Found {len(articles_data)} articles to import\")\n            \n            # Import suppliers first\n            print(\"\\n\" + \"=\"*50)\n            print(\"IMPORTING SUPPLIERS\")\n            print(\"=\"*50)\n            suppliers_imported = import_suppliers(suppliers_data)\n            \n            # Import articles\n            print(\"\\n\" + \"=\"*50)\n            print(\"IMPORTING ARTICLES\")\n            print(\"=\"*50)\n            articles_imported = import_articles(articles_data)\n            \n            print(\"\\n\" + \"=\"*50)\n            print(\"IMPORT SUMMARY\")\n            print(\"=\"*50)\n            print(f\"✅ Suppliers imported: {suppliers_imported}\")\n            print(f\"✅ Articles imported: {articles_imported}\")\n            print(\"✅ Data import completed successfully!\")\n            \n        except Exception as e:\n            print(f\"❌ Import failed: {e}\")\n            import traceback\n            traceback.print_exc()\n\nif __name__ == '__main__':\n    main()","size_bytes":10239},"import_new_articles.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nImport Script for New Article Format\nImports articles from simplified two-column format (NOM_P, Designation_P)\n\"\"\"\n\nimport os\nfrom flask_app import create_app\nfrom flask_models import db, Supplier, Article\n\ndef determine_article_category(designation):\n    \"\"\"Determine article category based on designation keywords\"\"\"\n    designation_lower = designation.lower()\n    \n    categories = {\n        'Hydraulique': ['hydraulique', 'flexible', 'pompe', 'verin', 'huile', 'filtre hydraulique'],\n        'Mécanique': ['roulement', 'palier', 'coussinet', 'axe', 'bague', 'courroie', 'poulie', 'mandrin'],\n        'Électrique': ['cable', 'bobine', 'contacteur', 'disjoncteur', 'moteur', 'electrique', 'lampe', 'ampoule'],\n        'Pneumatique': ['pneumatique', 'compresseur', 'air comprime', 'floteur'],\n        'Outils': ['foret', 'cle', 'tournevis', 'pince', 'outil', 'tenaille'],\n        'Consommables': ['vis', 'boulon', 'ecrou', 'joint', 'collier', 'filtre', 'bouchon'],\n        'Sécurité': ['chaussure', 'securite'],\n        'Divers': []\n    }\n    \n    for category, keywords in categories.items():\n        if any(keyword in designation_lower for keyword in keywords):\n            return category\n    \n    return 'Divers'\n\ndef import_articles_from_new_format():\n    \"\"\"Import articles from the new simplified format\"\"\"\n    articles_file = 'attached_assets/Pasted-NOM-P-Designation-P-30X860-100X640-AXE-TAMBOUR-CYLINDRIQUE-30X860-100X640-2442100-V4046-AMPOULE-ST-1756386266901_1756386266903.txt'\n    \n    if not os.path.exists(articles_file):\n        print(f\"❌ File not found: {articles_file}\")\n        return\n    \n    app = create_app()\n    \n    with app.app_context():\n        # Get default supplier\n        default_supplier = Supplier.query.first()\n        default_supplier_id = default_supplier.id if default_supplier else None\n        \n        imported_count = 0\n        skipped_count = 0\n        batch_size = 100\n        \n        print(f\"🚀 Starting import from new format file...\")\n        \n        with open(articles_file, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n        \n        # Skip header line\n        article_lines = lines[1:]\n        total_lines = len(article_lines)\n        \n        print(f\"📖 Found {total_lines} articles to process...\")\n        \n        # Check current article count\n        current_count = Article.query.count()\n        print(f\"📊 Current articles in database: {current_count}\")\n        \n        for i, line in enumerate(article_lines):\n            if not line.strip():\n                continue\n                \n            parts = line.strip().split('\\t')\n            if len(parts) < 2:\n                continue\n            \n            try:\n                nom_p = parts[0].strip() if parts[0] else ''\n                designation = parts[1].strip() if parts[1] else ''\n                \n                if not designation:\n                    continue\n                \n                # Create unique code_article\n                code_article = nom_p or designation[:50]\n                \n                # Check if already exists\n                existing = Article.query.filter_by(code_article=code_article).first()\n                if existing:\n                    skipped_count += 1\n                    continue\n                \n                # Determine category\n                category = determine_article_category(designation)\n                \n                # Create article\n                article = Article(\n                    code_article=code_article,\n                    designation=designation,\n                    categorie=category,\n                    marque='',\n                    reference=nom_p,\n                    stock_initial=0,\n                    stock_actuel=0,\n                    unite='pcs',\n                    prix_unitaire=0.00,\n                    seuil_minimum=5,\n                    fournisseur_id=default_supplier_id\n                )\n                \n                db.session.add(article)\n                imported_count += 1\n                \n                # Commit in batches\n                if imported_count % batch_size == 0:\n                    try:\n                        db.session.commit()\n                        print(f\"✅ Batch committed: {imported_count} imported so far...\")\n                    except Exception as e:\n                        db.session.rollback()\n                        print(f\"❌ Error committing batch: {e}\")\n                        break\n                \n            except Exception as e:\n                print(f\"❌ Error processing line {i+1}: {e}\")\n                continue\n        \n        # Final commit\n        try:\n            db.session.commit()\n            print(f\"\\n🎉 Import completed!\")\n            print(f\"✅ Articles imported: {imported_count}\")\n            print(f\"⏭️  Articles skipped (already existed): {skipped_count}\")\n            \n            # Final count\n            final_count = Article.query.count()\n            print(f\"📊 Total articles now in database: {final_count}\")\n            \n        except Exception as e:\n            db.session.rollback()\n            print(f\"❌ Error in final commit: {e}\")\n\nif __name__ == '__main__':\n    import_articles_from_new_format()","size_bytes":5277},"import_suppliers.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nScript to import supplier data from the provided text file\n\"\"\"\n\nimport re\nimport os\nimport sys\nfrom flask_app import create_app\nfrom flask_models import db, Supplier\nfrom datetime import datetime\n\ndef clean_phone_number(phone):\n    \"\"\"Clean and normalize phone numbers\"\"\"\n    if not phone or phone in ['0', '00', '000', '0000', '00000', '000000', '0000000', '00000000', '000000000', '0000000000', '00000000000']:\n        return None\n    \n    # Remove spaces and clean formatting\n    phone = re.sub(r'[^\\d+]', '', str(phone))\n    \n    # If it's just zeros, return None\n    if re.match(r'^0+$', phone):\n        return None\n        \n    return phone if phone else None\n\ndef clean_email(email):\n    \"\"\"Clean and validate email addresses\"\"\"\n    if not email or email.strip() == '':\n        return None\n    \n    email = email.strip()\n    \n    # Basic email validation\n    if '@' in email and '.' in email:\n        return email\n    \n    return None\n\ndef parse_supplier_line(line):\n    \"\"\"Parse a single line of supplier data\"\"\"\n    if not line or line.startswith('_F') or len(line.strip()) < 10:\n        return None\n    \n    # Split by tabs\n    parts = line.split('\\t')\n    \n    if len(parts) < 6:\n        return None\n    \n    nom = parts[0].strip() if parts[0] else None\n    adresse = parts[1].strip() if parts[1] else None\n    telephone = clean_phone_number(parts[2]) if parts[2] else None\n    fax = clean_phone_number(parts[3]) if parts[3] else None\n    email = clean_email(parts[4]) if parts[4] else None\n    \n    # Skip if no name\n    if not nom or nom == '':\n        return None\n    \n    # Create supplier data\n    supplier_data = {\n        'nom': nom,\n        'adresse': adresse,\n        'telephone': telephone,\n        'email': email,\n        'contact': None,  # We'll use the main phone as contact if available\n        'conditions_paiement': None,\n        'delai_livraison': None\n    }\n    \n    return supplier_data\n\ndef import_suppliers_from_file(file_path):\n    \"\"\"Import suppliers from the text file\"\"\"\n    app = create_app()\n    \n    with app.app_context():\n        try:\n            # Read the file\n            with open(file_path, 'r', encoding='utf-8') as f:\n                lines = f.readlines()\n            \n            imported_count = 0\n            skipped_count = 0\n            \n            print(f\"Processing {len(lines)} lines...\")\n            \n            for line_num, line in enumerate(lines, 1):\n                supplier_data = parse_supplier_line(line)\n                \n                if not supplier_data:\n                    skipped_count += 1\n                    continue\n                \n                # Check if supplier already exists\n                existing = Supplier.query.filter_by(nom=supplier_data['nom']).first()\n                if existing:\n                    print(f\"Supplier '{supplier_data['nom']}' already exists, skipping...\")\n                    skipped_count += 1\n                    continue\n                \n                try:\n                    # Create new supplier\n                    supplier = Supplier(\n                        nom=supplier_data['nom'],\n                        adresse=supplier_data['adresse'],\n                        telephone=supplier_data['telephone'],\n                        email=supplier_data['email'],\n                        contact=supplier_data['contact'],\n                        conditions_paiement=supplier_data['conditions_paiement'],\n                        delai_livraison=supplier_data['delai_livraison']\n                    )\n                    \n                    db.session.add(supplier)\n                    imported_count += 1\n                    \n                    if imported_count % 50 == 0:\n                        print(f\"Processed {imported_count} suppliers...\")\n                        \n                except Exception as e:\n                    print(f\"Error creating supplier '{supplier_data['nom']}': {str(e)}\")\n                    skipped_count += 1\n                    continue\n            \n            # Commit all changes\n            db.session.commit()\n            \n            print(f\"\\nImport completed!\")\n            print(f\"Successfully imported: {imported_count} suppliers\")\n            print(f\"Skipped: {skipped_count} entries\")\n            \n            return imported_count, skipped_count\n            \n        except Exception as e:\n            print(f\"Error during import: {str(e)}\")\n            db.session.rollback()\n            return 0, 0\n\nif __name__ == '__main__':\n    file_path = 'attached_assets/Pasted--F-ADRESSE-F-TEL-F-FAX-F-EMAIL-F-ID-D-REMARQUE-F-A-D-S-INDUSTRIE-MAROC-0539714269-1-FERAILLE-SI-1756416297250_1756416297251.txt'\n    \n    if not os.path.exists(file_path):\n        print(f\"File not found: {file_path}\")\n        sys.exit(1)\n    \n    imported, skipped = import_suppliers_from_file(file_path)\n    print(f\"\\nFinal result: {imported} imported, {skipped} skipped\")","size_bytes":4934},"init_user.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nInitialize the default user for Orbit system\nCreates user: mustapha with password: 26cedesa8@2024\n\"\"\"\n\nfrom flask_app import create_app\nfrom flask_models import db, User\n\ndef init_default_user():\n    app = create_app()\n    \n    with app.app_context():\n        # Check if user already exists\n        existing_user = User.query.filter_by(username='mustapha').first()\n        \n        if existing_user:\n            print(\"User 'mustapha' already exists\")\n            return\n        \n        # Create the default user\n        user = User(\n            username='mustapha',\n            full_name='Mustapha',\n            email='mustapha@orbit.com',\n            is_active=True\n        )\n        user.set_password('26cedesa8@2024')\n        \n        db.session.add(user)\n        db.session.commit()\n        \n        print(\"Default user 'mustapha' created successfully\")\n        print(\"Username: mustapha\")\n        print(\"Password: 26cedesa8@2024\")\n\nif __name__ == '__main__':\n    init_default_user()","size_bytes":1016},"server/db.ts":{"content":"import { Pool, neonConfig } from '@neondatabase/serverless';\nimport { drizzle } from 'drizzle-orm/neon-serverless';\nimport ws from \"ws\";\nimport * as schema from \"@shared/schema\";\n\nneonConfig.webSocketConstructor = ws;\n\nif (!process.env.DATABASE_URL) {\n  throw new Error(\n    \"DATABASE_URL must be set. Did you forget to provision a database?\",\n  );\n}\n\nexport const pool = new Pool({ connectionString: process.env.DATABASE_URL });\nexport const db = drizzle({ client: pool, schema });\n","size_bytes":483}},"version":1}